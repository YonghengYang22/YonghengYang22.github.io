<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>6.19周报</title>
    <link href="/2025/06/16/6-19%E5%91%A8%E6%8A%A5/"/>
    <url>/2025/06/16/6-19%E5%91%A8%E6%8A%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>这周主要是看了几个facial expression recognition任务的基于视频的数据集，最终选择CK+数据集。以及具体学习了面部对齐方法中的AAM方法，后续再进行一些实验看看效果。</p><h2 id="视频表情识别数据集"><a href="#视频表情识别数据集" class="headerlink" title="视频表情识别数据集"></a>视频表情识别数据集</h2><p>数据集是在paperswithcode去找的</p><h3 id="AFEW"><a href="#AFEW" class="headerlink" title="AFEW"></a>AFEW</h3><p>acted facial expressions in the wild。</p><p>从电影中选取的视频片段</p><p>分类任务：七分类。【Angry Disgust Fear Happy Sad Surprise Neutral】</p><p>一个视频片段对应一个情绪类别</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250616153420384.png" alt="image-20250616153420384" style="zoom:30%;" /><p><em>为什么在这个数据集上的表情识别任务最高也只在20年刷到了65，还是基础的resnet，没人来刷吗，后面出来的Vit之类的模型没人试试吗？</em></p><p>【题外话，怎么判断一个任务有没有做的意义，有的数据集上没有什么人去做，点也没有被刷的很高，是因为一些小众一些的数据集就没有刷点的意义了吗】</p><h3 id="AFEW-VA"><a href="#AFEW-VA" class="headerlink" title="AFEW-VA"></a>AFEW-VA</h3><p>V:Valence效价，衡量情绪的正负[-1,1]</p><p>A:Arousal（唤醒度），衡量情绪激活程度[-1,1]</p><p>回归问题</p><p>逐帧标注数据集，每个帧或滑动窗口都有VA值，以及其对应的68维面部关键点</p><p>用途：<strong>情绪轨迹建模</strong>，情感计算(<em>抑郁症任务和情感计算任务是否有相通点？</em>)</p><p>情绪轨迹建模这个思想和对关键点进行轨迹建模形成光流的这个思想感觉有点相似。<em>话说老师提到光流的目的是什么，是让我把面部关键点随时间变化形成的光流作为特征输入模型还是能通过面部关键点轨迹去做对齐呢？</em></p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250616183346574.png" alt="image-20250616183346574" style="zoom:33%;" /><h3 id="CK-数据集"><a href="#CK-数据集" class="headerlink" title="CK+数据集"></a>CK+数据集</h3><p>123个个体，593个视频序列，每个序列从中性表情过度到峰值表情。327个序列有情绪标签。</p><p>情绪标签有7个类别，0&#x3D;neutral 1&#x3D;anger  2&#x3D;contempt 3&#x3D;disgust 4&#x3D;fear 5&#x3D;happy 6&#x3D;sadness 7&#x3D;surprise</p><p>数据集包含视频序列的帧，每帧的情感标签，动作单元标签，68维关键点这四个部分</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250618224708702.png" alt="image-20250618224708702" style="zoom:33%;" /><h2 id="抑郁症检测数据集"><a href="#抑郁症检测数据集" class="headerlink" title="抑郁症检测数据集"></a>抑郁症检测数据集</h2><h3 id="LMVD"><a href="#LMVD" class="headerlink" title="LMVD"></a>LMVD</h3><p><a href="https://github.com/helang818/LMVD">LMVD</a>是一个多模态的抑郁症数据集，包含nonverbal的视觉特征和音频特征，其中视觉特征包含FAU,facial landmarks,eye gaze,head pose</p><h3 id="DVlog"><a href="#DVlog" class="headerlink" title="DVlog"></a>DVlog</h3><p>和LMVD类似，但是没有包含head pose信息</p><h2 id="Deprssion-Detection和FER的相同与不同"><a href="#Deprssion-Detection和FER的相同与不同" class="headerlink" title="Deprssion Detection和FER的相同与不同"></a>Deprssion Detection和FER的相同与不同</h2><h3 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h3><ul><li>输入的模态都包含视频或者图像</li><li>都是对面部视觉信号的分析，都会使用一些面部动作单元AU，面部关键点等作为特征来分析</li><li>数据预处理都会进行人脸检测与裁剪，面部对齐，时间序列建模</li></ul><h3 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h3><ul><li>抑郁症检测检测出来的是个体的抑郁程度，不会因为不同帧表情不同而出现不同的检测结果。表情识别是针对每帧的表情进行检测，每帧之间的结果可以不同。</li><li>抑郁症是分类任务，标签可以通过量表PHQ-9来标注，表情识别可以是分类任务，固定的情绪类别，也可以是回归任务，得到情绪的效价valence以及唤醒都arousal。</li><li>表情是情绪的外在表现，抑郁症则是情绪长期异常状态。抑郁症通常伴随<strong>情绪表达异常</strong>，如：微笑减少、愉悦表情减少（低效价）；面部活动减少（低唤醒）；中性&#x2F;悲伤表情持续时间变长</li></ul><p>在抑郁症检测中也有通过表情识别模型提取情绪时间序列，再做情绪轨迹建模分析（如情绪起伏少 → 抑郁倾向）。<a href="https://www.sciencedirect.com/science/article/abs/pii/S1047320318302761">Facial expression video analysis for depression detection in Chinese patients - ScienceDirect</a></p><h2 id="面部对齐方法"><a href="#面部对齐方法" class="headerlink" title="面部对齐方法"></a>面部对齐方法</h2><p>之前那篇综述里面模型方面一共提到了6个面部对齐的模型，主要了解了一下AAM面部对齐方法</p><h3 id="Active-Apperance-Models-AAMS"><a href="#Active-Apperance-Models-AAMS" class="headerlink" title="Active Apperance Models(AAMS)"></a>Active Apperance Models(AAMS)</h3><p>[^AAMS]: T. Cootes, G. Edwards, and C. Taylor. Active Appearance Models. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 23(6):681–685, 2001</p><p>AAM是一种可以对人脸进行建模、跟踪和识别的方法，同时考虑了形状变化(shape variation)和外观变化（apperance variation)。AAM可以用在人脸视频或图像中对面部进行自动对齐，提取特征。</p><p>AAM 的 <strong>形状 <code>s</code></strong> 用二维网格（三角网）表示，顶点坐标用向量 <code>[x1, y1, x2, y2, ..., xn, yn]</code> 表示，共 n 个点（通常是人脸关键点）。</p><p>这些关键点可以通过线性方式建模为：<br>$$<br>s &#x3D; s_0 + \sum_{i&#x3D;1}^{m} p_i s_i<br>$$</p><ul><li><code>s0</code>：基础形状（base shape），可以看作是所有训练样本的平均形状；</li><li><code>si</code>：第 i 个形状变化向量（表示一个形变方向）；</li><li><code>pi</code>：对应的形状参数（权重）。</li></ul><p>形状参数p分为两个类型刚性和非刚性</p><table><thead><tr><th>类型</th><th>含义</th></tr></thead><tbody><tr><td>ps（刚性）</td><td>对应 平移、旋转、缩放 等仿射变换</td></tr><tr><td>po（非刚性）</td><td>对应 表情变化（如张嘴、眯眼等）</td></tr></tbody></table><p>使用 Procrustes 对齐来估计 <code>s0</code> —— 把不同图像中的人脸关键点对齐成一致形状，求平均。<br>使用AAM得到两个特征SPTS和CAPP，然后将这两个特征输入到后续模型中。</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250618233544772.png" alt="image-20250618233544772" style="zoom:50%;" /><p><strong>SPTS</strong>（Similarity-normalized Shape）：形状参数，去除了位置&#x2F;角度&#x2F;尺度影响</p><p><strong>CAPP</strong>（Canonical Appearance）：外观特征，如纹理、灰度分布等</p><p>姿态角可以通过关键点计算，应该可以不用在面部对齐的时候保留信息</p><h2 id="多种面部对齐方法对比"><a href="#多种面部对齐方法对比" class="headerlink" title="多种面部对齐方法对比"></a>多种面部对齐方法对比</h2><table><thead><tr><th>方法</th><th>建模维度</th><th>是否支持纹理</th><th>是否支持3D</th><th>鲁棒性</th><th>适用场景</th></tr></thead><tbody><tr><td>ASM</td><td>2D</td><td>❌ 无纹理建模</td><td>❌</td><td>弱</td><td>基本轮廓点检测</td></tr><tr><td>AAM</td><td>2D</td><td>✅ 联合纹理建模</td><td>❌</td><td>中</td><td>表情分析、人脸对齐</td></tr><tr><td>3D-PDM</td><td>3D</td><td>❌ 无纹理建模</td><td>✅</td><td>较强</td><td>多视角、人脸姿态估计</td></tr><tr><td>3DMM</td><td>3D</td><td>✅ 完整建模</td><td>✅</td><td>强</td><td>3D人脸重建、动画、AR</td></tr><tr><td>Bayesian</td><td>2D&#x2F;3D</td><td>✅（可选）</td><td>可选</td><td>中</td><td>学术研究，建模不确定性</td></tr><tr><td>Heatmaps</td><td>2D&#x2F;3D</td><td>✅（隐式）</td><td>可扩展</td><td>非常强</td><td>关键点检测、工业落地</td></tr></tbody></table><h2 id="知识补充"><a href="#知识补充" class="headerlink" title="知识补充"></a>知识补充</h2><h3 id="情绪轨迹建模"><a href="#情绪轨迹建模" class="headerlink" title="情绪轨迹建模"></a>情绪轨迹建模</h3><p>“情绪轨迹建模（Emotion Trajectory Modeling）” 是指对<strong>随时间变化的情绪状态</strong>进行建模和分析的过程，核心是捕捉情绪在一段时间内的<strong>动态演变过程</strong>，而不是只做一个时刻的情绪分类或回归。</p><p>在一段视频中，人物可能从“平静” → “愤怒” → “悲伤” → “平静”。这种时间序列就是情绪轨迹。</p><p>情绪轨迹比单点情绪更能反映<strong>内在状态变化</strong>和<strong>行为意图</strong>。</p><h2 id="后续方向"><a href="#后续方向" class="headerlink" title="后续方向"></a>后续方向</h2><p>打算在CK+数据集上试验一些面部对齐的方法，不过CK+论文的基准方法当时就是使用的AAM进行面部对齐得到对齐后的面部特征输入到SVM中进行分类的，作为对齐来试试其它的面部对齐方法</p>]]></content>
    
    
    
    <tags>
      
      <tag>周报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>端午节周报</title>
    <link href="/2025/06/02/%E7%AB%AF%E5%8D%88%E8%8A%82%E5%91%A8%E6%8A%A5/"/>
    <url>/2025/06/02/%E7%AB%AF%E5%8D%88%E8%8A%82%E5%91%A8%E6%8A%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="基础知识："><a href="#基础知识：" class="headerlink" title="基础知识："></a>基础知识：</h2><h4 id="人脸关键点建模"><a href="#人脸关键点建模" class="headerlink" title="人脸关键点建模"></a>人脸关键点建模</h4><p>通常采用68个关键点对人脸进行建模。另外可以加上头部的姿态角（欧拉角）</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250602160214496.png" alt="image-20250602160214496" style="zoom:50%;" /><p>图像通常是平面的，对人脸关键点的定位采用二维坐标x,y。但是实际的人脸是处于三维坐标中，为了表示一些三维的信息，对人脸的信息又可以加上三个空间中的角度，raw,yaw roll。分别对应向左向右看，上下点头，左右偏头。</p><p>其中roll左右偏头这个角度正好在xy这个平面上，对这个角度的校正比较容易，和对图像进行旋转是一样的。</p><p>另外两个角度涉及到了三维的信息，难以还原。</p><h4 id="LMVD数据集"><a href="#LMVD数据集" class="headerlink" title="LMVD数据集"></a>LMVD数据集</h4><p>视觉特征：</p><p>facial landmark面部关键点</p><p>head pose 头部姿态</p><p>FAU面部动作单元</p><p>eye gaze</p><h4 id="面部对齐（Face-alignment"><a href="#面部对齐（Face-alignment" class="headerlink" title="面部对齐（Face alignment)"></a>面部对齐（Face alignment)</h4><p>基本的方法是仿射变换，直接对图像上的关键点用矩阵进行映射变换到模板位置。但是由于数据集中的特征关键点坐标是二维的，只能在二维平面上做仿射变换。</p><p>如果希望用上姿态角的信息，需要尝试用姿态角然后找到标准人脸模板进行3d建模，像视觉PnP算法（Perspecitve n point)，根据二维图像点，计算出三维场景中物体的位置和姿态。在三维里进行仿射变换再还原到二维。或者看是否有合适的深度学习的模型能进行变换。</p><h2 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h2><p><strong>仿射变换</strong>（Affine Transformation)是一种保持点间直线关系和比例关系的几何变换。可以实现的操作有平移，缩放，旋转，剪切。</p><p>在人脸对齐中使用仿射变换将图像中的人脸关键点对齐到标准模板关键点的位置。</p><p>算法流程：</p><p>准备人脸和模板的关键点坐标</p><p>计算仿射变换矩阵M</p><p>将M作用到原始关键点上得到对齐后关键点坐标</p><p><strong>几种仿射变换的代码：</strong></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604230606082.png" alt="image-20250604230606082" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604230624436.png" alt="image-20250604230624436" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604230641779.png" alt="image-20250604230641779" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604230659894.png" alt="image-20250604230659894" style="zoom:33%;" /></p><p>四种方法特点总结</p><table><thead><tr><th>特性</th><th>procrustes_align_136 (经典普氏)</th><th>similarity_align_136 (Umeyama算法)</th><th>OpenCV_align_136 (OpenCV estimateAffinePartial2D)</th><th><strong>OpenCV_align_136_full</strong>（cv2.estimateAffine2D）</th></tr></thead><tbody><tr><td>变换类型</td><td>欧式变换 (平移, 旋转)</td><td>相似变换 (平移, 旋转, 均匀缩放)</td><td>相似变换 (平移, 旋转, 均匀缩放)</td><td>仿射变换（平移、旋转、非均匀缩放、剪切）</td></tr><tr><td>处理尺度</td><td>否 (假设尺度一致)</td><td>是 (自动计算均匀缩放因子)</td><td>仅改变大小、位置、方向，保持形状不变</td><td>可以改变形状（拉伸、倾斜）</td></tr><tr><td>处理剪切</td><td>否</td><td>否</td><td>否 (通常用于相似变换)</td><td>是（拉伸、倾斜）</td></tr><tr><td>鲁棒性</td><td>对噪声敏感 (标准最小二乘)</td><td>对噪声敏感 (标准最小二乘)</td><td>对异常值鲁棒 (LMEDS方法)</td><td>对异常值鲁棒 (LMEDS方法)</td></tr><tr><td>实现方式</td><td>手动SVD分解</td><td>手动SVD分解</td><td>调用OpenCV库函数</td><td>调用OpenCV库函数</td></tr><tr><td>自由度（2D）</td><td>3</td><td>4</td><td>4</td><td>6</td></tr></tbody></table><p>总结：直接调用OpenCV的2D的映射变换函数cv2.estimateAffine2D效果最好</p><h3 id="关键点映射前后效果展示："><a href="#关键点映射前后效果展示：" class="headerlink" title="关键点映射前后效果展示："></a>关键点映射前后效果展示：</h3><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604195851802.png" alt="image-20250604195851802" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604195909473.png" alt="image-20250604195909473" style="zoom:50%;" /></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604195942846.png" alt="image-20250604195942846" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604200003593.png" alt="image-20250604200003593" style="zoom:50%;" /></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604200030348.png" alt="image-20250604200030348" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604200109026.png" alt="image-20250604200109026" style="zoom:50%;" /></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604200206851.png" alt="image-20250604200206851" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604200300712.png" alt="image-20250604200300712" style="zoom:50%;" /></p><h2 id="仿射变换方法实验"><a href="#仿射变换方法实验" class="headerlink" title="仿射变换方法实验"></a>仿射变换方法实验</h2><p>LMVD数据集处理</p><p>将136维的面部关键点特征单独提取出来处理</p><p>在LMVD的代码上给的<strong>机器学习模型knn</strong>上试了一下效果，<strong>有1个多点提升</strong></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604200830957.png" alt="image-20250604200830957" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604200923248.png" alt="image-20250604200923248" style="zoom:50%;" /></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250604201635736.png"></p><h3 id="其它方法"><a href="#其它方法" class="headerlink" title="其它方法"></a>其它方法</h3><p>和人脸对齐(face alignment)类似的还有一个人脸正对化（face frontalization)</p><p>在人脸正对化里有个模型TP-GAN，看它展示出来的图片处理的效果还不错。不过模型是直接处理的图像，能不能处理关键点还得再研究研究。</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250602155841084.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>周报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Dvlog_intro</title>
    <link href="/2025/05/29/Dvlog-intro/"/>
    <url>/2025/05/29/Dvlog-intro/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>face_align</title>
    <link href="/2025/05/29/face-align/"/>
    <url>/2025/05/29/face-align/</url>
    
    <content type="html"><![CDATA[<h3 id="相似变换"><a href="#相似变换" class="headerlink" title="相似变换"></a><strong>相似变换</strong></h3><p>opencv现有库  cv2.estimateAffinePartial2D()</p><p><strong>平移（Translation）</strong>：图像移动</p><p><strong>缩放（Scaling）</strong>：图像缩放</p><p><strong>旋转（Rotation）</strong>：图像绕某点旋转</p><p><strong>统一尺度保持的变形（不包含剪切）</strong></p><p>对转动只是对着z轴，头部向左倾斜，向右倾斜这种能转动，但是对于绕x,y轴的转动不能处理。</p><p>GAN模型生成正脸图像</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250529094857517.png" alt="image-20250529094857517"></p><p>3D模型建模</p>]]></content>
    
    
    
    <tags>
      
      <tag>face alignment</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>track1和track2的划分逻辑</title>
    <link href="/2025/05/15/track1%E5%92%8Ctrack2%E7%9A%84%E5%88%92%E5%88%86%E9%80%BB%E8%BE%91/"/>
    <url>/2025/05/15/track1%E5%92%8Ctrack2%E7%9A%84%E5%88%92%E5%88%86%E9%80%BB%E8%BE%91/</url>
    
    <content type="html"><![CDATA[<p>MPDD Track1和Track2的划分逻辑</p>]]></content>
    
    
    
    <tags>
      
      <tag>多模态情感识别</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mpdd_Elderly数据集分析</title>
    <link href="/2025/05/14/mpdd%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90/"/>
    <url>/2025/05/14/mpdd%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="MPDD-Elderly数据集分析"><a href="#MPDD-Elderly数据集分析" class="headerlink" title="MPDD Elderly数据集分析"></a>MPDD Elderly数据集分析</h1><h2 id="人格标签各项统计"><a href="#人格标签各项统计" class="headerlink" title="人格标签各项统计"></a>人格标签各项统计</h2><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514121314918.png" alt="image-20250514121314918"></p><h2 id="相关性分析"><a href="#相关性分析" class="headerlink" title="相关性分析"></a>相关性分析</h2><h3 id="各项相关性分析"><a href="#各项相关性分析" class="headerlink" title="各项相关性分析"></a>各项相关性分析</h3><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514132147081.png" alt="image-20250514132147081" style="zoom:50%;" /><h3 id="五人格与二分类抑郁的箱图"><a href="#五人格与二分类抑郁的箱图" class="headerlink" title="五人格与二分类抑郁的箱图"></a>五人格与二分类抑郁的箱图</h3><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514124421948.png" alt="image-20250514124421948" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514125350038.png" alt="image-20250514125350038" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514125429038.png" alt="image-20250514125429038" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514125452958.png" alt="image-20250514125452958" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514125510664.png" alt="image-20250514125510664" style="zoom:25%;" /></p><h3 id="五人格与三分类抑郁的箱图"><a href="#五人格与三分类抑郁的箱图" class="headerlink" title="五人格与三分类抑郁的箱图"></a>五人格与三分类抑郁的箱图</h3><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514130124963.png" alt="image-20250514130124963" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514130142439.png" alt="image-20250514130142439" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514130204732.png" alt="image-20250514130204732" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514130220265.png" alt="image-20250514130220265" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514130234265.png" alt="image-20250514130234265" style="zoom:25%;" /></p><h3 id="t检验分析（二分类抑郁类型）"><a href="#t检验分析（二分类抑郁类型）" class="headerlink" title="t检验分析（二分类抑郁类型）"></a>t检验分析（二分类抑郁类型）</h3><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514141746818.png" alt="image-20250514141746818" style="zoom:50%;" /><p>注：t统计值为负是正相关，即得分越高越可能抑郁。p值小于0.05在统计学上具体参考意义。</p><p>五人格中<strong>抑郁质</strong> <strong>开放性</strong>对是否抑郁判断最有用  其中抑郁组的得分抑郁质得分偏高，开放性评分偏低</p><p><strong>HAMD量表</strong>判断抑郁症效果比PHQ_9效果好</p><p>经济压力和家庭成员参考性一般</p><p><strong>疾病</strong>数量很有参考意义</p><h3 id="相关性分析小结"><a href="#相关性分析小结" class="headerlink" title="相关性分析小结"></a>相关性分析小结</h3><p><strong>疾病</strong>   <strong>HAMD_24  PHQ_9  Openness Neuroticism</strong></p><h2 id="标签数据统计"><a href="#标签数据统计" class="headerlink" title="标签数据统计"></a>标签数据统计</h2><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514155740070.png" alt="image-20250514155740070" style="zoom:67%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514155755009.png" alt="image-20250514155755009" style="zoom:67%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514155808461.png" alt="image-20250514155808461" style="zoom:67%;" /></p><p>二分类就是<strong>没有</strong>和<strong>有</strong></p><p>三分类中将有<strong>没有</strong>划分为了<strong>没有</strong>，<strong>有倾向</strong>，<strong>有</strong></p><p>五分类进一步细分，具体怎么分的看不太出来，在人格信息文件里也没有用上五分类标签</p><h2 id="人格特征统计直方图"><a href="#人格特征统计直方图" class="headerlink" title="人格特征统计直方图"></a>人格特征统计直方图</h2><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>老师这个比赛上面的<strong>谷歌数据集的链接数据有更新吗</strong>？我点开这个链接只看到了训练集的文件。虽然公开网站上显示的是在15号会更新测试集，但是我看群消息里面他们有提到使用了测试集，好像公开了部分测试集，我不知道怎么获取。而且15号公开测试集我也是点开这个谷歌网盘链接里面就自动更新吗？</p><p>草稿：现在对Elderly的人格数据分析的差不多了，具体也知道了人格信息中哪些部分是重要的。</p><p>接下来的任务：</p><ul><li><input disabled="" type="checkbox"> 重新跑代码，跑出baseline的结果</li><li><input disabled="" type="checkbox"> 理清代码的训练集， 验证集，测试集怎么分的（群消息里面提到的测试集是哪里来的？）</li><li><input disabled="" type="checkbox"> 理清生成人格特征的逻辑，重新只使用几个重要的的人格并尝试合适的prompt来生成人格特征</li><li><input disabled="" type="checkbox"> 接入emotion llama，找陈旭东学长问怎么跑这个大模型</li></ul><p>对数据处理部分还没理清楚</p><p>一共就89个人的信息拿来训练，还要随机划分出去十分之一作为验证集，最后训练能用到的也就80个人了。数据量真的少的夸张了这个任务，波动也很大。</p><p>跑一次只要八分钟，我还是和baseline差距很大，群里没有人提到和baseline差距大这个问题，还没有找出来问题在哪</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514173052293.png" alt="image-20250514173052293" style="zoom: 20%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514173115420.png" alt="image-20250514173115420" style="zoom:20%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250514173127580.png" alt="image-20250514173127580" style="zoom:20%;" /></p>]]></content>
    
    
    
    <tags>
      
      <tag>多模态情感计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>毕业答辩</title>
    <link href="/2025/05/09/%E6%AF%95%E4%B8%9A%E7%AD%94%E8%BE%A9/"/>
    <url>/2025/05/09/%E6%AF%95%E4%B8%9A%E7%AD%94%E8%BE%A9/</url>
    
    <content type="html"><![CDATA[<h1 id="本科毕业答辩"><a href="#本科毕业答辩" class="headerlink" title="本科毕业答辩"></a>本科毕业答辩</h1><h1 id="基于随机嵌入的跨模态行人重识别方法"><a href="#基于随机嵌入的跨模态行人重识别方法" class="headerlink" title="基于随机嵌入的跨模态行人重识别方法"></a>基于随机嵌入的跨模态行人重识别方法</h1><h2 id="研究背景、意义与现状"><a href="#研究背景、意义与现状" class="headerlink" title="研究背景、意义与现状"></a>研究背景、意义与现状</h2><h3 id="背景与意义"><a href="#背景与意义" class="headerlink" title="背景与意义"></a>背景与意义</h3><p>行人重识别：行人重识别任务是指在跨摄像头情况下匹配和识别相同的行人个体。  【 任务插图  】 page1</p><p>背景1：随着现在的城市化进程加快，城市人口密度持续上升，各类智能安防系统在城市建设中普及。单纯依赖人工进行图像监控与筛查，已难以满足高效、准确的安全管理需求。</p><p>意义：发展更加高效、智能、可扩展的行人识别技术，成为人工智能在公共安全领域落地应用的重要方向，具有深远的社会价值与现实意义。  page2</p><p>背景2：当前研究多依赖大规模标注数据进行有监督学习，但实际应用中，获取准确身份标签耗时费力，且受数据隐私与采集条件限制，难以大规模获取高质量数据。此外，现有单一图像模态方法难以充分理解和表达目标语义信息，在目标不清晰或缺乏判别特征时表现不佳。  【基于文本的行人重识别任务插图】</p><p>意义：因此，如何在缺乏精确标注信息的前提下，充分利用图像、文本、属性等多模态信息，进行跨模态建模和弱监督学习，已成为当前智能视觉识别技术突破的关键方向之一。 page3</p><h3 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h3><p>行人重识别作为计算机视觉领域的重要研究方向，近年来在深度学习技术的推动下取得了显著进展。深度神经网络凭借其强大的特征学习能力，逐渐成为解决 ReID问题的核心工具，并衍生出多种创新方法，涵盖网络架构设计、损失函数优化、局部特征建模以及注意力机制融合等关键技术方向。</p><p>尽管现有的行人重识别方法在公开数据集上取得了较高的性能，但仍然存在以下不足：数据标注成本高，监督学习依赖大规模标注数据，而获取跨摄像头的大量高质量标签数据代价昂贵；特征匹配的确定性假设，大多数方法基于欧式距离或余弦相似度进行匹配，未考虑数据的概率分布，容易受到噪声影响；模型的泛化能力有限，由于行人外观受环境因素影响较大，训练好的模型在不同场景下的泛化能力往往较差；缺乏有效的不确定性建模，传统的行人特征提取方法往往输出固定的特征向量，而不确定性建模可以通过高斯分布表示特征，提供更加丰富的信息，但目前的研究仍较为初步。page4-5</p><h2 id="方法介绍"><a href="#方法介绍" class="headerlink" title="方法介绍"></a>方法介绍</h2><h3 id="问题定义与模型框架"><a href="#问题定义与模型框架" class="headerlink" title="问题定义与模型框架"></a>问题定义与模型框架</h3><p>在弱监督基于文本的行人重识别任务中是用文本去检索符合描述的行人图像。数据集中图像有对应的文本描述，但是相同行人的不同图像没有行人的身份标注。因此在训练时输入包括文本和图像两个模态的数据，为了能够根据文本检索出对应的行人图像，我们的模型框架设计如图  【模型框架图】</p><p>Page6-8</p><p>使用被大量数据预训练过的具有强大跨模态对齐能力的模型 CLIP 的图像编码器和文本编码器来分别提取图像特征和文本特征，为了解决弱监督没有行人标注的问题，我们首先使用图像编码器提取全部图像特征，然后用图像特征对随机嵌入网络 SENet 进行训练，并实现对图像特征的随机嵌入，用嵌入后的图像特征进行聚类得到图像的伪标签，再将伪标签标注到真实的图像和文本，用有伪标签的图像和文本再来训练 CLIP 的图像编码器和文本编码器。在训练 CLIP的图像编码器和文本编码器的时候采用的是跨模态分布匹配损失（CDM)以及跨模态难样本挖掘损失（CHM)，在训练 SENet 的时候采用的是 KL 损失和重构损失。</p><h3 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a>SENet</h3><p>在使用预训练好的 CLIP 图像编码器提取文本特征后，我们设计了一个随机嵌入网络 Stochastic Embedding Neural Network（SENet）来对图像特征进行随机嵌入。我们采用高斯分布来建模特征，即每个图像的特征被表示为一个均值向量和协方差矩阵。SENet 网络主要分为三部分，编码器、采样层和解码器，如图 3.2 所示。由 CLIP图像编码器得到的 512 维的图像特征被输入到 SENet 中，输出为潜在空间中高斯分布的参数（均值和对数方差），以及重构后的原始特征。【结构图】</p><p>损失函数</p><p>kl损失 重构损失</p><p>page9–10</p><h2 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h2><h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>page11</p><p>【数据集表】</p><p>【评价指标】</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>page12-13</p><p>【实验结果 表】</p><h3 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h3><p>page14</p><p>【检索图示】</p><h2 id="总结与致谢"><a href="#总结与致谢" class="headerlink" title="总结与致谢"></a>总结与致谢</h2><p>page15</p><p>本文针对传统行人重识别方法在特征建模方面忽视不确定性的问题，提出了一种基于不确定性嵌入建模的行人重识别方法。通过引入随机嵌入网络对图像特征进行高斯分布建模，，从而增强了特征表达的鲁棒性和泛化能力。</p><p>未来的研究可进一步探索更高效的概率建模方法。</p><p>我的展示到此结束 ，恳请老师指正。</p>]]></content>
    
    
    
    <tags>
      
      <tag>其它</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MPDD</title>
    <link href="/2025/05/07/MPDD/"/>
    <url>/2025/05/07/MPDD/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="MPDD"><a href="#MPDD" class="headerlink" title="MPDD"></a>MPDD</h1><p>多模态人格感知抑郁症检测</p><h2 id="抑郁症检测任务"><a href="#抑郁症检测任务" class="headerlink" title="抑郁症检测任务"></a>抑郁症检测任务</h2><p>常见信息：视频 音频 文本</p><p>判断是否有抑郁症   分类问题</p><p>二分类  有没有</p><p>三分类 没有 有倾向 有 </p><h2 id="本任务信息"><a href="#本任务信息" class="headerlink" title="本任务信息"></a>本任务信息</h2><p>视频 音频 人格信息</p><p>两个赛道：track1 Elderly    track2 young</p><p>二分类  三分类  五分类</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a><strong>数据集</strong></h2><h3 id="视频特征提取"><a href="#视频特征提取" class="headerlink" title="视频特征提取"></a>视频特征提取</h3><p>用1s或5s分段，每十帧截取一张图片，得到语段级的特征</p><p><em>没看懂是每帧一个特征向量还是每段一个特征向量</em></p><p><em>是一帧得到一个特征向量，然后用一个向量数组来表示这一段的视频特征</em></p><p><em>还是一帧得到一个特征向量，然后融合这些特征向量得到一个一维的特征向量来表示这一段的视频特征</em></p><p>特征提取模型</p><p>ResNet-50 1000</p><p>DenseNet-121 1024(track1)  1000(track2)</p><p>OpenFace 709</p><h3 id="音频特征提取"><a href="#音频特征提取" class="headerlink" title="音频特征提取"></a>音频特征提取</h3><p><strong>Wav2vec</strong>512</p><p><strong>MFCCs</strong>64</p><p><strong>OpenSmile</strong>6373</p><h3 id="人格特征提取"><a href="#人格特征提取" class="headerlink" title="人格特征提取"></a>人格特征提取</h3><p> GLM3生成人格描述</p><p>roberta-large 根据人格描述生成人格特征1024维</p><h3 id="代码中的具体data处理流程"><a href="#代码中的具体data处理流程" class="headerlink" title="代码中的具体data处理流程"></a>代码中的具体data处理流程</h3><p>Elderly  118人   即118个id</p><p>两种label的JSON文件</p><h4 id="有人格信息的Label"><a href="#有人格信息的Label" class="headerlink" title="有人格信息的Label"></a>有人格信息的Label</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507182603763.png" alt="image-20250507182603763" style="zoom:33%;" /><h4 id="无人格信息的label"><a href="#无人格信息的label" class="headerlink" title="无人格信息的label"></a>无人格信息的label</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507182754719.png" alt="image-20250507182754719" style="zoom:33%;" /><p><em>不同分段的视频和音频但是对应的抑郁分类都是相同的？</em></p><p><em>缺少的一些id就是被拿去后面作为测试集才放出来吗？</em></p><p><em>音频视频的原文件在哪？可以 根据原文件造数据吗？</em></p><h4 id="人格特征"><a href="#人格特征" class="headerlink" title="人格特征"></a>人格特征</h4><p>根据上面提到的有人格信息的label首先用GLM生成文本描述，然后使用roberta-large生成人格特征。</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507185141082.png" alt="image-20250507185141082"></p><p>实际89人</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507185237540.png" alt="image-20250507185237540"></p><p>人格特征1024维</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507190702810.png" alt="image-20250507190702810"></p><h4 id="音频特征"><a href="#音频特征" class="headerlink" title="音频特征"></a>音频特征</h4><p>1s分段的为例</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507192714970.png" alt="image-20250507192714970"><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507192936801.png" alt="image-20250507192936801"></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507192809664.png" alt="image-20250507192809664"></p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507192828436.png" alt="image-20250507192828436" style="zoom:50%;" /><p><em>也就是一个npy对应的里面存放的11s的音频特征？</em></p><h4 id="视觉特征"><a href="#视觉特征" class="headerlink" title="视觉特征"></a>视觉特征</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507193444891.png" alt="image-20250507193444891" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507193508158.png" alt="image-20250507193508158" style="zoom:33%;" /><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507193848460.png" alt="image-20250507193848460" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507193827618.png" alt="image-20250507193827618" style="zoom:33%;" /></p><p>一个npy里17s的图像特征</p><h2 id="baseline-model"><a href="#baseline-model" class="headerlink" title="baseline model"></a>baseline model</h2><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250507211315774.png" alt="image-20250507211315774"></p><p>另外还有一个分类头netEmoCF用来反向传播时使用Focal  loss来训练模型，模型训练一共使用两个损失，一个交叉熵损失一个Focal loss</p><h2 id="track1-baseline"><a href="#track1-baseline" class="headerlink" title="track1 baseline"></a>track1 baseline</h2><table><thead><tr><th>Length</th><th>Task Type</th><th>Audio Feature</th><th>Visual Feature</th><th>w&#x2F; PF (W_F1&#x2F;U_F1)</th><th>w&#x2F; PF (W_Acc.&#x2F;U_Acc.)</th><th>w&#x2F;o PF (W_F1&#x2F;U_F1)</th><th>w&#x2F;o PF (W_Acc.&#x2F;U_Acc.)</th></tr></thead><tbody><tr><td>1s</td><td>Binary</td><td>mfcc</td><td>openface</td><td>85.71 &#x2F; 79.13</td><td>85.40 &#x2F; 84.62</td><td>82.60 &#x2F; 70.89</td><td>69.37 &#x2F; 83.33</td></tr><tr><td>1s</td><td>Ternary</td><td>opensmile</td><td>resnet</td><td>56.48 &#x2F; 55.64</td><td>55.49 &#x2F; 56.41</td><td>54.35 &#x2F; 49.14</td><td>48.93 &#x2F; 55.13</td></tr><tr><td>1s</td><td>Quinary</td><td>opensmile</td><td>densenet</td><td>66.26 &#x2F; 46.66</td><td>45.79 &#x2F; 69.23</td><td>63.85 &#x2F; 44.00</td><td>42.45 &#x2F; 66.67</td></tr><tr><td>5s</td><td>Binary</td><td>opensmile</td><td>resnet</td><td>81.75 &#x2F; 72.37</td><td>75.40 &#x2F; 80.77</td><td>77.90 &#x2F; 66.15</td><td>67.94 &#x2F; 76.92</td></tr><tr><td>5s</td><td>Ternary</td><td>wav2vec</td><td>openface</td><td>58.22 &#x2F; 59.37</td><td>59.62 &#x2F; 57.69</td><td>50.88 &#x2F; 47.59</td><td>46.58 &#x2F; 50.00</td></tr><tr><td>5s</td><td>Quinary</td><td>mfcc</td><td>densenet</td><td>75.62 &#x2F; 58.40</td><td>57.71 &#x2F; 78.21</td><td>73.49 &#x2F; 56.83</td><td>56.98 &#x2F; 75.64</td></tr></tbody></table><p><em>跑出来效果差很多？</em></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20250508090347147.png" alt="image-20250508090347147"></p><h2 id="track2-baseline"><a href="#track2-baseline" class="headerlink" title="track2 baseline"></a>track2 baseline</h2><table><thead><tr><th>Length</th><th>Task Type</th><th>Audio Feature</th><th>Visual Feature</th><th>w&#x2F; PF (W_F1&#x2F;U_F1)</th><th>w&#x2F; PF (W_Acc.&#x2F;U_Acc.)</th><th>w&#x2F;o PF (W_F1&#x2F;U_F1)</th><th>w&#x2F;o PF (W_Acc.&#x2F;U_Acc.)</th></tr></thead><tbody><tr><td>1s</td><td>Binary</td><td>wav2vec</td><td>openface</td><td>59.96 &#x2F; 59.96</td><td>63.64 &#x2F; 63.64</td><td>55.23 &#x2F; 55.23</td><td>56.06 &#x2F; 56.06</td></tr><tr><td>1s</td><td>Ternary</td><td>mfcc</td><td>densenet</td><td>51.86 &#x2F; 51.62</td><td>49.66 &#x2F; 51.52</td><td>47.95 &#x2F; 43.72</td><td>42.63 &#x2F; 48.48</td></tr><tr><td>5s</td><td>Binary</td><td>opensmile</td><td>resnet</td><td>62.11 &#x2F; 62.11</td><td>62.12 &#x2F; 62.12</td><td>60.02 &#x2F; 60.02</td><td>60.61 &#x2F; 60.61</td></tr><tr><td>5s</td><td>Ternary</td><td>mfcc</td><td>densenet</td><td>48.18 &#x2F; 41.31</td><td>41.71 &#x2F; 50.00</td><td>42.82 &#x2F; 39.38</td><td>41.29 &#x2F; 42.42</td></tr></tbody></table><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><p>数据    模型   损失</p><p>数据方面:怎么去猜测试集的数据，现在数据集里面是提取完的视觉和音频特征，视频和音频的原文件也没有看到</p><p>模型方面：人格特征是直接拼接到transformer输出的视觉和音频特征融合特征，直接cat会不会太简单了，会不会也和视觉音频特征融合一下比较好</p><p>损失方面：现在用的是一个分类常用的交叉熵损失加上一个帮助区分难分样本的focal loss，感觉可以了</p>]]></content>
    
    
    
    <tags>
      
      <tag>多模态情感计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>icpg代码加入随机嵌入模块</title>
    <link href="/2025/04/22/icpg%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%85%A5%E9%9A%8F%E6%9C%BA%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9D%97/"/>
    <url>/2025/04/22/icpg%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%85%A5%E9%9A%8F%E6%9C%BA%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9D%97/</url>
    
    <content type="html"><![CDATA[<ul><li><p><input checked="" disabled="" type="checkbox"> 修改icpg模型结构</p><p>将嵌入网络模块添加到icpg结构中</p></li><li><p><input disabled="" type="checkbox"> 修改forward函数</p></li><li><p><input disabled="" type="checkbox"> 修改损失函数</p></li><li><p><input disabled="" type="checkbox"> 修改训练脚本</p></li><li><p><input disabled="" type="checkbox"> 修改配置文件</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习 代码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>安卓端自动跳广告脚本开发</title>
    <link href="/2025/03/14/%E5%AE%89%E5%8D%93%E7%AB%AF%E8%87%AA%E5%8A%A8%E8%B7%B3%E5%B9%BF%E5%91%8A%E8%84%9A%E6%9C%AC%E5%BC%80%E5%8F%91/"/>
    <url>/2025/03/14/%E5%AE%89%E5%8D%93%E7%AB%AF%E8%87%AA%E5%8A%A8%E8%B7%B3%E5%B9%BF%E5%91%8A%E8%84%9A%E6%9C%AC%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>技术 开发 安卓端 apk 脚本 自动化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2025/03/05/Untitled/"/>
    <url>/2025/03/05/Untitled/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2025.2-2025.3计划</title>
    <link href="/2025/02/16/2025-2-2025-3%E8%AE%A1%E5%88%92/"/>
    <url>/2025/02/16/2025-2-2025-3%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<p>2025.2.15已返校，大学本科的最后 一个学期了。</p><p>算是保研后的一个gap year了，我醒悟的算是比较晚了，到了这个时候才真正意义上的思考未来，以前都是虚无缥缈的假想，现在是真的考虑自己的未来了。以前高贵的说自己不需要钱，每个月的消费完全可以很低，物欲很低，但现在看那些只是省下来的小钱，实际上永远不会缺少对钱的需求。</p><p>至少最短期的目标是我要存钱买车买房，我的占有欲其实是很强的，很多东西希望是切实属于我自己的，独属于我。</p><p>考虑的自己的未来可能的选择，按可能性由低到高进行列举吧</p><ol><li>读研期间努力科研，发个B或者A刊，反正好一些的，对多模态有深入了解，进一步申博，拼到985去，毕业后进高校当老师。</li><li>研究生期间水一水，研一把c刊一发，满足毕业要求，研二研三老实进公司，选个开发岗，一直打灰，毕业后留公司</li><li>研究生期间发C刊，研二研三边摸鱼边学习形策申论，准备公务员考试</li><li>研究生考完教资，收集物理高中教师招聘信息，应聘高中物理老师</li><li>研究生努力发论文，边学习嵌入式相关的知识，做嵌入式相关的项目，研二研三努力往嵌入式方向靠，从事嵌入式相关岗位。</li></ol><p>接下来的一个月</p><ul><li>准备教资</li><li>准备毕设</li><li>学习数电模电基础知识</li><li>出去旅游，结交朋友</li><li>向enfj靠拢</li><li>找个新的家教</li><li>做视频，做有意思的硬件项目</li></ul><p>涨球涨球涨球！华物杯看我大展身手:)</p>]]></content>
    
    
    
    <tags>
      
      <tag>日常</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>研究生三年规划</title>
    <link href="/2025/02/16/%E7%A0%94%E7%A9%B6%E7%94%9F%E4%B8%89%E5%B9%B4%E8%A7%84%E5%88%92/"/>
    <url>/2025/02/16/%E7%A0%94%E7%A9%B6%E7%94%9F%E4%B8%89%E5%B9%B4%E8%A7%84%E5%88%92/</url>
    
    <content type="html"><![CDATA[<p>根据你的背景、兴趣和困惑，我为你梳理了以下几个方向的建议，希望能帮助你找到适合自己的发展路径：</p><hr><h3 id="一、发挥兴趣优势：硬件-电子工程方向"><a href="#一、发挥兴趣优势：硬件-电子工程方向" class="headerlink" title="一、发挥兴趣优势：硬件&#x2F;电子工程方向"></a><strong>一、发挥兴趣优势：硬件&#x2F;电子工程方向</strong></h3><p>你的兴趣在电路设计、动手实践，且物理基础扎实，这是转型硬件领域的核心优势。以下是具体建议：</p><ol><li><strong>补充专业知识</strong>  <ul><li><strong>自学基础课程</strong>：通过慕课（如Coursera、edX）学习《模拟电路》《数字电路》《嵌入式系统》等课程，重点掌握PCB设计（如Altium Designer）、单片机开发（Arduino&#x2F;STM32）。  </li><li><strong>实践项目</strong>：从简单电路开始（如LED控制、传感器应用），逐步参与开源硬件项目（如树莓派扩展板设计），积累作品集。</li></ul></li><li><strong>利用现有资源转型</strong>  <ul><li><strong>调整研究方向</strong>：尝试与导师沟通，将行人重识别课题与硬件结合（例如开发基于嵌入式设备的识别系统），或争取参与实验室的硬件相关课题。  </li><li><strong>联合培养机会</strong>：在东风商用车技术中心期间，主动接触车载电子、自动驾驶硬件模块等项目，积累工业级经验。</li></ul></li><li><strong>就业准备</strong>  <ul><li><strong>实习</strong>：瞄准武汉的硬件企业（如长江存储、烽火通信）、智能硬件公司或车企（如东风汽车电子部门），争取实习机会。  </li><li><strong>证书</strong>：考取《电子设计工程师》等证书提升竞争力。</li></ul></li></ol><hr><h3 id="二、软硬件结合方向：嵌入式开发-物联网"><a href="#二、软硬件结合方向：嵌入式开发-物联网" class="headerlink" title="二、软硬件结合方向：嵌入式开发&#x2F;物联网"></a><strong>二、软硬件结合方向：嵌入式开发&#x2F;物联网</strong></h3><p>计算机背景与硬件兴趣的结合点，适合INFP的创造性需求：</p><ul><li><strong>学习路径</strong>：掌握Linux驱动开发、RTOS实时系统（如FreeRTOS），熟悉通信协议（CAN总线、MQTT）。  </li><li><strong>职业选择</strong>：嵌入式软件工程师、物联网系统架构师，武汉的光电子和汽车产业对此类人才需求较大。</li></ul><hr><h3 id="三、职业路径备选方案"><a href="#三、职业路径备选方案" class="headerlink" title="三、职业路径备选方案"></a><strong>三、职业路径备选方案</strong></h3><ol><li><strong>教育行业</strong>  <ul><li><strong>优势</strong>：师范背景+技术基础，可应聘武汉的中学信息技术&#x2F;通用技术教师，或高职院校讲师。  </li><li><strong>风险应对</strong>：选择国际化学校或民办学校，通常对性取向包容度更高；积累教学经验后可通过在线教育兼职增加收入。</li></ul></li><li><strong>考公考编</strong>  <ul><li><strong>推荐岗位</strong>：技术类岗位（如工信局、质检中心）或高校行政岗，人际关系压力较小。  </li><li><strong>地域选择</strong>：武汉作为新一线城市，体制内环境相对宽松，可优先考虑开发区单位（如东湖高新区）。</li></ul></li><li><strong>过渡性选择</strong>  <ul><li><strong>短期开发岗</strong>：进入车企&#x2F;硬件企业的软件开发部门（如车载系统开发），逐步内部转岗至硬件团队。  </li><li><strong>副业探索</strong>：通过硬件DIY教程创作、技术测评视频等自媒体实现兴趣变现，为经济独立铺路。</li></ul></li></ol><hr><h3 id="四、心理与生活建议"><a href="#四、心理与生活建议" class="headerlink" title="四、心理与生活建议"></a><strong>四、心理与生活建议</strong></h3><ol><li><strong>经济独立计划</strong>  <ul><li><strong>硬件接单</strong>：在闲鱼&#x2F;极客论坛承接小型电路设计项目，初期报价可低于市场价（如500元&#x2F;单）积累口碑。  </li><li><strong>技能变现</strong>：利用师范背景做家教（物理&#x2F;信息技术课时费约80-150元&#x2F;小时）。</li></ul></li><li><strong>家庭关系处理</strong>  <ul><li><strong>阶段性策略</strong>：就业初期以“工作忙”为由减少家庭干涉，同时建立“好友支持圈”（加入武汉本地LGBTQ+社群）。  </li><li><strong>长远规划</strong>：争取进入外企或科技公司（如武汉的思科、IBM分公司），通常企业文化更包容。</li></ul></li></ol><hr><h3 id="五、行动时间表"><a href="#五、行动时间表" class="headerlink" title="五、行动时间表"></a><strong>五、行动时间表</strong></h3><ul><li><strong>研一（当前）</strong>：  <ul><li>3个月内完成《模拟电路》慕课学习+设计第一个PCB作品。  </li><li>与导师协商研究方向调整可能性。</li></ul></li><li><strong>研二（东风联合培养）</strong>：  <ul><li>主动申请参与车载电子相关项目，积累工业经验。  </li><li>考取Altium Designer官方认证。</li></ul></li><li><strong>研三秋招</strong>：  <ul><li>投递硬件工程师岗位（优先选择有明确培养体系的企业）。  </li><li>同步准备教师编制考试（保底选择）。</li></ul></li></ul><hr><p>你的核心优势在于<strong>动手能力+跨领域可能性</strong>，不必被当前专业限制。硬件行业更看重项目经验而非纯理论知识，通过6-12个月的针对性积累完全可能成功转型。武汉的光电子、汽车产业链完善，且生活成本可控，是适合你长期发展的城市。保持对兴趣的坚持，经济独立和职业成就感会为你赢得更多自主权。</p>]]></content>
    
    
    
    <tags>
      
      <tag>规划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cursor+vscode+ssh连不上服务器</title>
    <link href="/2024/12/27/cursor-vscode-ssh%E8%BF%9E%E4%B8%8D%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <url>/2024/12/27/cursor-vscode-ssh%E8%BF%9E%E4%B8%8D%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<p>bug记录</p><p>使用cursor+vscode+ssh远程连接服务器一直停留在downloading vscode server这一步。</p><p>出现bug的几个情况和原因</p><p>1.一直在downloading vscode server就是没有开始下载</p><p>本地网不好，没有翻墙</p><p>解决方法：不知道怎么好的网，然后cursor方面是在settings里面去重新import一下vscode的配置，可能是cursor的设置里面的代理某些位置有问题，尝试卸载重新下载，最后是重新import配置好的。</p><p>不过现在还是一直有一个问题，cursor里面的vscode不能下载插件，加载不出来，但如果不能联网，代码提示prompt这些功能又是好的，好奇怪</p><p>2.反复downloading vscode server，每次解压缩都失败了</p><p>这个没办法，服务器的空间不够，每次这些配置都是默认放在了&#x2F;home&#x2F;yyh下面，但是家目录下根本没有空间了。</p><p>解决方法：把配置tmp等文件迁移到&#x2F;mnt&#x2F;disk1&#x2F;yyh下，并且把链接指过来</p><p><code>mkdir -p /mnt/disk1/yyh/cursor-server</code></p><p><code>mv /home/yyh/.cursor-server /mnt/disk1/yyh/cursor-server</code></p><p><code>ln -s /mnt/disk1/yyh/cursor-server /home/yyh/.cursor-server</code></p><p>ps:我以为既然是从vscode直接导入的配置到cursor，cursor的配置就不用再下载了，没想到还是需要下载到服务器里。</p><p>折腾了一天半了，真浪费时间找这个bug</p><p>【cursor是ai+vscode vscode加上copilot是vscode+ai】顺序不同，体验不同</p><p>vscode和cursor居然可以同时两个脸上服务器，同时改代码，不卡同一用户同时用ssh登录。</p><p>不过想想也不能卡，我有时也会同时用终端登一下用scp传个文件，这也是ssh登录的。</p>]]></content>
    
    
    
    <tags>
      
      <tag>bug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蒙特卡洛近似计算</title>
    <link href="/2024/12/21/Approximation/"/>
    <url>/2024/12/21/Approximation/</url>
    
    <content type="html"><![CDATA[<p>Monte Carlo Approximation</p><p>方法：随机抽样来估计数学问题解</p><p>核心思想：通过随机生成大量样本来近似计算复杂的积分或期望值</p><p>原理：大数定理，用样本估计整体</p><p>应用：积分计算、期望计算</p><p>embedding</p><p>传统方法嵌入就是嵌入为一个维数固定的向量</p><p>传统的嵌入方法，（确定嵌入，点嵌入）计算嵌入后的z1 z2的距离经典的就是使用欧几里得距离的对比损失，然后在HIB这篇文章中对对比损失改进了一下，修改成了软对比。</p><p>现在很流行这种，<strong>把离散的计算变得连续</strong>。这个趋势也是符合自然规律得，是很合理得，因为毕竟周围环境中得东西实际上都是连续得。</p><p>离散化很容易，一般打上的标签就都是离散的，数据处理时也可以通过设置一个阈值，区分开来离散化。</p><p>加权是一种变得连续的方法，之前得krnn那篇文章中，</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241221193550678.png" alt="image-20241221193550678" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241221193612160.png" alt="image-20241221193612160" style="zoom:50%;" /><p>把图片相关性编码成为向量就有由hard到soft的过程，所以由距离给权重<br>$$<br>e^{-d}<br>$$<br>是一个很好用的函数</p><p>还有sigmoid也是个好用的函数</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241221194000052.png" alt="image-20241221194000052" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241221194131543.png" alt="image-20241221194131543" style="zoom:30%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241221194535940.png" alt="image-20241221194535940" style="zoom:33%;" /><p>基于概率的嵌入是嵌入为一个不确定的概率分布<br>$$</p><p>$$</p><p>$$</p><p>$$</p><p>在modeling uncertainty with hedged instance embedding这篇文章中的概率嵌入部分就有：</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241221190650689.png" alt="image-20241221190650689"><br>$$<br>\sigma(x)&#x3D;\frac{1}{1+e^{-x}}<br>$$</p><p>好了，第一篇论文得前面点嵌入部分基本都看懂了，公式也比较熟悉了。下课，打球！</p>]]></content>
    
    
    
    <tags>
      
      <tag>概率嵌入</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ML的发展历史</title>
    <link href="/2024/10/29/ML%E7%9A%84%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/"/>
    <url>/2024/10/29/ML%E7%9A%84%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/</url>
    
    <content type="html"><![CDATA[<p>所以一个模型就相当于一个公式，这个公式可以对不同的输入计算不同的输出，公式里面有很多参数，模型的具体组织形式是很多个节点形成一个层，然后层与层连接形成网络，节点有权重w和偏置b，如果层与层间直接连接就相当于线性的了，但是如果加上激活函数就可以是非线性的了。然后通过预测结果与实际结果间的误差，使用反向传播算法来训练模型，是这样吗</p>]]></content>
    
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer</title>
    <link href="/2024/10/29/Transformer/"/>
    <url>/2024/10/29/Transformer/</url>
    
    <content type="html"><![CDATA[<p>classic model-Transformer</p>]]></content>
    
    
    
    <tags>
      
      <tag>paper reading</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征空间</title>
    <link href="/2024/10/29/%E8%B6%85%E5%B9%B3%E9%9D%A2/"/>
    <url>/2024/10/29/%E8%B6%85%E5%B9%B3%E9%9D%A2/</url>
    
    <content type="html"><![CDATA[<p>representation learning</p><p>论文[<a href="https://yiyibooks.cn/arxiv/2005.10242v10/index.html">2005.10242] Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere</a></p><p><a href="D:\Downloads\多模态机器学习.pdf">D:\Downloads\多模态机器学习.pdf</a></p><p>数学知识</p><p>超hyper的意思就是嵌入在比自己高一维的空间里，比如在三维空间里定义一个二维平面，在一个二维空间里定义一个一维直线。</p><p>嵌入在n维空间里的n-1维子空间。</p><p>hyper这个词很有意思啊，科幻里面很多这种概率，三体里的三体人，高一维的视角就和开了上帝视角一样。星际穿越等等，很多科幻电影都有这种思想。</p><p>你在一维里定义的一个直线，从直线上的一点到另一点，可能弯曲在二维空间里，在二维视角下完全有更近的走法。</p><p>超曲面hypersurface</p><p>n维空间中嵌入一个n-1维的曲面，可以是开放的，可以是封闭的，可以是无曲率的（平面），可以是有曲率的。</p><p>超平面hyperplane</p><p>一个n维空间切开分成两半，分成两个半空间，形成n-1维的子空间。</p><p>n维空间中的超平面的线性方程表达式<br>$$<br>a_1x_1+a_2x_2+…+a_nx_n+b&#x3D;0<br>$$<br>一个n维空间中多了一个约束方程，就降了一维（线性代数知识）</p><p>这个方程表达的就是嵌入在n维空间里的超平面，这个超平面的法向量是(a1,…an)，b是偏置项</p><p>edg:三维空间里的2x+3y+4z&#x3D;0表示的是一个二维平面，这个平面就是嵌入在三维空间里的超平面。</p><p>应用：超平面用在分类问题<strong>支持向量机SVM中，将不同类别的数据点分离开，选择合适的超平面，最大化不同类别的间隔，提高分类问题的准确性</strong>（具体细节待学习）</p><p>超球面hypersphere</p><p>另一种特殊的超曲面，超球面hypersphere是n维球体n-sphere的表面或边界，一维球面是二维空间里的圆，二维球面是三维空间里球体的表面，高于二维的球面称为超球面。</p><p>一个n维空间，定义一个<br>$$<br>x_1^2+x_2^2+x_3^2+…+x_n^2&#x3D;R^2<br>$$<br>的n-1维的球面就是超球面，补一点，这就算是欧几里得距离公式。</p><p>现在特征空间很多都用超球面，对比学习里面正负样本就是在hypersyphere上，拉远和拉近，超球面上的特征分布讲究alignment和uniformity,详见论文图</p><p><strong>距离公式</strong></p><p>欧几里得距离Euclidean distance</p><p>空间中的绝对距离，二维平面里<br>$$<br>d&#x3D;\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}<br>$$<br>也称欧式距离。</p><p>余弦距离cosine similarity<br>$$<br>cosine&#x3D;\frac{\boldsymbol{A\cdot{B}}}{||\boldsymbol{A}||||\boldsymbol{B}||}<br>$$<br>余弦距离非常常用，已经看过很多次了，因为现在很多都是嵌入在超球面的，而超球面都是norm后的标准球面，空间绝对距离没有意义了，可以只看角度</p><p>曼哈顿距离manhatten distance<br>$$<br>d&#x3D;|x_2-x_1|+|y_2-y_1|<br>$$<br>切比雪夫距离Chebyshev Distance<br>$$<br>d&#x3D;max(|x_2-x_1|,|y_2-y1|)<br>$$<br>闵可夫斯基距离（Minkowski Distance）： 闵可夫斯基距离是欧几里得距离和曼哈顿距离的一般化</p><p>马氏距离：考虑了数据的协方差，是欧几里得距离的一种加权版本</p>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>乒乓日记3</title>
    <link href="/2024/10/25/%E4%B9%92%E4%B9%93%E6%97%A5%E8%AE%B03/"/>
    <url>/2024/10/25/%E4%B9%92%E4%B9%93%E6%97%A5%E8%AE%B03/</url>
    
    <content type="html"><![CDATA[<p>yesterday evening played pingpang with xiaomi, a fulfilling day again. particularly, my forehand improved and can loop against backspin stably. yeah, that’s perfect!</p><p>still, my backhand’s problem is still evident, can’t defend the topspin balls. and my backhand push is not as good as my forehand. At the moment, I’m more proficient at slicing the ball, but if it’s a strong topspin, i easily make mistakes when chopping. So i really need to improve my backhand now, at least to improve my backhand pushing back ball. even if i can’t initiate a high quality, i should be able to create opportunities for my forehand. After all, it’s about gaining the upper hand with the backhand and scoring with the forehand.</p>]]></content>
    
    
    
    <tags>
      
      <tag>乒乓球</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>乒乓日记2</title>
    <link href="/2024/10/23/%E4%B9%92%E4%B9%93%E6%97%A5%E8%AE%B02/"/>
    <url>/2024/10/23/%E4%B9%92%E4%B9%93%E6%97%A5%E8%AE%B02/</url>
    
    <content type="html"><![CDATA[<p>Luckily i havn’t went home today, xiaofang sis invited me to play table tennis this afternoon. This is really an exciting news for me cause i have been looking forward to this since this new term. Well, this time my forehand gave a good performance, my backhand was just as before, a poor hit rate, but exceeded expectations a couple of times.</p><p>sis said she could come more frequently to play the ball during this time, this is awesome! oops.</p><p>i am really happy to hear this news.</p><p>a nice day playing ball again.</p><p>by the way, i have bought some bicycle sticker home and maybe this week i will ride bike home and decorate my bike. i will get a nearly new bike then, can’t help being excited when think of this idea.</p>]]></content>
    
    
    
    <tags>
      
      <tag>乒乓球</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>进组第一次组会</title>
    <link href="/2024/10/23/%E8%BF%9B%E7%BB%84%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%BB%84%E4%BC%9A/"/>
    <url>/2024/10/23/%E8%BF%9B%E7%BB%84%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%BB%84%E4%BC%9A/</url>
    
    <content type="html"><![CDATA[<p>a sleepy morning, yesterday i sleep at half past two o’clock and then i woke up cause i have drunk so much water and want to go to the bathroom. only five more hours or so for me to sleep.</p><p>but the group meeting is not bad, the senior sister have given a clear presentation and i can almost get 70 percent content of it.</p><p>Presenter :MaMengyuan</p><p>Attender :LiuSIjia(also like me , a Master of Engineering)</p><p>Recording:</p><p>it is all about sentiment analysis, clearly speaking is about depression detection.</p><p>[ppt](F:\组会\第一次组会\Multimodal  Depression Detection Based on Vlog.pptx)</p><p>Problem:</p><p>here is where i don’t understand much.</p><p>why this is called six dimesion?</p><p>答：head pose 是6维向量的原因是空间中 的坐标xyz是三维的，加上旋转需要三个角度表示 yaw, pitch, roll和高数里面的求球体的三重积分思路是一样的。因此加起来是6维。</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241023112908856.png" alt="image-20241023112908856"></p><p>D-vlog(论文还可以是创立一个数据集然后再提出一个模型吗，这感觉有点亏啊，感觉建立一个数据集的工作量就够了，咋还得再提出一个方法)</p><p>LMVD（large-scale multimodel vlog dataset)</p><p>数据规模和来源，各视频平台1475个subjects参与者和1823个samples样本，一共214小时数据</p><p>多模态：音频模态A+视频模态V</p><p>what is lstm, transformer?</p><p>remember this normalization trick</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20241023113041775.png" alt="image-20241023113041775"></p><p>why the count of frame L is set as 300, 300 is 300&#x2F;25 seconds?</p>]]></content>
    
    
    
    <tags>
      
      <tag>组会</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>乒乓日记</title>
    <link href="/2024/10/22/%E4%B9%92%E4%B9%93%E6%97%A5%E8%AE%B0/"/>
    <url>/2024/10/22/%E4%B9%92%E4%B9%93%E6%97%A5%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>three people play in turn</p><p>tonight play table tennis with chenzixin and the master. the performance of my forehand is not bad, but the backhand really underperformed, it has missed so many balls and even though made the ball to the table, the quality was quite poor and i was easily caught off guard by a sharp angle to my forehand side.</p><p>so i really need to improve my backhand against topsin.</p><p>a good night, intersting, having a good mood.</p><p>fight on. ^_^</p>]]></content>
    
    
    
    <tags>
      
      <tag>乒乓球</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>骑行计划</title>
    <link href="/2024/10/22/%E9%AA%91%E8%A1%8C%E8%AE%A1%E5%88%92/"/>
    <url>/2024/10/22/%E9%AA%91%E8%A1%8C%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<p>These days the weather is not bad, no sun and cool. This is a good chance for me to achieve my long expected goal. riding back home!!! this is awesome. </p><p>It will take 5 hours or so. I would pack three bottles of yuanqisenlin of 900ml.</p><p>so today i will repair my bike and put on the camera holder. tonight i will go to play pingpang and tomorrow after having anticipated the weekly group meeting, i then will set up at about eleven o’clock after having the dinner, some pancake, making sure i will not feel hungry in the journey.</p><p>i can’t help thing how exciting it will be!</p><p>i will record this journey using my camera, there will also be so many sights. great!</p><p>supplement </p><p>10.23.11:04</p><p>well today is a good day, a gentle sun casting a warm glow, but regrettably i was so sleepy cause i go to bed so late yesterday. i have tried so many times to go to bed early but fail all the time.i promise i will gradually go to bed earlier. </p><p>so i have to put off the riding schedule, may be the yuandan i will do this, but i will do this for sure in this year, cause this is the last year during my undergraduate life. i can’t make it a regret for me not having a impulsive thing in my college life.</p><p>and before my riding journey, i will repair my bike, mount the camera holder on the bicycle, and decorate it in cool white sticker.</p>]]></content>
    
    
    
    <tags>
      
      <tag>big thing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pingpangpick</title>
    <link href="/2024/10/20/pingpangpick/"/>
    <url>/2024/10/20/pingpangpick/</url>
    
    <content type="html"><![CDATA[<p>idea:在看论文代码的时候突然想自己完完整整用Pytorch写一套模型代码来使用。正好学的很多视觉模型，来训练一个识别乒乓球的模型。之前做过一个建议机械臂的项目，然后还买了一套小车没有使用过，模型运行在arduio上肯定是不行的，正好有废弃手机利用一下。</p><p>material:一部废弃手机，一个亚克力小车，一个机械钳，一个arduino，然后其它细节元器件</p><p>软件部分：训练好一个识别乒乓球的视觉模型，并且开发一个手机app，把模型部署到手机上，并且想办法把手机和单片机建立通信，蓝牙通信，小车端接受手机指令，控制车轮电机，机械钳舵机</p><p>硬件部分：小车配置必要传感器，摄像头，距离传感器，辅助乒乓球的定位与识别</p><p>设计电源部分，计算功率，能够有足够续航</p><p>说干就干</p><p>step1 训练模型</p><p>完了好像不需要使用深度学习模型，opencv就可以了</p><p>step2 开发app</p>]]></content>
    
    
    
    <tags>
      
      <tag>电子作品</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>prompt engineer</title>
    <link href="/2024/10/12/promptengineer/"/>
    <url>/2024/10/12/promptengineer/</url>
    
    <content type="html"><![CDATA[<p><em>论文阅读清单</em></p><ul><li><input checked="" disabled="" type="checkbox"> Learning Transferable Visual Models From Natural Language Supervision</li><li><input checked="" disabled="" type="checkbox"> Learning to Prompt for Vision-Language Models</li><li><input disabled="" type="checkbox"> Conditional Prompt Learning for Vision-Language Models </li><li><input disabled="" type="checkbox"> A Pedestrian is Worth One Prompt: Towards Language Guidance Person Re-Identification</li></ul><p>复现论文</p><p>A Pedestrian is Worth One Prompt: Towards Language Guidance Person Re-Identification</p>]]></content>
    
    
    
    <tags>
      
      <tag>reid</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/09/19/%E6%AF%8F%E6%97%A5%E5%AE%89%E6%8E%92/"/>
    <url>/2024/09/19/%E6%AF%8F%E6%97%A5%E5%AE%89%E6%8E%92/</url>
    
    <content type="html"><![CDATA[<ul><li><input checked="" disabled="" type="checkbox"> 收集实习信息</li><li><input disabled="" type="checkbox"> 整理桌面所有文件 35min</li><li><input disabled="" type="checkbox"> 整理所有博客2h</li><li><input disabled="" type="checkbox"> 制作简历2h</li><li><input disabled="" type="checkbox"> 出考研资料</li><li><input disabled="" type="checkbox"> 为东风的面试做准备，主要复盘人工智能方面的知识，我打算面人工智能方向的课题</li></ul><p>this weekend</p><p>go back home, repair my holocubic, and add an additional function, maybe connect to the xiaomi band                                                             watch and get     the daily step count. oh no , another task , repair my keyboard, the blank key sometimes not work. </p><p>all in all</p><p>小米  </p><p>京东</p><p>科大讯飞（小小坚定了我学人工智能方向）</p><p>想学</p><p>1.模拟电路</p><p>2.数字电路</p><p>3.绘制pcb板</p><p>4.机器学习</p><p>5.统计学</p><p>i have made up my mind that i will major in artificial intelligence, and make hardware a kind of hobby，cuz  life cannot be full of work, aslo something novel and you are interested and can give you a highly sense of accomplishment.</p><p>i will surely continue my pingpang practice, hope i can become a high level amateur.</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>软件工程期末复习</title>
    <link href="/2024/06/25/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"/>
    <url>/2024/06/25/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="第1章-软件工程基础"><a href="#第1章-软件工程基础" class="headerlink" title="第1章 软件工程基础"></a>第1章 软件工程基础</h1><h4 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h4><p>软件&#x3D;程序+数据+文档</p><p>软件对比硬件的故障曲线</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625123356168.png" alt="image-20240625123356168" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625123406956.png" alt="image-20240625123406956" style="zoom:33%;" /></p><p>系统软件  支撑软件 应用软件</p><h4 id="软件危机"><a href="#软件危机" class="headerlink" title="软件危机"></a>软件危机</h4><p>计算机软件在<strong>开发</strong>和<strong>维护</strong>过程中遇到的一系列问题</p><h4 id="软件工程"><a href="#软件工程" class="headerlink" title="软件工程"></a>软件工程</h4><p>三要素：方法、工具和过程</p><h4 id="软件生命周期"><a href="#软件生命周期" class="headerlink" title="软件生命周期"></a>软件生命周期</h4><p>从提出软件产品开始，直到该软件产品被淘汰的全过程</p><ol><li>可行性研究与计划</li><li>需求分析</li><li>总体设计</li><li>详细设计</li><li>实现</li><li>集成测试</li><li>确认测试</li><li>使用和维护</li></ol><h4 id="软件过程模型（软件生命周期模型）"><a href="#软件过程模型（软件生命周期模型）" class="headerlink" title="软件过程模型（软件生命周期模型）"></a>软件过程模型（软件生命周期模型）</h4><p>软件生命周期模型是跨越整个生命周期的系统开发、运作、维护所实施的全部工作和任务的结构框架。</p><ul><li>瀑布模型</li><li>快速原型模型</li><li>增量模型</li><li>螺旋模型</li><li>喷泉模型</li></ul><h5 id="瀑布模型"><a href="#瀑布模型" class="headerlink" title="瀑布模型"></a>瀑布模型</h5><p>阶段间具有顺序性和依赖性</p><p>推迟实现</p><p>文档驱动</p><p>缺乏灵活性，不适用需求不明确的情况，客户后期才能看到软件，前期客户看不到软件确要提出明确需求是不实际的。</p><h5 id="快速原型模型"><a href="#快速原型模型" class="headerlink" title="快速原型模型"></a>快速原型模型</h5><p>快速建立反映用户主要需求的原型系统，反复由用户评价修正需求，开发出最终产品。</p><p>如名，就是快速有个原型</p><h5 id="增量模型"><a href="#增量模型" class="headerlink" title="增量模型"></a>增量模型</h5><p>把软件产品作为一系列增量构建来设计、编码、继承和测试</p><h5 id="螺旋模型"><a href="#螺旋模型" class="headerlink" title="螺旋模型"></a>螺旋模型</h5><p>大型软件开发，进行风险评估</p><h5 id="喷泉模型"><a href="#喷泉模型" class="headerlink" title="喷泉模型"></a>喷泉模型</h5><p>软件生命周期的各个阶段是相互重叠和多次反复的</p><h1 id="第2章-软件项目管理基础"><a href="#第2章-软件项目管理基础" class="headerlink" title="第2章 软件项目管理基础"></a>第2章 软件项目管理基础</h1><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a><strong>概念</strong></h4><p>软件项目管理是为了使软件项目能够按照预定的成本、进度、质量顺利完成，而对成本、人员、进度、质量、风险等进行分析和管理的活动。</p><h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a><strong>目的</strong></h4><p>让软件项目，尤其是大型项目的整个软件生命周期（从分析、设计、编码到测试、维护全过程）都能在管理者的控制之下，以预定的成本，按期、按质完成软件，然后交付用户使用。</p><h4 id="项目管理三角形"><a href="#项目管理三角形" class="headerlink" title="项目管理三角形"></a><strong>项目管理三角形</strong></h4><p><strong>成本 时间  项目范围</strong></p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625130116242.png" alt="image-20240625130116242" style="zoom:50%;" /><p>软件工作的质量会受成本、时间、项目范围的限制 </p><h4 id="项目进度计划"><a href="#项目进度计划" class="headerlink" title="项目进度计划"></a>项目进度计划</h4><p>进度计划是指把工作量分配给特定的软件工程任务并规定完成各项任务的起止日期，从而将估算的项目工作量分布于计划好的项目持续期内。</p><h4 id="甘特图"><a href="#甘特图" class="headerlink" title="甘特图"></a>甘特图</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625131110868.png" alt="image-20240625131110868" style="zoom:33%;" /><p>竖着看一个颜色结束表示三个工艺结束刮完一面墙。横着看一个颜色结束表述一面墙的这个工艺结束，横着整个结束就是这项工艺整个结束。</p><h1 id="第3章-软件需求分析基础"><a href="#第3章-软件需求分析基础" class="headerlink" title="第3章 软件需求分析基础"></a>第3章 软件需求分析基础</h1><h4 id="软件需求的概念"><a href="#软件需求的概念" class="headerlink" title="软件需求的概念"></a>软件需求的概念</h4><p>指明系统必须实现什么的规格说明，它描述了系统的行为、特性或属性，是在开发过程中对系统的约束。</p><p>软件需求是用户对目标软件系统的要求和期望。 </p><h4 id="软件需求的分类"><a href="#软件需求的分类" class="headerlink" title="软件需求的分类"></a>软件需求的分类</h4><p>功能需求 性能需求 可靠性和可用性需求 安全保密要求 出错处理需求 接口需求 约束性需求 逆向需求</p><h5 id="结构化分析模型"><a href="#结构化分析模型" class="headerlink" title="结构化分析模型"></a>结构化分析模型</h5><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625132302250.png" alt="image-20240625132302250" style="zoom: 33%;" /><h4 id="数据流图"><a href="#数据流图" class="headerlink" title="数据流图"></a>数据流图</h4><p>0层DFD</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625132452043.png" alt="image-20240625132452043" style="zoom:25%;" /><p>矩形：数据的源点或终点     人员 部分 传感器装置</p><p>圆角矩形：数据加工&#x2F;处理</p><p>箭头：数据流</p><p>开口矩形：数据存储</p><h4 id="数据字典"><a href="#数据字典" class="headerlink" title="数据字典"></a>数据字典</h4><p>用以描述系统中的每个数据和加工的具体含义，采用半形式化方法表达。要对数据流图中出现的所有名字（数据流、加工、数据存储）进行定义。</p><h1 id="第4章-软件设计基础"><a href="#第4章-软件设计基础" class="headerlink" title="第4章 软件设计基础"></a>第4章 软件设计基础</h1><h4 id="模块独立性的概念、意义"><a href="#模块独立性的概念、意义" class="headerlink" title="模块独立性的概念、意义"></a>模块独立性的概念、意义</h4><p>具有独立功能且和其他模块没过多作用。</p><p>容易分工合作<br>容易测试和维护，修改工作量较小，错误传播范围小，扩充功能容易</p><h4 id="模块独立性的两个度量标准：耦合、内聚"><a href="#模块独立性的两个度量标准：耦合、内聚" class="headerlink" title="模块独立性的两个度量标准：耦合、内聚"></a>模块独立性的两个度量标准：耦合、内聚</h4><p>高内聚、低耦合</p><h4 id="耦合、内聚的几种类型"><a href="#耦合、内聚的几种类型" class="headerlink" title="耦合、内聚的几种类型"></a>耦合、内聚的几种类型</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625144659331.png" alt="image-20240625144659331" style="zoom:50%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625144721447.png" alt="image-20240625144721447" style="zoom:50%;" /><h1 id="第5章-软件体系结构设计"><a href="#第5章-软件体系结构设计" class="headerlink" title="第5章 软件体系结构设计"></a>第5章 软件体系结构设计</h1><h4 id="·-数据流图映射成软件结构图：变换型、事务型"><a href="#·-数据流图映射成软件结构图：变换型、事务型" class="headerlink" title="· 数据流图映射成软件结构图：变换型、事务型"></a>· 数据流图映射成软件结构图：变换型、事务型</h4><h1 id="第7章-构件级设计"><a href="#第7章-构件级设计" class="headerlink" title="第7章 构件级设计"></a>第7章 构件级设计</h1><h4 id="·过程设计工具：程序流程图、盒图（N-S图）、PAD图、判定表-树、PDL"><a href="#·过程设计工具：程序流程图、盒图（N-S图）、PAD图、判定表-树、PDL" class="headerlink" title="·过程设计工具：程序流程图、盒图（N-S图）、PAD图、判定表&#x2F;树、PDL"></a>·过程设计工具：程序流程图、盒图（N-S图）、PAD图、判定表&#x2F;树、PDL</h4><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145127733.png" alt="image-20240625145127733" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145144458.png" alt="image-20240625145144458" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145206636.png" alt="image-20240625145206636" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145233890.png" alt="image-20240625145233890" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145317814.png" alt="image-20240625145317814" style="zoom:25%;" /></p><h1 id="第8章-面向对象的概念和建模符号"><a href="#第8章-面向对象的概念和建模符号" class="headerlink" title="第8章 面向对象的概念和建模符号"></a>第8章 面向对象的概念和建模符号</h1><h4 id="UML"><a href="#UML" class="headerlink" title="UML"></a>UML</h4><p>统一建模语言</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145720773.png" alt="image-20240625145720773" style="zoom:25%;" /><p>用例图、类图、状态图、顺序图、活动图</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145754070.png" alt="image-20240625145754070" style="zoom:25%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625145822241.png" alt="image-20240625145822241" style="zoom:25%;" /></p><h1 id="第9章-面向对象的需求获取与分析"><a href="#第9章-面向对象的需求获取与分析" class="headerlink" title="第9章 面向对象的需求获取与分析"></a>第9章 面向对象的需求获取与分析</h1><h4 id="用例模型"><a href="#用例模型" class="headerlink" title="用例模型"></a>用例模型</h4><h4 id="OOA方法：注意分析类的三种类型（边界类、控制类、实体类）"><a href="#OOA方法：注意分析类的三种类型（边界类、控制类、实体类）" class="headerlink" title="OOA方法：注意分析类的三种类型（边界类、控制类、实体类）"></a>OOA方法：注意分析类的三种类型（边界类、控制类、实体类）</h4><h1 id="第10章-面向对象设计"><a href="#第10章-面向对象设计" class="headerlink" title="第10章 面向对象设计"></a>第10章 面向对象设计</h1><h4 id="OOD：包含系统设计、对象设计"><a href="#OOD：包含系统设计、对象设计" class="headerlink" title="OOD：包含系统设计、对象设计"></a>OOD：包含系统设计、对象设计</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625151820130.png" alt="image-20240625151820130" style="zoom:33%;" /><h4 id="画类图"><a href="#画类图" class="headerlink" title="画类图"></a>画类图</h4><h1 id="第11章-软件测试"><a href="#第11章-软件测试" class="headerlink" title="第11章 软件测试"></a>第11章 软件测试</h1><h4 id="软件测试的目的"><a href="#软件测试的目的" class="headerlink" title="软件测试的目的"></a>软件测试的目的</h4><p>目的是希望以最低代价，以尽可能多地找出软件中潜在的各种错误和缺陷。</p><h4 id="测试的分类"><a href="#测试的分类" class="headerlink" title="测试的分类"></a>测试的分类</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625150813875.png" alt="image-20240625150813875" style="zoom:33%;" /><p>· 黑盒测试：边界值分析法、等价类划分法</p><p>· 白盒测试：逻辑覆盖、基本路径测试</p><h1 id="第12章-软件维护"><a href="#第12章-软件维护" class="headerlink" title="第12章 软件维护"></a>第12章 软件维护</h1><h4 id="软件维护的概念和类型（纠错性维护、适应性维护、完善性维护、预防性维护）"><a href="#软件维护的概念和类型（纠错性维护、适应性维护、完善性维护、预防性维护）" class="headerlink" title="软件维护的概念和类型（纠错性维护、适应性维护、完善性维护、预防性维护）"></a>软件维护的概念和类型（纠错性维护、适应性维护、完善性维护、预防性维护）</h4><h5 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h5><p>是指在软件的运行&#x2F;维护阶段由软件厂商向客户所提供的服务工作。<br>是在软件交付使用后，为了改正错误或满足新的需求而修改软件的过程。</p><h5 id="纠错性维护"><a href="#纠错性维护" class="headerlink" title="纠错性维护"></a>纠错性维护</h5><p>在软件投入运行一段时间后，可能会暴露出一部分在测试阶段没有发现的错误，为改正这些错误而对软件进行修改</p><h5 id="适应性维护"><a href="#适应性维护" class="headerlink" title="适应性维护"></a>适应性维护</h5><p>为了适应计算机的飞速发展，使软件适应外部新的硬件和软件环境或者数据环境发生的变化，而对软件进行修改</p><h5 id="完善性维护"><a href="#完善性维护" class="headerlink" title="完善性维护"></a>完善性维护</h5><p>用户需求经常变化，在软件使用过程中，用户可能会对软件提出新的功能和性能要求，为了满足这些新的要求而对软件进行修改，使之在功能和性能上得到完善和增强</p><h5 id="预防性维护"><a href="#预防性维护" class="headerlink" title="预防性维护"></a>预防性维护</h5><p>为了提高软件的可维护性和可靠性等目标，不等用户提出维护申请，主动采用先进的软件工程方法对需要维护的软件或软件中的某一部分重新进行设计、编码和测试，为以后进一步改进软件打下良好基础</p><h4 id="软件维护的副作用和类型"><a href="#软件维护的副作用和类型" class="headerlink" title="软件维护的副作用和类型"></a>软件维护的副作用和类型</h4><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240625151030077.png" alt="image-20240625151030077" style="zoom:80%;" />]]></content>
    
    
    
    <tags>
      
      <tag>软件工程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>转动惯量</title>
    <link href="/2024/06/21/%E8%BD%AC%E5%8A%A8%E6%83%AF%E9%87%8F/"/>
    <url>/2024/06/21/%E8%BD%AC%E5%8A%A8%E6%83%AF%E9%87%8F/</url>
    
    <content type="html"><![CDATA[<p><strong>定义</strong></p><p>转动惯量是物体旋转惯性的一种量度，描述了物体对其选择运动的抗拒程度。它取决与物体的质量和旋转轴的位置</p><p>$$I&#x3D;mr^2$$</p><p>旋转系统的微分方程<br>$$<br>J\ddot{\theta}+b\dot \theta+k\theta&#x3D;T_{in}<br>$$<br>惯性项$$J\ddot \theta$$</p><p>类比线性系统中的ma</p><p>阻尼项$$b\dot \theta $$</p><p>类似线性系统中的摩擦力，与角速度成正比</p><p>回复项$$k\theta$$</p><p>类似线性系统中的弹力kx,与角位移成正比</p><p>外部力矩$$T_{in}$$</p><p>作用在系统上的外部输入力矩，类比线性系统的作用力F</p>]]></content>
    
    
    
    <tags>
      
      <tag>机械系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>希腊字母表</title>
    <link href="/2024/06/21/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D%E8%A1%A8/"/>
    <url>/2024/06/21/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="希腊字母表"><a href="#希腊字母表" class="headerlink" title="希腊字母表"></a>希腊字母表</h3><table><thead><tr><th>大写字母</th><th>小写字母</th><th>名称</th><th>常见用途</th></tr></thead><tbody><tr><td>Α</td><td>α</td><td>Alpha (αλφα)</td><td>角度、系数、衰减常数</td></tr><tr><td>Β</td><td>β</td><td>Beta (βητα)</td><td>贝塔系数、角度、磁通密度</td></tr><tr><td>Γ</td><td>γ</td><td>Gamma (γαμμα)</td><td>γ射线、希腊字母伽马分布、欧拉常数</td></tr><tr><td>Δ</td><td>δ</td><td>Delta (δελτα)</td><td>改变量、偏差、克罗内克函数</td></tr><tr><td>Ε</td><td>ε</td><td>Epsilon (εψιλον)</td><td>小量、介电常数</td></tr><tr><td>Ζ</td><td>ζ</td><td>Zeta (ζητα)</td><td>阻尼系数、统计学中的zeta函数</td></tr><tr><td>Η</td><td>η</td><td>Eta (ητα)</td><td>量子效率、统计学中的效率</td></tr><tr><td>Θ</td><td>θ</td><td>Theta (θητα)</td><td>角度、温度、时间常数</td></tr><tr><td>Ι</td><td>ι</td><td>Iota (ιωτα)</td><td>微小量、某些特定的物理常数</td></tr><tr><td>Κ</td><td>κ</td><td>Kappa (καππα)</td><td>波数、弹性系数、热导率</td></tr><tr><td>Λ</td><td>λ</td><td>Lambda (λαμδα)</td><td>波长、特征值、热传导系数</td></tr><tr><td>Μ</td><td>μ</td><td>Mu (μυ)</td><td>微米、磁导率、动摩擦系数</td></tr><tr><td>Ν</td><td>ν</td><td>Nu (νυ)</td><td>频率、波数</td></tr><tr><td>Ξ</td><td>ξ</td><td>Xi (ξι)</td><td>变量、随机变量</td></tr><tr><td>Ο</td><td>ο</td><td>Omicron (ομικρον)</td><td>极小量</td></tr><tr><td>Π</td><td>π</td><td>Pi (πι)</td><td>圆周率、乘积符号、数学常数</td></tr><tr><td>Ρ</td><td>ρ</td><td>Rho (ρω)</td><td>密度、抵抗率、相关系数</td></tr><tr><td>Σ</td><td>σ</td><td>Sigma (σιγμα)</td><td>标准差、和、表面张力</td></tr><tr><td>Τ</td><td>τ</td><td>Tau (ταυ)</td><td>时间常数、剪切应力、寿命</td></tr><tr><td>Υ</td><td>υ</td><td>Upsilon (υψιλον)</td><td>核外电子能量、希腊字母upsilon粒子</td></tr><tr><td>Φ</td><td>φ</td><td>Phi (φι)</td><td>黄金比例、磁通量、角度</td></tr><tr><td>Χ</td><td>χ</td><td>Chi (χι)</td><td>卡方分布、磁化率</td></tr><tr><td>Ψ</td><td>ψ</td><td>Psi (ψι)</td><td>波函数、流函数</td></tr><tr><td>Ω</td><td>ω</td><td>Omega (ωμεγα)</td><td>角速度、电阻、固有频率</td></tr></tbody></table><p>不是，是谁叫我zeta读的kersi:</p>]]></content>
    
    
    
    <tags>
      
      <tag>latex</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>二阶系统标准形式</title>
    <link href="/2024/06/21/%E4%BA%8C%E9%98%B6%E7%B3%BB%E7%BB%9F%E6%A0%87%E5%87%86%E5%BD%A2%E5%BC%8F-md/"/>
    <url>/2024/06/21/%E4%BA%8C%E9%98%B6%E7%B3%BB%E7%BB%9F%E6%A0%87%E5%87%86%E5%BD%A2%E5%BC%8F-md/</url>
    
    <content type="html"><![CDATA[<p><strong>一阶系统的标准形式</strong></p><p><em>传递函数形式</em><br>$$<br>H(S)&#x3D;\frac{K}{\tau s+1}<br>$$<br>$$\tau$$：时间常数</p><p>时间常数代表系统的响应速度，时间常数$$\tau$$越大，系统的响应速度越慢</p><p>K:系统增益</p><p><em>响应特性</em></p><p>单位阶跃响应</p><p>$$r(t)&#x3D;1(t\ge0)$$</p><p>$$c(t)&#x3D;K(1-e^{-\frac{t}{\tau}})$$</p><p>$$\tau$$为2                                                                                 $$\tau$$为20</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240621202628538.png" alt="image-20240621202628538" style="zoom:33%;" /><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240621202739408.png" alt="image-20240621202739408" style="zoom:33%;" /></p><p><strong>二阶系统的标准形式</strong></p><p><em>传递函数形式</em><br>$$<br>H(s)&#x3D;\frac{\omega_n^2}{s^2+2\zeta\omega_ns+\omega_n^2}<br>$$<br>没有零点</p><p>$$\omega_n$$：自然频率</p><p>自然频率是系统在没有阻尼的情况下的自由振荡的频率。它决定了系统的振荡速度。</p><p>$$\zeta$$：阻尼比</p><p>阻尼比是一个无量纲参数，它表示系统的阻尼程度。不同的阻尼比对应不同类型的响应：</p><ul><li><p>$$\zeta$$&#x3D;0：无阻尼，系统响应是持续振荡的</p></li><li><p>0&lt;$$\zeta$$&lt;1:欠阻尼，系统响应是振荡衰减的</p></li><li><p>$$\zeta$$&#x3D;1:临界阻尼，系统响应不振荡且快速达到稳态</p></li><li><p>$$\zeta$$&gt;1:过阻尼，系统响应不振荡且缓慢达到稳态</p></li></ul><p>二阶系统的单位阶跃响应</p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240621200044013.png" style="zoom: 33%;" /><h2 id="一阶系统和二阶系统的实际应用"><a href="#一阶系统和二阶系统的实际应用" class="headerlink" title="一阶系统和二阶系统的实际应用"></a>一阶系统和二阶系统的实际应用</h2><p><strong>一阶系统</strong></p><p>一阶系统的动态行为可以用一个一阶微分方程来描述，通常只设计到单个储能元件，（如电容或电感）。一阶系统的响应是单调的，不会出现振荡。（不振荡的意思是如果输入是不振荡的，那输出不震荡，输入振荡，输出也振荡</p><p><strong>当输入是正弦函数时，尽管输出函数是振荡的（因为正弦函数本身是振荡的），但这种振荡完全是由输入频率决定的，系统不会引入新的振荡频率（等到频域分析）</strong></p><p>1.电气系统的RC电路</p><p>电阻-电容（RC)是一个典型的一阶系统。其电压响应可以描述为一个一阶微分方程。</p><p>$$H(s)&#x3D;\frac{1}{RCs+1}$$</p><p>2.流体系统中的液位控制</p><p>一个具有恒定流入流出的水箱，液位的变化可以通过一阶系统来描述。</p><p>$$H(S)&#x3D;\frac{1}{\tau s+1}$$</p><p>3.热系统中的温度控制</p><p>一个简单的热系统，比如加热一个物体的过程，可以用一阶系统来描述，温度的变化是单调的，没有振荡。</p><p>$$H(s)&#x3D;\frac{K}{\tau s +1}$$</p><p><strong>二阶系统</strong></p><p>二阶系统的行为可以用一个二阶微分方程来描述，通常涉及到两个储能元件（如电感和电容）。它们的响应可以是振荡的（欠阻尼），或单调的（过阻尼或临界阻尼）。（什么叫做振荡的，振荡的是只在输入不是振荡的单位阶跃信号的情况下，输出是否振荡吗，还是输入也可以是振荡的？应该是特别针对单位阶跃响应的）</p><p>1.电器系统中的RCL电路</p><p>电阻-电感-电容（RLC）是典型的二阶系统。其电压或电流响应都可以描述为一个二阶微分方程。</p><p>$$H(s)&#x3D;\frac{1}{LCs^2+RCs+1}$$</p><p>2.机械系统中的质量-弹簧-阻尼器系统</p><p>一个具有弹簧和阻尼器的质量系统，其运动方程是一个二阶微分方程</p><p>$$H(s)&#x3D;\frac{1}{ms^2+fs+k}$$</p><p>f:阻尼系数（知道为什么二阶系统中叫阻尼比不叫阻尼系数了吧）  k:弹簧弹性系数  </p><p>3.控制系统的伺服电机控制</p><p>伺服电机的控制通常是二阶的，尤其是涉及到位置控制时，其动态响应可以描述为 一个二阶系统。</p><p>$$\frac{K}{Js^2+Bs+K}$$</p><p>J:转动惯量  B:阻尼系数  K:系统增益</p><h2 id="一阶系统与二阶系统的区分"><a href="#一阶系统与二阶系统的区分" class="headerlink" title="一阶系统与二阶系统的区分"></a>一阶系统与二阶系统的区分</h2><p>1.储能元件数量</p><p>一阶系统：一个储能元件（电容或电感）ps:电容：电流对电压变化的响应 电感：电压对电流变化的响应</p><p>二阶系统：两个储能元件（一个电容一个电感或一个弹簧一个质量块）</p><p>2.响应特性</p><p>一阶系统：响应是单调的，没有振荡（其实我对这里的振荡还是没有理解太清楚），系统的动态行为由一个时间常数决定。</p><p>二阶系统：响应可以是振荡的也可以是单调的，取决于系统的阻尼比，系统的动态行为由自然频率和阻尼比共同决定。</p><p>3.传递函数形式<br>$$<br>一阶系统 \frac{K}{\tau s+1}<br>二阶系统\frac{\omega_n}{s^2+2\zeta\omega_n s +\omega_n^2}<br>$$</p><h6 id="附："><a href="#附：" class="headerlink" title="附："></a>附：</h6><p>$$<br>K \tau \zeta \omega_n在具体系统中体现为什么<br>$$</p><p><em>1.增益K（此增益非彼增益）</em></p><p><em>定义</em></p><p>系统增益是指输出与输入的比例关系</p><p><em>实际体现</em></p><p>电器系统：放大器中输出电流或电压与输入电流或电压之比 ps 特哥作业的这个习题还没做</p><p>机械系统 ：力学中系统的位移响应与施加力之间的比例关系（不是与加速度？为什么是位移</p><p>热力系统：热力系统中输出温度变化与输入热量之间的关系</p><p>2.时间常数$$\tau$$</p><p><em>定义</em></p><p>时间常数$$tau$$是描述系统响应速度的参数，它表示系统达到其最终值约63%所需的时间（存疑）</p><p>怎么求时间常数？记得特哥讲过可以根据实验的方法，但是没提过63%这个值啊</p><p><em>实际体现</em></p><p>机械系统：在RC电路中，时间常数$$\tau$$&#x3D;RC表示电容器充电到其最终电压63%所需的时间</p><p>3.自然频率$$\omega_n$$</p><p><em>定义</em></p><p>自然频率指系统在没有阻尼的情况下自由振荡的固有频率。</p><p><em>实际体现</em></p><p>机械系统 :质量-弹簧-阻尼器系统，自然频率$$\omega_n&#x3D;\sqrt{\frac{k}{m}}$$</p><p>电气系统：LC电路中，自然频率$$\omega_n&#x3D;\frac{1}{\sqrt{LC}}$$</p><p>结构工程：自然频率表示结构在收到冲击或地震时的固有振动频率</p><p>4.阻尼比$$\zeta$$</p><p><em>定义</em></p><p>阻尼比是描述系统阻尼程度的参数，表示系统的阻尼和临界阻尼的比值</p><p>在控制系统中，阻尼比表示系统收到干扰后的振荡程度。</p>]]></content>
    
    
    
    <tags>
      
      <tag>自动控制原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cross_entropy</title>
    <link href="/2024/04/01/cross-entropy/"/>
    <url>/2024/04/01/cross-entropy/</url>
    
    <content type="html"><![CDATA[<p><strong>信息熵</strong></p><p><em>例子</em></p><p>两条信息</p><p>1.信息x:明天要下雨</p><p>2.信息y:太阳从东边升起</p><p>信息熵x&gt;y</p><p><em>定义</em></p><p>直观感受，x包含的信息比y包含的信息多，y的信息没有用，用来评价这种信息的价值，叫做信息熵。</p><p>专业说法：消除不确定性所需信息量的度量。</p><p><em>公式</em></p><p>x都是离散型的随机变量  x&#x3D;{x1,x2,x3,…xn}</p><p>信息xi的信息熵  xi发生的概率是p(xi)</p><p>那么xi的信息熵就是-log(p(xi))   函数图像也符合，概率越大，信息熵越小</p><p>概率越小，不确定性越大，信息熵越大</p><p><strong>熵（香农熵）</strong></p><p><em>引入</em></p><p>信息熵是衡量一个离散型的变量为给定值时包含的信息量，消除不确定性所需信息量的量度。衡量的是一个变量。</p><p>那么如果要衡量整个概率分布的熵呢？不是取特定值包含的信息，而是这一个概率分布包含的信息量，或许成为这个概率分布的混乱程度更加准确。</p><p><em>定义</em></p><p>有一个概率分布P(ps 该复习概率分布了，X与x的区别都不熟悉了，概率分布的一些基本写法都忘记了)</p><p>我们可以用香农熵（简称熵）来对整个概率分布的平均信息量来进行描述。</p><p><em>公式</em><br>$$<br>H(x)&#x3D;-\sum _{i&#x3D;1}^{n}p(x_i)log(p(xi))<br>$$</p>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习 熵</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tf_zpk</title>
    <link href="/2024/03/27/tf-zpk/"/>
    <url>/2024/03/27/tf-zpk/</url>
    
    <content type="html"><![CDATA[<p><strong>微分方程</strong></p><p>RC电路充电情景</p><p><em>公式</em><br>$$<br>RC\frac{dV(t)}{d(t)}+V(t)&#x3D;V_{in}(t)<br>$$<br><em>代码</em></p><p>talk is cheap, show me the code</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs matlab">R=<span class="hljs-number">1</span>; <span class="hljs-comment">%Ohm</span><br>C=<span class="hljs-number">1</span>; <span class="hljs-comment">%Farad</span><br>Vin=<span class="hljs-number">5</span>; <span class="hljs-comment">% Input voltage in Volts</span><br><br><span class="hljs-comment">%Define the differential equation</span><br>dVdt=@(t,V)(Vin-V)/(R*C);<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>matlab 自动控制原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tf</title>
    <link href="/2024/03/27/tf/"/>
    <url>/2024/03/27/tf/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>3.24</title>
    <link href="/2024/03/24/3-24/"/>
    <url>/2024/03/24/3-24/</url>
    
    <content type="html"><![CDATA[<p><strong>杂谈</strong></p><p>今天又去家教喽</p><p>还挺精神，家教回来居然没有死掉，以后还是不要坐公交了，就坐地铁喽</p><p>下午学控制，晚上学高数</p><p>控制</p><p>电容在复数域的等效  复阻抗</p><p>R&#x3D;1&#x2F;Cs</p><p>还有那个电路，不是电桥电路，就是普通的串并联电路</p><p>高数</p><p>极限的性质</p><p>唯一性</p><p>极限的值是唯一的，有极限极限不是无穷</p><p>局部有界性</p><p>连续区间内一定有极限，有极限不一定连续  极限存在必有界 因此如果一个开区间，两端的取值是没有极限的，那么就不是局部有界</p><p>局部保号性</p><p>所有光环靠近std都是和std同号的，什么什么追求什么什么，balabala哲学的一段话</p><p>英语单词复习100，学习100</p><p>晚上超市踩雷，巨难吃那烘焙里面的什么蛋糕盒子，真恶心那味道</p><p>就这些喽，给今天表现打7分吧</p>]]></content>
    
    
    
    <tags>
      
      <tag>考研 日记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>i2t_loss</title>
    <link href="/2024/03/23/i2t-loss/"/>
    <url>/2024/03/23/i2t-loss/</url>
    
    <content type="html"><![CDATA[<p><strong>i2t loss</strong></p><p>五天啊，花了我五天，终于能跑了</p><p>说实话，经过这么几个月的炼丹，我明白了一个道理，<em>永远不要提前开香槟</em>，你永远不知道不跑到最后，这个模型的结果是怎么样的。</p><p>现在写这心情也是忐忑的，我不知道这个得分的加权究竟是准确的还是不准确的。</p><p>图片是不准确的，需要一个评价标准。</p><p>因为我的图像特征是提取好的，所以我使用的是特征值，而不是直接图像的三通道值。</p><p>其实之间老师说的熵是可以尝试的，但是我没有尝试，可能之前人真的麻了，真不想弄这个了，看不到希望。</p><p>但是我觉得还是值得一试的，在这个任务里，只要别用对比学习中用最难的，都好说，我可以什么都没学到，但是这个任务中我一定学到了一个东西，不要在不准的数据集里面去使用最难样本的这种loss。</p><p>好了回到正题。</p><p>实现这个loss的细节有，首先准备好图片特征，图片特征都是有id，有path的。</p><p>计算所有图片样本的score</p><p>然后在每个类内评价图片，把图片从类里面删去</p><p>。。。</p><p>刚看了眼结果，心又凉了。。。</p>]]></content>
    
    
    
    <tags>
      
      <tag>行人重识别 多模态</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3.22</title>
    <link href="/2024/03/22/3-22/"/>
    <url>/2024/03/22/3-22/</url>
    
    <content type="html"><![CDATA[<p><strong>数学</strong></p><p>学完了函数图像这一节</p><p><strong>六个基本初等函数</strong></p><hr><p>常数函数{铅垂线法}</p><p>幂函数{y&#x3D;x^2 y&#x3D;x^3  }</p><p>指数函数{}</p><p>对数函数{}</p><p>三角函数{}</p><p><strong>基本初等函数的性质</strong></p><p>奇偶性</p><p>单调性</p><p>周期性</p><p>然后极限开了头</p><p>极限的定义</p><p>无限逼近法</p><p>超实数法</p><p>自动控制原理</p><p>方框图的组成{信号流 引出点 反馈点  方框}</p><p>方框图的传递函数的简化规则</p><p>好多条，只记得最基本的</p><p>今天虽然旷了早八，上午打了一上午游戏，睡了一下午加打游戏，但晚上还是学了很久的</p><p>打6分吧</p>]]></content>
    
    
    
    <tags>
      
      <tag>每日小结 考研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sdm_loss修改</title>
    <link href="/2024/03/18/sdm-loss%E4%BF%AE%E6%94%B9/"/>
    <url>/2024/03/18/sdm-loss%E4%BF%AE%E6%94%B9/</url>
    
    <content type="html"><![CDATA[<p><em>实验</em></p><p>t2i（<a href="https://arxiv.org/pdf/1903.06325.pdf">1903.06325.pdf (arxiv.org)</a>）论文中的公式1，2</p><p>构造软标签</p><p>DBSCAN聚类出来软标签，是通过Image和image聚类出来的</p><p>计算图像与图像之间的相似度，除了可以用余弦来计算（但是可能不太好），还可以使用<strong>借助一个新的数据集</strong>，通过计算图像与新的数据集中图片的相似度来衡量两个图片的相似度，该图片与数据集中n张图片计算相似度用softmax得到一个相似分布，比较两个图像之间的分布来衡量图像之间的相似度。</p><p>新的数据集通过使用DBSCAN聚类算法确定聚类中心，可能1000个，但是可能得在一个batch里面去找聚类中心，可能找不到？？？（什么意思）  如果一个batch64太小了，可能要改成128或者更大</p><p>DBSCAN要在一个batch里面做</p><p>i2t（<a href="https://arxiv.org/pdf/2301.00930.pdf">2301.00930.pdf (arxiv.org)</a>）</p><p>64个图像 去 检索64个文本</p><p>每个图像softmax预测出来的概率分布和64个文本的标签分布算Kl距离</p><p>（是这里把batch调大一些吗？因该不是）</p><p>每个图像算出来一个Loss,算出来64个loss，给这64个loss加上权重（就类似之前得用熵来衡量，但老师找的这个肯定效果更好） </p><p>具体怎么<strong>加权重</strong>呢？</p><p>一个员工的价值不是由自身价值衡量的，而是由这个公司缺少他后衡量的</p><p>于是，衡量一个样本的 权重，使用的方法是通过样本集的价值减去样本集中去掉这个样本后剩下的价值</p><p>这个价值是怎么计算的呢</p><p>衡量样本价值可以在训练之前就做好</p><p><strong>衡量样本价值</strong></p><p>1.余弦相似度计算H_inner</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">H_inner = torch.matmul(a, a.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p>2.调整H_inner得到相似的矩阵H</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240318214152330.png" alt="image-20240318214152330"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">H_inner = torch.matmul(a, a.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br><span class="hljs-keyword">del</span> a<br>H = H_inner*(np.pi-torch.acos(H_inner))/(<span class="hljs-number">2</span>*np.pi)<br><span class="hljs-keyword">del</span> H_inner<br>H.fill_diagonal_(<span class="hljs-number">1</span>/<span class="hljs-number">2</span>)<br><br>invH = torch.inverse(H)<br><span class="hljs-keyword">del</span> H<br></code></pre></td></tr></table></figure><p>看看别人的代码写的多漂亮，不用的变量都及时移除了</p><p><em>计算CG-score的公式</em></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240318220843988.png" alt="image-20240318220843988"></p><p>y:所有图片的标签</p><p>H:相似度矩阵，通过Hinner计算的出来的</p><p>CG(i)：第i个图片的复杂性差距得分</p><p>到底是CG_score得分高好还是低好呢</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240319143733427.png" alt="image-20240319143733427"></p><p>5000个图片计算score需要一分钟</p><p>十分钟处理完50000张</p><p>很快啊，cifar10是五万张图片，十分钟就处理完了</p><p>有值了都好说</p><p>但是原来代码是直接计算数据集中图片的 cg-score，我是计算cuhk数据集的图像score还是特征的score呢</p><p>感觉可能是特征好一点，毕竟我不是用图像训练的，是用图像特征训练的</p><p>每个图片和 对应得分是怎么对应起来的呢</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240319154004361.png" alt="image-20240319154004361"></p><p>训练集中一个batch取出来的图片都是shuffle打乱过的</p><p>image_ids是从0开始的</p><p>训练数据集已经弄好了，现在就等着把得分pkl文件计算出来了</p><p>计算cg-score</p><p>1.准备好特征文件，包含图片id，图片特征，图片路径</p><p>2.加载一个id内的图片，选取对应id的图片，然后也选取不同id的图片，由ratio确定比例（cifar10是10个类别，5000张图片，因此源代码构造的10000*10000的相似矩阵，我也那么做，那我岂不是构造不到10*10的矩阵，好奇怪啊。而且一万多个类别，循环次数增大1000倍，gpu擅长并行，矩阵大小虽然减小很多但速度并不明显，可能后面计算矩阵的逆会很快，那也说不定速度是增还是减</p><ol start="3"><li></li></ol><p>人改麻了</p><p>把chosen_curr_list形状改好了，4个元素，每个元素是（1*512）的tensor</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240320230913027.png" alt="image-20240320230913027"></p><p>现在要把chosen_another_list形状也改好</p><p>麻了形状真难改，看来对numpy，pytorch这些对张量操作的代码都要记清楚，chatgpt还是不是很擅长这个</p><p>pos 和 neg不记得是那个方法里面的了</p>]]></content>
    
    
    
    <tags>
      
      <tag>reid 损失函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解决hexo+gitee博客推送后页面没更新</title>
    <link href="/2024/03/18/%E8%A7%A3%E5%86%B3hexo-gitee%E5%8D%9A%E5%AE%A2%E6%8E%A8%E9%80%81%E5%90%8E%E9%A1%B5%E9%9D%A2%E6%B2%A1%E6%9B%B4%E6%96%B0/"/>
    <url>/2024/03/18/%E8%A7%A3%E5%86%B3hexo-gitee%E5%8D%9A%E5%AE%A2%E6%8E%A8%E9%80%81%E5%90%8E%E9%A1%B5%E9%9D%A2%E6%B2%A1%E6%9B%B4%E6%96%B0/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>直流电动机</title>
    <link href="/2024/03/18/%E7%9B%B4%E6%B5%81%E7%94%B5%E5%8A%A8%E6%9C%BA/"/>
    <url>/2024/03/18/%E7%9B%B4%E6%B5%81%E7%94%B5%E5%8A%A8%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/byeyear/p/6254145.html">https://www.cnblogs.com/byeyear/p/6254145.html</a></p><p>基本概念</p><p>绕组和线圈</p><p>绕组就是多组线圈</p><p>转动惯量</p><p>转动惯量在转动力学中相当于线性力学的质量</p><p><strong>直流电动机</strong></p><p><em>反电动势</em></p><p>Eb&#x3D;Ce*w</p><p>反电动势的大小和角速度成正比</p><p>E&#x3D;BLV</p><p><em>力矩</em></p><p>Mm&#x3D;CmI</p><p>力矩大小和电流成正比</p><p>F&#x3D;BIL</p><p>力矩平衡</p>]]></content>
    
    
    
    <tags>
      
      <tag>自动控制原理 元器件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>下载minist数据集时报错</title>
    <link href="/2024/03/18/%E4%B8%8B%E8%BD%BDminist%E6%95%B0%E6%8D%AE%E9%9B%86%E6%97%B6%E6%8A%A5%E9%94%99/"/>
    <url>/2024/03/18/%E4%B8%8B%E8%BD%BDminist%E6%95%B0%E6%8D%AE%E9%9B%86%E6%97%B6%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<p><strong>使用tensorflow 和 keara 下载minist数据集时报错</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Load the data and split it between train and test sets</span><br>(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()<br></code></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">URL <span class="hljs-keyword">fetch</span> failure <span class="hljs-keyword">on</span> https://<span class="hljs-keyword">storage</span>.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz: <span class="hljs-keyword">None</span> <span class="hljs-comment">-- [WinError 10061] 由于目标计算机积极拒绝，无法连接。 Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...</span><br></code></pre></td></tr></table></figure><p>真的很坑，这个翻译过来看起来是网络的问题，第一反应是开梯子或者关梯子</p><p>但是实际原因居然是因为路径里面不能有中文</p><p>把路径改成英文就可以了</p><p>尽量用英文路径，不要用中文路径，不然很容易出现一些奇奇怪怪的错误还找不到原因</p><p>不懂，难道是偶然，到底是关梯子好的还是改路径好的？</p><p>因为回答里面没一个提到路径的                                              </p><p>​                                          </p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>力矩平衡</title>
    <link href="/2024/03/18/%E5%8A%9B%E7%9F%A9%E5%B9%B3%E8%A1%A1/"/>
    <url>/2024/03/18/%E5%8A%9B%E7%9F%A9%E5%B9%B3%E8%A1%A1/</url>
    
    <content type="html"><![CDATA[<p><strong>力矩</strong></p><p>定义：力矩是一种使物体能绕轴产生转动的力</p><p>计算公式：<br>$$<br>\tau &#x3D; r \times F<br>$$</p><p>$$<br>\tau 发音为tao,此处表示为力矩，\tau在物理学中可以用来表示力矩，还可以用来表示时间常数<br>$$</p><p>$$<br>\tau &#x3D; r \cdot F \cdot \sin(\theta)<br>$$</p>]]></content>
    
    
    
    <tags>
      
      <tag>自动控制原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一点闲谈</title>
    <link href="/2024/03/15/%E4%B8%80%E7%82%B9%E9%97%B2%E8%B0%88/"/>
    <url>/2024/03/15/%E4%B8%80%E7%82%B9%E9%97%B2%E8%B0%88/</url>
    
    <content type="html"><![CDATA[<p><strong>一点乱记</strong></p><p>这周算是有点颓废的一周</p><p>不想弄代码，不想看了，感觉很迷茫，觉得做下去没有意义了</p><p>后续有其它方向，可是我已经没有精力去尝试了。</p><p>现在可能就是，每天网上，可以跑一下代码了，改代码是真不想弄了</p><p>每次改动，从能跑，高兴，到跑的挺好，激动，到最后，一直突不破那道坎，涨不了点，失望，灰心</p><p>很难不怀疑这么做下去的意义了，如果我大二，没事干，可以，可以这么不追求结果，因为只要在学习，就算没结果，东西是学到了。</p><p>可现在我不能了啊，我得追求产出了，这么一个没有保证得事情。</p><p>还有关于跨考，究竟适合我吗</p><p>从学得这几天来看，我觉得学的还挺有意思得，虽然学得很慢，但是很充实。</p><p>有电路，有数学。虽然我并没有特别喜欢数学，但是这种建立在物理世界上得数学，一个公式是能找到物理实体去解释得，我还是挺喜欢这种的。</p><p>我没有很喜欢计算机，因为我始终觉得计算机只是一个工具，专门学没什么意思。或者那种偏工程性质的，纯写软件的，也是在人们制定的规则中去实现，就像学一门新的语言一样。</p><p>规则都是人类规定的，我不喜欢学这种规则，我喜欢学物理中，数学中，已经被证实的，永恒的是对的知识。</p><p>对哪些知识我可以联想到生活中的实体，我能有一个直观的感受，就算后面会越学越偏理论，抽象，但始终有个出发点，有个物理实体</p><p>而计算机太偏逻辑了，我感觉我在逻辑思维方面并没有优势，虽然也能学会，但是学的很累，没意思。</p><p>好了好了，没必要想这么多</p><p>对了这个博客，断了这么久，要是可以在网页中编辑就好用了，上网搜搜，搭个动态的部署到本地不就好了嘛？不过那样就没有托管了，不能直接访问网址了，还是先静态吧,markdown里面编辑也挺好</p><p>想想我控制学到哪里了</p><p>拉式变换</p><p>拉式逆变换都学了</p><p>把结构图，关系流图再学了，争取这一周把第二章结束吧</p>]]></content>
    
    
    
    <tags>
      
      <tag>日常</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>复数中三角函数与指数的转换关系.md</title>
    <link href="/2024/03/15/%E5%A4%8D%E6%95%B0%E4%B8%AD%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0%E4%B8%8E%E6%8C%87%E6%95%B0%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%85%B3%E7%B3%BB-md/"/>
    <url>/2024/03/15/%E5%A4%8D%E6%95%B0%E4%B8%AD%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0%E4%B8%8E%E6%8C%87%E6%95%B0%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%85%B3%E7%B3%BB-md/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>自动控制原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/embedding_space/"/>
    <url>/2024/03/14/embedding_space/</url>
    
    <content type="html"><![CDATA[<p>embedding space </p><p>嵌入空间</p><p>有一组数据</p><p>表示很多个动物</p><p>动物有体重，身高，毛发这些数据，有很多个数据</p><table><thead><tr><th>动物序号</th><th>体重</th><th>身高</th><th>毛发</th></tr></thead><tbody><tr><td>1</td><td>5kg</td><td>1meter</td><td>black</td></tr><tr><td>2</td><td>10kg</td><td>1.4meter</td><td>white</td></tr><tr><td>3</td><td>2kg</td><td>0.8meter</td><td>grey</td></tr></tbody></table><p>这样的一组数据信息，怎么表示在计算机里面呢</p><p>数据库用的是表，神经网络用的是向量vector</p><p>各个数据统一一个向量表示，就是统一到一个向量空间里面，叫做嵌入空间</p><p>当各个动物的数据都表示为向量了，动物之间的差异就可以使用向量来衡量了</p><p>(5，1，rgb)</p><p>(10,1.4,rgb)</p><p>(2,0.8,rgb)</p><p>怎么比较呢，<strong>感觉各个维度可以给不同权重啊</strong></p><p>这个仅仅简单把各个类型值作为一个维度，感觉向量空间的表示肯定有更好的方式</p><p>神经网络里面衡量向量的相似度</p><p>欧式距离（少用）l1 l2两种欧式距离，就是平方差距离</p><p>余弦距离  （常用） 越接近1，越靠近，越接近-1，越远离</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/kl%E6%95%A3%E5%BA%A6/"/>
    <url>/2024/03/14/kl%E6%95%A3%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240127100957401.png" alt="image-20240127100957401"></p><p>t2i_loss &#x3D; t2i_pred ***** (<strong>F</strong>.<strong>log_softmax</strong>(text_proj_image, dim&#x3D;1) <strong>-</strong> <strong>torch</strong>.<strong>log</strong>(labels_distribute + epsilon))</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240127101049315.png" alt="image-20240127101049315"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/latex/"/>
    <url>/2024/03/14/latex/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/linux%E5%91%BD%E4%BB%A4/"/>
    <url>/2024/03/14/linux%E5%91%BD%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/simCLR/"/>
    <url>/2024/03/14/simCLR/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/softmax/"/>
    <url>/2024/03/14/softmax/</url>
    
    <content type="html"><![CDATA[<p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240121145555103.png" alt="image-20240121145555103"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/torch.mean/"/>
    <url>/2024/03/14/torch.mean/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/torch.randint%20(2)/"/>
    <url>/2024/03/14/torch.randint%20(2)/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/torch.randint/"/>
    <url>/2024/03/14/torch.randint/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/torch.topk/"/>
    <url>/2024/03/14/torch.topk/</url>
    
    <content type="html"><![CDATA[<p>torch.topk</p><p>返回张量中前k个值和对应的序列</p><p>values,indices&#x3D;torch.topk(input,k,dim&#x3D;none,largest&#x3D;True,sorted&#x3D;True,out)</p><p>input输入张量</p><p>dim是否按维度排序</p><p>largest&#x3D;True  最大在前面</p><p>sorted&#x3D;True 返回的值和序列是保持原始张量顺序还是保持大小顺序</p><p>out用于保存输出张量</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/torch.where/"/>
    <url>/2024/03/14/torch.where/</url>
    
    <content type="html"><![CDATA[<p>torch.where(condition,x,y)</p><p>返回一个新的张量</p><p>如果condition为真，则对应为x的值，如果为假，则是y的值</p><p>如果有一个mask</p><p>mask为true的地方保留为x的值</p><p>mask为false的地方保留为y的值</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E7%BB%84%E4%BC%9A/"/>
    <url>/2024/03/14/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E7%BB%84%E4%BC%9A/</url>
    
    <content type="html"><![CDATA[<p>minibatch</p><p>benchmark</p><p>normalization</p><p>baseline </p><p>benchmark</p><p>metric 三个有什么区别</p><p>neutral中性的</p><p>mer  multimodal emotion  recognization 多模态情感识别</p><p>乘法改成加法</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240121000800665.png" alt="image-20240121000800665"></p><p>什么-3什么的，听不懂一点  怎么改啊</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E7%AC%AC%E4%BA%94%E6%AC%A1%E7%BB%84%E4%BC%9A/"/>
    <url>/2024/03/14/%E7%AC%AC%E4%BA%94%E6%AC%A1%E7%BB%84%E4%BC%9A/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E5%AF%92%E5%81%87%E8%AE%BA%E6%96%871_simCLR/"/>
    <url>/2024/03/14/%E5%AF%92%E5%81%87%E8%AE%BA%E6%96%871_simCLR/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E5%AF%92%E5%81%87%E8%AE%BA%E6%96%872_simCLRv2/"/>
    <url>/2024/03/14/%E5%AF%92%E5%81%87%E8%AE%BA%E6%96%872_simCLRv2/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E5%AF%92%E5%81%87%E8%AE%BA%E6%96%873_IRRA/"/>
    <url>/2024/03/14/%E5%AF%92%E5%81%87%E8%AE%BA%E6%96%873_IRRA/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1/"/>
    <url>/2024/03/14/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1/</url>
    
    <content type="html"><![CDATA[<p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240121132154411.png" alt="image-20240121132154411"></p><p>多分类问题</p><p>真实标签y是一个概率分布   </p><p>y真实概率分布</p><p>y^预测概率分布</p><p>yi真实标签的第i个元素</p><p>yi^预测标签的第i个元素</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240121133232020.png" alt="image-20240121133232020"></p><p>交叉熵能衡量两个概率分布之间的相似性</p><p>为什么引入对数</p><p>对数缓慢增长，对小概率的增长更加敏感</p><p><strong>对数可以将更小的概率映射到更大的值</strong>   交叉熵   损失函数    增加置信度</p><p><strong>指数可以将更大的概率映射得更大</strong>    softmax   分类头         放大损失函数值</p><p>有的公式是把softmax和交叉熵放一起了</p><p>所以既有对预测得分的处理成概率，又有计算损失函数部分</p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240121133943304.png" alt="image-20240121133943304"></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240121150101001.png" alt="image-20240121150101001"></p><p><img src="C:\Users\klull\AppData\Roaming\Typora\typora-user-images\image-20240121171801545.png" alt="image-20240121171801545"></p><p>likelihood</p><p>似然</p><p>我突然懂了</p><p>老师的意思是</p><p>把softmax进行给置信度那一部分</p><p>不要把负样本置信度给放的太大   改成加法</p><p>应用的创新点在哪里？？？</p><p>怎么加，怎么弄</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E4%B8%89%E5%85%83%E7%BB%84%E6%8D%9F%E5%A4%B1/"/>
    <url>/2024/03/14/%E4%B8%89%E5%85%83%E7%BB%84%E6%8D%9F%E5%A4%B1/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%92%B8%E9%A6%8F/"/>
    <url>/2024/03/14/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%92%B8%E9%A6%8F/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E7%BB%84%E4%BC%9A3/"/>
    <url>/2024/03/14/%E7%BB%84%E4%BC%9A3/</url>
    
    <content type="html"><![CDATA[<p>正交</p><p>private </p><p>shared</p><p>background motivation innovation</p><p>对抗网络  gan</p><p>两个模型pk </p><p>两个模型交叉训练</p><p>两个模型一起训练  gradient reversal layers</p><p>GRL反梯度下降</p><p>两个域</p><p>私有域公有域距离远离</p><p>用向量正交计算Loss</p><p>scale缩放</p><p>scaler标量</p><p>正样本 乘法</p><p>噪声 加法</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/%E7%BB%84%E4%BC%9A4/"/>
    <url>/2024/03/14/%E7%BB%84%E4%BC%9A4/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/03/14/2024-3-3%E7%BB%84%E4%BC%9A/"/>
    <url>/2024/03/14/2024-3-3%E7%BB%84%E4%BC%9A/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>irra实验结果</title>
    <link href="/2024/01/03/irra%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C/"/>
    <url>/2024/01/03/irra%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C/</url>
    
    <content type="html"><![CDATA[<p>triplet</p><p><img src="/irra%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C/image-20240103195843243.png" alt="image-20240103195843243"></p><p>正样本的相似性值太小了</p><p>想办法增大正样本相似性的值</p><p>笑死把sdm也搞坏了</p><p>或者会不会是margin太大了</p><p><img src="/irra%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C/image-20240103200120007.png" alt="image-20240103200120007"></p><p>这个<strong>有搞头</strong>，把负样本的值弄小些，正样本值弄大些</p><p><img src="/irra%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C/image-20240103201747595.png" alt="image-20240103201747595"></p><p>还可以调调margin，感觉margin会不会大了点</p><p>就指望你了，选用的 最简单的负样本，然后用了多个正样本</p><p>随机选一个负样本</p><p>随机选一个负样本+正样本构造</p><p><img src="/irra%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C/image-20240103200933847.png" alt="image-20240103200933847"></p><p>用triplet跑跑，还是多个正样本和，一个困难样本，然后*10</p><p>这个<strong>没搞头</strong></p><p><img src="/irra%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C/image-20240103204127632.png" alt="image-20240103204127632"></p><p>初始是大，后面太简单了，收敛太早了，根本训练不到</p><p>目前最好的效果</p><p>sdm+使用最难负样本和全部正样本</p><p>要Yue了，水不出来了</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mask</title>
    <link href="/2024/01/02/mask/"/>
    <url>/2024/01/02/mask/</url>
    
    <content type="html"><![CDATA[<p>mask操作</p><p>在计网里面学ip地址的时候，学ip地址这一章的时候</p><p>有一个子网掩码，掩码就是mask</p><p>定义来说，mask通常是指一个用来<strong>掩盖</strong>或<strong>选择</strong>特定位的二进制序列，或者是一个用来<strong>标记</strong>或<strong>过滤</strong>某些元素的布尔数组</p><p>对矩阵操作时</p><p>选择Id相同或不同</p><p>就是过滤到某些元素，就要使用<strong>布尔掩码</strong></p><p>大佬说的：gpu擅长并行计算</p><p>所以不要像以前的编程思想了，深度学习里面的计算都是矩阵运算了，谁还去写两个for循环啊</p>]]></content>
    
    
    
    <tags>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>np和list</title>
    <link href="/2024/01/02/np%E5%92%8Clist/"/>
    <url>/2024/01/02/np%E5%92%8Clist/</url>
    
    <content type="html"><![CDATA[<p>numpy和list本质上都是封装好了的数组</p><p>numpy底层用c语言实现的</p><p>list列表是python内置的</p><p>难怪老师要我好好学一下numpy啊，可惜我没听进去</p><p>NumPy 数组是由 C 语言编写的，支持广播（broadcasting）等高级操作</p>]]></content>
    
    
    
    <tags>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>范数norm</title>
    <link href="/2024/01/02/%E8%8C%83%E6%95%B0norm/"/>
    <url>/2024/01/02/%E8%8C%83%E6%95%B0norm/</url>
    
    <content type="html"><![CDATA[<p>范数（norm)是用于衡量向量空间中向量大小或长度的一种数学概念。是一种广义的距离度量，描述向量的大小和某种意义上的长度。</p><p>范数感觉跟模的概念好像</p><p>向量的大小或某种意义上的长度</p><p>L1范数</p><p>向量元素的绝对值之和   </p><p>edg [1,-1,2,3,-2] L1范数为3</p><p>L2范数（欧几里得范数）</p><p>向量元素的平方和的平方根</p><p>edg [1,2,3] L2范数 根号1的平方加2的平方加3的平方</p><p>torch.norm</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成一个简单的文本特征示例</span></span><br><span class="line">text_features = torch.tensor([</span><br><span class="line">    [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>],</span><br><span class="line">    [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>],</span><br><span class="line">    [<span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对文本特征进行归一化</span></span><br><span class="line">text_norm = text_features / text_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>torch.norm()dim参数指定哪一维，keepdim参数指定是否保持原维度</p><p>0用第一维，-1用倒数第一维</p><p>上面用倒数第一位，就是用的列，求列的范数，说实话，这不是按行求吗</p><p>混了混了真混了</p><p>不管了，跑代码的时候直接打断点看看就行了</p><p>torch.tensor</p><p>轻舟过了千重山了</p><p>这几天真的是，累成一条狗了</p><p>充实还是很充实的，能认识大佬跟着大佬学</p><p>就是一开始一个人要写这个损失函数的时候</p><p>真的是很焦虑啊很焦虑</p><p>人都吓病了</p><p>还好，这几天遇到的人啊都很好</p><p>家教很幸运遇到这个热情的一家</p><p>代码很幸运有这么一个大佬</p><p>朋友很幸运有那么一个朋友喊我玩</p><p>还有还有，王老师巨好巨好巨好</p><p>人不能是孤独的</p><p>一个人可能走得更快，但一群人一定走得更远</p><p>越来越赞同人是群居动物了，是处在社会关系中的</p>]]></content>
    
    
    
    <tags>
      
      <tag>pytorch torch.tensor</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>组会2</title>
    <link href="/2023/12/29/%E7%BB%84%E4%BC%9A2/"/>
    <url>/2023/12/29/%E7%BB%84%E4%BC%9A2/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>itc损失</title>
    <link href="/2023/12/29/itc%E6%8D%9F%E5%A4%B1/"/>
    <url>/2023/12/29/itc%E6%8D%9F%E5%A4%B1/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>transformer家族</title>
    <link href="/2023/12/27/transformer%E5%AE%B6%E6%97%8F/"/>
    <url>/2023/12/27/transformer%E5%AE%B6%E6%97%8F/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>修改主干网络</title>
    <link href="/2023/12/27/%E4%BF%AE%E6%94%B9%E4%B8%BB%E5%B9%B2%E7%BD%91%E7%BB%9C/"/>
    <url>/2023/12/27/%E4%BF%AE%E6%94%B9%E4%B8%BB%E5%B9%B2%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>pkl文件查看</title>
    <link href="/2023/12/27/pkl%E6%96%87%E4%BB%B6%E6%9F%A5%E7%9C%8B/"/>
    <url>/2023/12/27/pkl%E6%96%87%E4%BB%B6%E6%9F%A5%E7%9C%8B/</url>
    
    <content type="html"><![CDATA[<p>真就是基础不牢，地动山摇，后悔Python课没好好听了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取.pkl文件</span></span><br><span class="line">pkl_file_path = <span class="string">&#x27;/mnt/disk1/yyh/Person_reID_baseline_pytorch-master/id_path_CUHK.pkl&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(pkl_file_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> pkl_file:</span><br><span class="line">    id_path_dict = pickle.load(pkl_file)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印字典内容</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">id</span>, path <span class="keyword">in</span> id_path_dict.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;ID: <span class="subst">&#123;<span class="built_in">id</span>&#125;</span>, Path: <span class="subst">&#123;path&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p>读文件</p><p>rb以二进制的形式读取文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取 JSON 文件</span></span><br><span class="line">json_file_path = <span class="string">&#x27;/mnt/disk1/wcj/code/IRRA/data/CUHK-PEDES/reid_raw.json&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(json_file_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    data = json.load(json_file)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建字典，每个文件路径对应一个ID</span></span><br><span class="line">path_id_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">    id_value = item[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">    file_path = <span class="string">&#x27;/mnt/disk1/wcj/code/IRRA/data/CUHK-PEDES/imgs/&#x27;</span> + item[<span class="string">&#x27;file_path&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将当前文件路径作为键，对应的ID作为值</span></span><br><span class="line">    path_id_dict[file_path] = id_value</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存为 .pkl 文件</span></span><br><span class="line">pkl_file_path = <span class="string">&#x27;/mnt/disk1/yyh/Person_reID_baseline_pytorch-master/path_id_CUHK.pkl&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(pkl_file_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> pkl_file:</span><br><span class="line">    pickle.dump(path_id_dict, pkl_file)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Dictionary saved to <span class="subst">&#123;pkl_file_path&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>写文件</p><p>wb</p><p>以二进制的格式写文件，会覆盖原有文件</p><p>ab</p><p>以二进制的格式写文件，在文末追加</p>]]></content>
    
    
    
    <tags>
      
      <tag>python pkl</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>跟着李沐读论文——transformer</title>
    <link href="/2023/12/27/%E8%AE%BA%E6%96%87%E6%9C%AF%E8%AF%AD/"/>
    <url>/2023/12/27/%E8%AE%BA%E6%96%87%E6%9C%AF%E8%AF%AD/</url>
    
    <content type="html"><![CDATA[<p>layer law</p><p>batch law</p><p>横着切，竖着切</p><p><img src="/%E8%AE%BA%E6%96%87%E6%9C%AF%E8%AF%AD/image-20231227201609321.png" alt="image-20231227201609321"></p><p>decoder</p><p>multi head</p><p>auto regression自回归 以前时刻的输出作为当前的输入</p><p>transformer 模型中解码器有一个mask保证在当前时刻是看不到之后的输出的</p><p>分类器是可以包含很多层的，可以包含全连接层和激活函数，一般分类器的最后都是加上一个softmax激活函数</p><p>softmax指数函数会强调置信度高的地方，降低置信度低的地方，适合用做多分类问题的输出层</p><p>classifier(分类器)通常是指整个用来分类的模块或网络层，可能包括多个子层，以及激活函数等</p><p>classification head (分类头)通常是指分类结构的顶部</p><p>所以分类头一般是指分类器的最后一部分，在一定语境下两个也可以是同义的</p>]]></content>
    
    
    
    <tags>
      
      <tag>跟着李沐读论文 论文术语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra</title>
    <link href="/2023/12/27/irra/"/>
    <url>/2023/12/27/irra/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>irra模型使用指南</title>
    <link href="/2023/12/26/irra%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <url>/2023/12/26/irra%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p><img src="/irra%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/image-20231226163818025.png" alt="image-20231226163818025"></p><p>提取的特征文件</p><p>dense resnet50 swin</p><p>老师说的resnet101  vit模型代码里面没有啊</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VIT</title>
    <link href="/2023/12/26/VIT/"/>
    <url>/2023/12/26/VIT/</url>
    
    <content type="html"><![CDATA[<p>Vision Transformer</p><p>VIT需要数据集很大，效果才能很明显</p>]]></content>
    
    
    
    <tags>
      
      <tag>backbone network</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文</title>
    <link href="/2023/12/26/%E8%AE%BA%E6%96%87/"/>
    <url>/2023/12/26/%E8%AE%BA%E6%96%87/</url>
    
    <content type="html"><![CDATA[<p>实验</p><p>itcn</p><p>vit</p><p>resnet </p><p>resnet101</p><p>swin</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra图像id保存</title>
    <link href="/2023/12/25/irra%E5%9B%BE%E5%83%8Fid%E4%BF%9D%E5%AD%98/"/>
    <url>/2023/12/25/irra%E5%9B%BE%E5%83%8Fid%E4%BF%9D%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<p>irra模型训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用text_encode提特征</span></span><br><span class="line">        text_feats = self.base_model.encode_text(caption_ids)</span><br><span class="line">        t_feats = text_feats[torch.arange(text_feats.shape[<span class="number">0</span>]), caption_ids.argmax(dim=-<span class="number">1</span>)].<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">        logit_scale = self.logit_scale</span><br><span class="line">        ret.update(&#123;<span class="string">&#x27;temperature&#x27;</span>: <span class="number">1</span> / logit_scale&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;itc&#x27;</span> <span class="keyword">in</span> self.current_task:</span><br><span class="line">            ret.update(&#123;<span class="string">&#x27;itc_loss&#x27;</span>:objectives.compute_itc(i_feats, t_feats, logit_scale)&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;sdm&#x27;</span> <span class="keyword">in</span> self.current_task:</span><br><span class="line">            ret.update(&#123;<span class="string">&#x27;sdm_loss&#x27;</span>:objectives.compute_sdm(i_feats, t_feats, batch[<span class="string">&#x27;pids&#x27;</span>], logit_scale)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;cmpm&#x27;</span> <span class="keyword">in</span> self.current_task:</span><br><span class="line">            ret.update(&#123;<span class="string">&#x27;cmpm_loss&#x27;</span>:objectives.compute_cmpm(i_feats, t_feats, </span><br><span class="line">                                                            </span><br><span class="line">                                                            </span><br><span class="line">                                                            </span><br><span class="line">                                                            [<span class="string">&#x27;pids&#x27;</span>])&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;id&#x27;</span> <span class="keyword">in</span> self.current_task:</span><br><span class="line">            image_logits = self.classifier(i_feats.half()).<span class="built_in">float</span>()</span><br><span class="line">            text_logits = self.classifier(t_feats.half()).<span class="built_in">float</span>()</span><br><span class="line">            ret.update(&#123;<span class="string">&#x27;id_loss&#x27;</span>:objectives.compute_id(image_logits, text_logits, batch[<span class="string">&#x27;pids&#x27;</span>])*self.args.id_loss_weight&#125;)</span><br><span class="line"></span><br><span class="line">            image_pred = torch.argmax(image_logits, dim=<span class="number">1</span>)</span><br><span class="line">            text_pred = torch.argmax(text_logits, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            image_precision = (image_pred == batch[<span class="string">&#x27;pids&#x27;</span>]).<span class="built_in">float</span>().mean()</span><br><span class="line">            text_precision = (text_pred == batch[<span class="string">&#x27;pids&#x27;</span>]).<span class="built_in">float</span>().mean()</span><br><span class="line">            ret.update(&#123;<span class="string">&#x27;img_acc&#x27;</span>: image_precision&#125;)</span><br><span class="line">            ret.update(&#123;<span class="string">&#x27;txt_acc&#x27;</span>: text_precision&#125;)</span><br></pre></td></tr></table></figure><p>四种损失函数itc,sdm,cmpm,id</p><p>图片准确率比文本准确率还高</p><p>那么batch[‘pids’]</p><p>修改：</p><p>生成正负样本</p><p>定义损失函数（对比学习，三元组损失）</p><p>task:</p><p>1.代码都写一份呗  pkl</p><p>一份id作为键，path作为值</p><p>一份path作为键，id作为值</p><p>2.再训练几个用来提取图片特征的模型</p><p>resnet50 resnet100</p><p>swin </p><p>VIT</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>json文件</title>
    <link href="/2023/12/25/json%E6%96%87%E4%BB%B6/"/>
    <url>/2023/12/25/json%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<p><strong>JSON</strong></p><p>javascript object notation </p><p>js对象表示法</p><p>CUHK-PEDES数据集</p><p>每个元素是用字典表示的，然后所有元素放在一个列表里面是吗，字典里面的键有split captions file_path processed_tokens id</p>]]></content>
    
    
    
    <tags>
      
      <tag>数据集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra数据集</title>
    <link href="/2023/12/25/irra%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2023/12/25/irra%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>sdm损失函数</title>
    <link href="/2023/12/24/sdm%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/2023/12/24/sdm%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>term</p><p><strong>loss function</strong> 损失函数 定义<strong>单个样本</strong>与<strong>真实值</strong>之间的误差</p><p><strong>cost function</strong> 代价函数 定义一个<strong>batch</strong>或者整个<strong>数据集</strong>与真实值之间的误差</p><p><strong>objective function</strong> 目标函数 泛指任意可以被优化的函数</p><p>损失函数是代价函数的一部分，代价函数是目标函数的一种类别</p><p>用来最小化目标函数常用的方法就是<strong>梯度下降法</strong>（gradient decent)</p><p>损失函数衡量模型作出的预测与真实值（<strong>ground truth</strong>)之间的偏离程度</p><p>损失函数有两大类别，<strong>回归（regression)损失</strong>,<strong>分类（classification)损失</strong></p><p><strong>分类损失</strong></p><p>计算机本质上都是在做分类问题，计算机只会0101</p><p><strong>熵</strong></p><p>熵是用于描述对<strong>不确定性</strong>的度量</p><blockquote><p>传输1比特的信息意味着将接收者的不确定性降低2倍。 —— 香浓</p></blockquote><p><img src="/sdm%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20231224210029301.png" alt="image-20231224210029301"></p><p>X是随机变量，P(xi)是X取值为xi的概率</p><p>熵是非负的</p><p><strong>交叉熵</strong></p><p>交叉熵则是用来衡量两个概率分布之间的相似度</p><p><img src="/sdm%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20231224210825781.png" alt="image-20231224210825781"></p><p>P(xi)是真实的概率分布，Q(xi)是模型给出的概率分布</p><p><img src="/sdm%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20231224211313632.png" alt="image-20231224211313632"></p><p>讲得太好了，大师我悟了</p><p>信息的不确定性降两倍，log2(x),所以公式里面才会出现对数</p><p>用真实分布去<strong>加权计算</strong>模型分布的<strong>负对数概率</strong>，对混乱程度需要的表示位数进行加权，</p><p>交叉熵是KL散度的一种特殊情况</p><p>SDM</p><p>similarity distribution matching</p><p>相似度分布匹配</p>]]></content>
    
    
    
    <tags>
      
      <tag>损失函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra修改损失函数</title>
    <link href="/2023/12/24/irra%E4%BF%AE%E6%94%B9%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/2023/12/24/irra%E4%BF%AE%E6%94%B9%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p><strong>sdm</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>电桥</title>
    <link href="/2023/12/24/%E7%94%B5%E6%A1%A5/"/>
    <url>/2023/12/24/%E7%94%B5%E6%A1%A5/</url>
    
    <content type="html"><![CDATA[<p><strong>应变</strong></p><p>物体在受到外部力或应变时，其形状、大小或体积可能会发生变化，这种变化称为应变。</p><p><strong>桥式电路</strong></p><p>电桥是一种电路结构，通常用来测量电阻或者检测物理量的变化。</p><p><strong>平衡电桥</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>电路</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Girls_can_change_the_world</title>
    <link href="/2023/12/24/Girls-can-change-the-world/"/>
    <url>/2023/12/24/Girls-can-change-the-world/</url>
    
    <content type="html"><![CDATA[<p><a href="https://ejoy-english.com/go/video/girls-can-change-the-world/53">Girls Can Change the World | eJOY English (ejoy-english.com)</a></p><p>Girls can change the world</p><p>I am really <strong>passionate</strong> about the climate change. 充满热情的</p><p>My interest is to find a cure for <strong>breast cancer</strong> because my mom had it.乳腺癌</p><p>I wanna make sure that we’re able to have a <strong>self-sustaining</strong> environment 自给自足的</p>]]></content>
    
    
    
    <tags>
      
      <tag>英语打卡</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模型训练结果</title>
    <link href="/2023/12/24/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C/"/>
    <url>/2023/12/24/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C/</url>
    
    <content type="html"><![CDATA[<p><strong>训练结果</strong></p><p>损失函数loss&#x3D;mlm+id+sdm</p><p>epoch 50</p><p>训练图片编码器+文本编码器</p><p>速度1min20s</p><p>最终loss 10</p><p>最终准确率70多</p><p>损失函数loss&#x3D;sdm+id</p><p>epoch18 达到了最高准确率 40</p><p>训练文本编码器</p><p>速度4s</p><p>最终loss </p><p>最终准确率37.8</p><p>抽空把博客给整理一下，把图片不能显示的问题解决了，然后设置按时传到网站上</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gpu</title>
    <link href="/2023/12/24/gpu/"/>
    <url>/2023/12/24/gpu/</url>
    
    <content type="html"><![CDATA[<p>LINUX终端查看GPU使用情况</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p> NVIDIA System Management Interface</p><p>LINUX终端查看cpu内存情况</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">free -h</span><br></pre></td></tr></table></figure><p>gpu显存</p><p><img src="/gpu/image-20231224122742957.png" alt="image-20231224122742957"></p><p>cpu内存</p><p><img src="/gpu/image-20231224134306991.png" alt="image-20231224134306991"></p><p>Cpu</p><p>中央处理器</p><p>RAM条 <strong>内存</strong></p><p>我电脑只有16个G</p><p>GPU</p><p>图形处理器</p><p>GPU Memory <strong>显存</strong></p><p>显卡内存，图形存储器</p><p>4090显存24G</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模型数据转移</title>
    <link href="/2023/12/24/%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB/"/>
    <url>/2023/12/24/%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB/</url>
    
    <content type="html"><![CDATA[<p>tips</p><p><strong>查看数据是在cpu还是在gpu</strong></p><p><em>python包pdb(python debugger)</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pdb</span><br><span class="line">pdb.set_trace()</span><br></pre></td></tr></table></figure><p>终于懂了老师之前说的可能一次全部加载gpu会放不下的意思了</p><p>我真服了，之前不搜，白走了这么久的弯路</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB/image-20231224141055528.png" alt="image-20231224141055528"></p><p>特征文件只有83M，gpu显存妥妥的可以放的下啊</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB/image-20231224141844676.png" alt="image-20231224141844676"></p><p>特征全部放到gpu上</p><p>报错</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB/image-20231224135614090.png"></p><p>后面的数据集的build函数会出问题，因为build函数写的是处理cpu上的数据</p><p>特征全部放到cpu上</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB/image-20231224142236040.png" alt="image-20231224142236040"></p><p>直接把.cuda() 改成.cpu()就可以了</p><p>.cuda()里面可以传参数选定使用哪块gpu，.cpu()不可以传参数</p><p>卧槽，换了之后巨快训练</p><p>我真的是服了我之前，数据都放在外存，每个batch都去外存取，怎么想的啊，你怎么敢的</p><p>4s一批次，之前一分半一批次，啊啊啊，真的难绷，这还是放在cpu上的</p><p>内存五十多g，显存24G,哈哈哈哈</p><p>硬件好软件写的稀巴烂也不行啊，暴殄天物啊</p><p>现在训练比原来快了十倍了</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模型冻结</title>
    <link href="/2023/12/23/%E6%A8%A1%E5%9E%8B%E5%86%BB%E7%BB%93/"/>
    <url>/2023/12/23/%E6%A8%A1%E5%9E%8B%E5%86%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>傅里叶变换</title>
    <link href="/2023/12/23/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    <url>/2023/12/23/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<p><strong>傅里叶级数</strong>和<strong>傅里叶变换</strong></p><p><strong>无穷级数</strong></p><p><strong>级数</strong><br>$$<br>\sum_{n&#x3D;0}^{\infty}a_n<br>$$<br>级数可以是<strong>收敛</strong>的，也可以是<strong>发散</strong>的</p><p>级数是一种数学结构，表示无穷多个数的和</p><p><strong>幂级数</strong><br>$$<br>\sum_{n&#x3D;0}^{\infty}a_nx^n<br>$$<br>每个项都是常量乘以变量的幂</p><p>幂级数有时可以表示为一个函数，当 x 取某些值时，级数收敛于一个特定的函数值。</p><p><strong>泰勒级数</strong></p><p>泰勒级数展开的目的是在给定点附近用多项式逼近原始函数。</p><p>在特定点展开成无穷级数来模拟函数</p><p>应用：<strong>函数逼近</strong> <strong>极值问题</strong> <strong>微分方程</strong> <strong>信号处理和控制系统</strong></p><p><strong>麦克劳林级数</strong></p><p>在零点展开的泰勒级数</p><p>把复杂的函数表示为<strong>幂级数</strong><br>$$<br>e^x&#x3D;1+x+\frac{x^2}{2!}+\frac{x^3}{3!}…<br>$$</p><p><strong>傅里叶级数</strong></p><p>任何<strong>周期函数</strong>都可以表示成正弦函数和余弦函数之和<br>$$<br>f(x)&#x3D;a_0+\sum_{n&#x3D;1}^{\infty}[a_ncos(2{\pi}nf_0t)+b_nsin(2{\pi}nf_0t)]<br>$$<br>傅里叶级数是一种特殊的级数形式，是正弦和余弦叠加的级数形式</p><p>傅里叶级数的核心思想就是<strong>任何一个周期函数都可以表示为不同频率的正弦和余弦函数的叠加。</strong></p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223174820638.png" alt="image-20231223174820638"></p><p>让我们以一种直观的方式来理解傅里叶级数。想象一个音乐盒，这个音乐盒里的旋律是我们要研究的周期性函数。</p><ol><li><strong>周期性函数就像音乐盒的旋律：</strong> 如果我们把音乐盒的旋律看作是一个周期性函数，那么这个旋律在一段时间内会重复。这个周期可以类比为函数的周期。</li><li><strong>正弦和余弦函数就像音乐盒的基本音符：</strong> 傅里叶级数告诉我们，任何复杂的旋律都可以由一系列简单的正弦和余弦函数组成，就像任何复杂的周期函数都可以由一系列正弦和余弦函数的组合构成。这些正弦和余弦函数可以被看作是音乐盒的基本音符。</li><li><strong>傅里叶系数就像音符的振幅：</strong> 傅里叶系数告诉我们每个正弦和余弦函数在这个旋律中的“重要性”，就像每个音符在音乐盒旋律中的振幅一样。</li><li><strong>级数的逼近性质就像用有限音符逼近旋律：</strong> 当我们播放音乐盒时，如果只选择有限的音符，我们可能无法完美地重现原始旋律，但我们可以逼近。傅里叶级数也是这样，通过选择适当数量的正弦和余弦函数，我们可以逼近原始的周期函数。</li><li><strong>高频率的音符就像复杂的细节：</strong> 如果我们选择高频率的音符，就像在傅里叶级数中选择较大的 <em>n</em>，我们可以更好地捕捉周期函数的细节和急剧的变化。</li></ol><p>这个类比有助于理解傅里叶级数的核心思想：任何周期性的复杂函数都可以通过适当选择的正弦和余弦函数的组合来表示。就像音乐盒的旋律可以通过简单的音符组成，周期函数的形状可以通过简单的正弦和余弦函数组成。</p><p>基本频率f_0 频率 n*f_0</p><p><strong>时域</strong></p><p>信号在时间轴上的变化</p><p><strong>频域</strong></p><p>信号在频率轴上的变化</p><p><strong>复平面</strong></p><p>复数构成的平面</p><p>实数用一个实轴表示，而复数需要使用一个复平面来表示</p><p><strong>基波</strong></p><p>频率最小的那个波，通常是第一个谐波</p><p><strong>谐波</strong></p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223192859162.png" alt="image-20231223192859162"></p><p><strong>傅里叶变换</strong></p><p>将时域信号里面的的不同频率，不同振幅的信号分解出来</p><p><strong>逆傅里叶变换</strong></p><p><strong>拉普拉斯变换</strong></p><p>将时域函数变成复平面上的函数</p><p>拉普拉斯变换可以将时域上的<strong>微分方程</strong>转换为复频域上的<strong>代数方程</strong></p><p><strong>具体例子</strong></p><p>弹簧–质点系统的微分方程：</p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223200131503.png" alt="image-20231223200131503"></p><p>m表示质点质量，c表示阻尼，k表示弹性系数，x(t)是位移，F(t)是外力</p><p>时域函数x(t)拉普拉斯变换为X(s),时域函数F(t)拉普拉斯变换后F(s),s是复平面上的复数，<em>s</em>&#x3D;<em>σ</em>+<em>jω</em></p><p>微分方程通过拉普拉斯变换后：</p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223200305119.png" alt="image-20231223200305119"></p><p>传递函数</p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223200828465.png" alt="image-20231223200828465"></p><p>特征方程</p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223200923837.png" alt="image-20231223200923837"></p><p><strong>逆拉普拉斯变换</strong></p><p>通过傅里叶变换和拉普拉斯变换可以将时域信号变成频域信号，频域函数通常是复平面上的函数</p><p>通过逆傅里叶变换和逆拉普拉斯变换可以将频域信号变成时域信号</p><p>在控制系统中，拉普拉斯变换用于分析系统的稳定性和动态响应，而傅里叶变换则更适合分析信号的频谱特性。</p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223201207987.png" alt="image-20231223201207987"></p><p>该说不说，chatgpt讲的好啊，是真的形象啊</p><p>补充关于<strong>线性时不变系统</strong>里面的一些知识点</p><p><strong>传递函数</strong></p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223204247835.png" alt="image-20231223204247835"></p><p>传递函数是输出除以输入，关于复频域变量s的函数</p><p><img src="/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/image-20231223204432818.png" alt="image-20231223204432818"></p><p><strong>特征方程</strong></p><p>分母一般就是特征方程，其值决定了系统的稳定性和动态响应</p><p>（线代里面也有特征方程，特征向量，现在已经忘关了，抽时间看看）</p>]]></content>
    
    
    
    <tags>
      
      <tag>高数 自控</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读1</title>
    <link href="/2023/12/23/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB1/"/>
    <url>/2023/12/23/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB1/</url>
    
    <content type="html"><![CDATA[<p>WPE</p><p>setting背景</p><p>大量数据集</p><p>新的数据集（样本量很少）</p><p>n位k shot</p><p>什么是shot</p><p>迁移学习</p><p>高斯分布？？？（正态分布）</p><p>什么叫特征符合高斯分布？</p><p>特征就是预测结果，那个类别大，在那个地方的值就大，使用softmax激活函数将数值向量归一化为一个概率分布向量</p><p>topk</p><p>similarity measure怎么计算的</p><p>概率分布，预测概率属于什么分布</p><p>什么叫原型？</p><p>关系原型？</p><p>不确定性</p><p>prototype</p><p>三元组</p><p>分类，预测一个值</p><p>文章分类</p><p>第一篇差不多听懂了</p><p>第二篇第三篇不懂</p><p><strong>原型模型（Prototype Model）：</strong> 在监督学习中，原型模型是一种基于实例的学习方法。该方法的核心思想是将每个类别表示为该类别中所有实例的平均值或中心点。当有新实例需要分类时，通过比较新实例与每个类别的中心点的相似度来进行分类。</p><p>伪标签</p><p>模型冻结</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>前后端连接bug</title>
    <link href="/2023/12/22/%E5%89%8D%E5%90%8E%E7%AB%AF%E8%BF%9E%E6%8E%A5bug/"/>
    <url>/2023/12/22/%E5%89%8D%E5%90%8E%E7%AB%AF%E8%BF%9E%E6%8E%A5bug/</url>
    
    <content type="html"><![CDATA[<p>找了这么久的bug，通过前端console.log(useId)，在控制台看到输出为2，没有任何问题，还以为是前端成功发送了，问题一定出在后端，没想到找了这么久，问题居然还是出在前端</p><p>解决思路</p><p>首先后端排查</p><p>数据库执行语句完全没有任何问题，把前端显示的值放在数据库中执行是能正确查询的</p><p>然后后端返回值，先替换成随便写的数据，也是能返回前端的。</p><p>所以问题就出在前端向后端发送以及后端查询这部分</p><p>排查是后端查询的问题，也直接把2赋值给后端让它不用去从前端数据库解析，结果也能成果执行</p><p>所以问题就是在后端并不能从前端传来的数据中解析到数据</p><p>可是控制台显示前端的数据没有问题啊</p><p>body: ‘userId&#x3D;’ + encodeURIComponent(userId)</p><p>body: JSON.stringify({ userId: userId })</p><p>问题就在这里，</p><p>居然是前端传的这个数据形式后端不能解析，气死我了，虽然我也看不懂第一个传的是什么形式，但当时想着chatgpt写的应该是不会有问题的，结果没想到问题就在这</p><p>担心接口问题</p><p>没想到编码不能被解析  啊啊啊</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs 网站开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>检索模型VSM</title>
    <link href="/2023/12/21/%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8BVSM/"/>
    <url>/2023/12/21/%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8BVSM/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>信息检索</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>构建k近邻矩阵</title>
    <link href="/2023/12/21/%E6%9E%84%E5%BB%BAk%E8%BF%91%E9%82%BB%E7%9F%A9%E9%98%B5/"/>
    <url>/2023/12/21/%E6%9E%84%E5%BB%BAk%E8%BF%91%E9%82%BB%E7%9F%A9%E9%98%B5/</url>
    
    <content type="html"><![CDATA[<p><strong>TF（词频，Term Frequency）</strong>：衡量一个词在文档中的出现频率。通常采用词频除以文档总词数的方式计算，以消除文档长度的影响。</p><p><strong>IDF（逆文档频率，Inverse Document Frequency）</strong>：衡量一个词对整个文档集合的重要性。</p><p>IDF</p><p>逆文档频率</p><p>TF-IDF矩阵</p>]]></content>
    
    
    
    <tags>
      
      <tag>信息检索</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>xml文档树</title>
    <link href="/2023/12/20/xml%E6%96%87%E6%A1%A3%E6%A0%91/"/>
    <url>/2023/12/20/xml%E6%96%87%E6%A1%A3%E6%A0%91/</url>
    
    <content type="html"><![CDATA[<p><strong>项目示例代码</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 XML 文档树</span></span><br><span class="line">        doc = ET.Element(<span class="string">&quot;doc&quot;</span>)</span><br><span class="line">        ET.SubElement(doc, <span class="string">&quot;id&quot;</span>).text = <span class="string">&quot;%d&quot;</span>%(i)</span><br><span class="line">        ET.SubElement(doc, <span class="string">&quot;url&quot;</span>).text = news[<span class="number">1</span>]</span><br><span class="line">        ET.SubElement(doc, <span class="string">&quot;title&quot;</span>).text = news[<span class="number">2</span>]</span><br><span class="line">        ET.SubElement(doc, <span class="string">&quot;datetime&quot;</span>).text = news[<span class="number">0</span>]</span><br><span class="line">        ET.SubElement(doc, <span class="string">&quot;body&quot;</span>).text = body</span><br><span class="line">        <span class="comment"># 创建 XML 文档对象并写入文件</span></span><br><span class="line">        tree = ET.ElementTree(doc)</span><br><span class="line">        tree.write(doc_dir_path + <span class="string">&quot;%d.xml&quot;</span>%(i), encoding = doc_encoding, xml_declaration = <span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 更新计数器</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 每抓取 500 条新闻后，等待 3 分钟</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Sleeping for 3 minute&quot;</span>)</span><br><span class="line">            time.sleep(<span class="number">180</span>)</span><br></pre></td></tr></table></figure><p>看着这段代码</p><p>看得懂吗？不懂才对。</p><p>ET.Element</p><p>ET.SubElement</p><p>xml树，xml文档，这些都是什么啊？</p><p>带着疑问去学</p><p><strong>什么是xml</strong></p><p>xml与html类似，都是<em>标记</em>语言，但是html是用<em>呈现数据</em>，而xml是用来<em>存储</em>和<em>传递</em>数据，xml以<em>文档</em>的形式保存</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">person</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>John Doe<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">age</span>&gt;</span>30<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">city</span>&gt;</span>New York<span class="tag">&lt;/<span class="name">city</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">person</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这种用标签包裹信息就是标记语言,总而言之，xml是一种用来存储和传递数据的语言，xml是一种用来存储和传递数据的语言,xml是一种用来存储和传递数据的语言！！！重要的事说三遍</p><p><strong>xml树</strong></p><p>python中常用来解析xml文档的数据结构，将xml描述成树状结构。</p><p>好，问题来了，上面看不懂的代码就是使用了python的xml解析库。</p><p>让我们先放放，去看看python的xml解析库中都有什么？</p><p><strong>python解析xml库</strong></p><p><code>xml.etree.ElementTree</code></p><p>python中最常见的用来解析xml文档的库，解析为树状结构</p><p><em>用法</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br></pre></td></tr></table></figure><p>看见ET一般就是指python的xml树状结构解析库</p><p>树状结构的特点</p><p>根节点，叶节点</p><p>节点之间存在父子的关系</p><p>因此，xml树状解析库可以将xml表示成树状结构，找出文档中根节点元素以及其它节点，从而表示出标签之间的关系</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析XML字符串</span></span><br><span class="line">xml_string = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;root&gt;</span></span><br><span class="line"><span class="string">    &lt;person&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;John Doe&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;age&gt;30&lt;/age&gt;</span></span><br><span class="line"><span class="string">        &lt;city&gt;New York&lt;/city&gt;</span></span><br><span class="line"><span class="string">    &lt;/person&gt;</span></span><br><span class="line"><span class="string">&lt;/root&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root = ET.fromstring(xml_string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历XML树</span></span><br><span class="line"><span class="keyword">for</span> person <span class="keyword">in</span> root.findall(<span class="string">&#x27;person&#x27;</span>):</span><br><span class="line">    name = person.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">    age = person.find(<span class="string">&#x27;age&#x27;</span>).text</span><br><span class="line">    city = person.find(<span class="string">&#x27;city&#x27;</span>).text</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Name: <span class="subst">&#123;name&#125;</span>, Age: <span class="subst">&#123;age&#125;</span>, City: <span class="subst">&#123;city&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>寻找对应名字的元素，和字典中键来查找类似</p><p>这样，就有一棵完美的树了，还可以从树里面取出想要的数据</p>]]></content>
    
    
    
    <tags>
      
      <tag>信息检索</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模型训练错误</title>
    <link href="/2023/12/20/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%94%99%E8%AF%AF/"/>
    <url>/2023/12/20/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%94%99%E8%AF%AF/</url>
    
    <content type="html"><![CDATA[<p>当模型训练到一定epoch时，被打断了</p><p>怎么回复模型状态，重新接着训练？</p>]]></content>
    
    
    
    <tags>
      
      <tag>经验总结 模型训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra模型修改中遇到的问题</title>
    <link href="/2023/12/20/irra%E6%A8%A1%E5%9E%8B%E4%BF%AE%E6%94%B9%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2023/12/20/irra%E6%A8%A1%E5%9E%8B%E4%BF%AE%E6%94%B9%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p><strong>steps</strong></p><p>first:修改dataloader,把batch里面加上返回图片特征。batch会自动打包，在batch里面用图片路径获取图片特征时使用的就是一个路径。不需要处理路径列表，加载许多图片特征。</p><p>second:修改模型文件里面的irra模型类，把forward方法里面的使用图片编码器给替换成直接从batch字典里面读取图片特征。</p><p>third:修改utils文件中的metric文件</p><p><strong>bugs</strong></p><p>首先当发现直接把图片特征放在batch里面一起返回回来，（居然没有让我做toTensor操作，batch加载看来功能很多啊），注释掉了图片编码器函数），以为就把模型改好了</p><p>然后发现后面模型训练一轮要进行验证checkpoint并且保存时，开始报错（怪了，那每一轮不同批次准确率是怎么确定的，怎么不报错啊),然后发现报错了，utils文件中的metric文件进行模型验证的时候使用到了图片编码器函数。（现在看来如果不直接注释掉图片编码器函数会怎么样呢，准确率会很低，图片编码器没被训练到？）</p><p>就开始了漫漫修改之路</p><p>首先在metric文件中修改传入图片编码器的数据，之前是图片列表，修改成图片路径列表</p><p>然后方式1，直接在metrc文件里面吧图片编码器部分给替换成提取特征的函数。</p><p>在方法1遇到的问题，首先和直接用在batch里面使用的提取特征函数，用不了，因为一个图片路径就是路径，一个图片路径是路径列表，是很多个</p><p>然后吧提特征函数换成列表的，结果然后提取的特征是np数组，不可以使用。接着改成tensor数据类型，然后是很多个tensor，事实上只能返回一个tensor，接着又用stack函数，把很多个tensor压缩成一个tensor。</p><p>后面还有一些奇奇怪怪的错误，没有把tensor类型数据放在gpu上等。还是具体细节不清楚啊</p><p>方法二</p><p>在model的build文件中修改</p><p>模型把图片编码器部分改了之后训练起来真的超级超级慢</p><p>为什么</p><p>明明少训练了一部分，结果训练速度慢了三倍</p><p>模型改了之后</p><p>xxxxxxxxxx pythonCopy codedef forward(self, batch):    ret &#x3D; dict()​    caption_ids &#x3D; batch[‘caption_ids’]    image_feats &#x3D; self.load_image_features(batch[‘image_feature_path’])    text_feats &#x3D; self.base_model.encode_text(caption_ids)​    i_feats &#x3D; image_feats[:, 0, :].float().detach()  # 使用detach()防止梯度更新    t_feats &#x3D; text_feats[torch.arange(text_feats.shape[0]), caption_ids.argmax(dim&#x3D;-1)].float()​    logit_scale &#x3D; self.logit_scale    ret.update({‘temperature’: 1 &#x2F; logit_scale})​    # 其余的任务处理保持不变…​    return retpython</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E4%BF%AE%E6%94%B9%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/image-20231221134033962.png" alt="image-20231221134033962"></p><p>我还怕会是我去来的图片特征不对</p><p>想想用之前模型训练的文本编码器是通过哪一个图片编码器的特征对比学习的，现在换成了另一个模型提取的图片特征，两个特征的相似度低应该才是正常的</p><p>问题</p><p>怎么调试啊，需要传递参数的时候</p><p>我已经忘了之前是怎么调试的了</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs 主干网络替换</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>变量大小查看</title>
    <link href="/2023/12/20/%E5%8F%98%E9%87%8F%E5%A4%A7%E5%B0%8F%E6%9F%A5%E7%9C%8B/"/>
    <url>/2023/12/20/%E5%8F%98%E9%87%8F%E5%A4%A7%E5%B0%8F%E6%9F%A5%E7%9C%8B/</url>
    
    <content type="html"><![CDATA[<p>跑深度学习模型进行数据处理时会遇到很多变量类型，常见的有字典，元组，列表，张量</p><p>字典：通过键来进行索引</p><p>元组：通过下标进行索引（不可变）   </p><p>列表：通过下标进行索引（可变）</p><p>（字典和元组都是有序的，元组一般比较短，所以经常没有给出下标索引，而是直接按顺序就赋值了 edg:t&#x3D;tuple((1,2)),x,y&#x3D;t  元组用(),列表用[]）</p><p>张量：tensor</p><p><strong>确定变量类型</strong></p><p>使用type()函数确定变量类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">variable = <span class="number">42</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(variable))  <span class="comment"># &lt;class &#x27;int&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line">variable = <span class="string">&quot;Hello, World!&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(variable))  <span class="comment"># &lt;class &#x27;str&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line">variable = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(variable))  <span class="comment"># &lt;class &#x27;list&#x27;&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>查看不同类型变量的大小</strong></p><p><strong>张量</strong>：使用shape属性</p><p><strong>列表</strong>：</p><p><strong>元组</strong>：</p><p><strong>字典</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>模型代码调试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch中对张量的处理</title>
    <link href="/2023/12/20/pytorch%E4%B8%AD%E5%AF%B9%E5%BC%A0%E9%87%8F%E7%9A%84%E5%A4%84%E7%90%86/"/>
    <url>/2023/12/20/pytorch%E4%B8%AD%E5%AF%B9%E5%BC%A0%E9%87%8F%E7%9A%84%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>Pytorch中torch.cat函数将一个列表中的张量按照指定的维度拼接成一个张量</p><p>张量列表-&gt;张量    维度不变</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设 gids 是一个包含两个张量的列表</span></span><br><span class="line">tensor1 = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor2 = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">gids=[tensor1,tensor2]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 torch.cat 沿着第 0 维（行）拼接这两个张量</span></span><br><span class="line">result = torch.cat(gids, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result.shape)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#输出</span></span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">torch.Size([<span class="number">6</span>])</span><br></pre></td></tr></table></figure><p>这样result就是一个一维的张量了，包含了两个原始的两个张量信息</p><p>Pytorch中torch.stack函数将一个列表中的张量在一个新的维度上堆叠成一个张量</p><p>张量列表-&gt;张量 维度改变</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设 gids 是一个包含两个张量的列表</span></span><br><span class="line">tensor1 = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor2 = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">gids=[tensor1,tensor2]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 torch.stack 沿着第 0 维（行）堆叠这两个张量</span></span><br><span class="line">result = torch.stack(gids, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#输出</span><br><span class="line">tensor([[1, 2, 3],</span><br><span class="line">        [4, 5, 6]])</span><br><span class="line"></span><br><span class="line">torch.Size([2, 3])        </span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>倒排索引构建</title>
    <link href="/2023/12/20/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E6%9E%84%E5%BB%BA/"/>
    <url>/2023/12/20/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E6%9E%84%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h4 id="什么是倒排索引"><a href="#什么是倒排索引" class="headerlink" title="什么是倒排索引"></a>什么是倒排索引</h4><p>倒排索引以词项为基础，倒排索引以词项为基础，倒排索引以词项为基础！！！</p><p>词项term</p><p>倒排索引提供<strong>由词项到文本的映射</strong></p><p><strong>倒排索引表</strong></p><p><em>词项</em> <em>文档频率</em> <em>文档信息</em>*</p><p>为什么要统计词项在文档中出现的频率，因为频率越高，重要性越低</p><p><strong>倒排索引构建的数据库posting的具体格式</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE postings (</span><br><span class="line">    term TEXT PRIMARY KEY,</span><br><span class="line">    df INTEGER,</span><br><span class="line">    docs TEXT</span><br><span class="line">);</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>信息检索</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>web开发cookie设置</title>
    <link href="/2023/12/18/web%E5%BC%80%E5%8F%91cookie%E8%AE%BE%E7%BD%AE/"/>
    <url>/2023/12/18/web%E5%BC%80%E5%8F%91cookie%E8%AE%BE%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p>我真的是又服气了</p><p>不想敲代码了，敲几天了，要吐了，不行，我考研真不想考计算机了</p><p>这个浏览器保存cookie，为了保存用户登录信息，保存用户id来实现后续功能</p><p>明明前几天的代码还能用的，那天晚上一直改一直改网页开太多了，把我edge都搞崩了</p><p>今天代码改死也没改好，就是不能保存更新cookie，一直显示cookie undefined。</p><p>结果呢，我把edge的cookie信息都清除一下，就好了，你说气人不</p><p>跟修电脑一样，重启再说</p><p>哎，一直不肯清cookie，这不是不想重新登chatgpt嘛，得重新换一下微软账号，不然qq邮箱登不上去openai。</p><p>真服气，麻烦就是省不了啊</p>]]></content>
    
    
    
    <tags>
      
      <tag>bug web开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>服务器渲染模式</title>
    <link href="/2023/12/15/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B8%B2%E6%9F%93%E6%A8%A1%E5%BC%8F/"/>
    <url>/2023/12/15/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B8%B2%E6%9F%93%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<p>服务器渲染模式 前端渲染模式</p><p><strong>服务器渲染模式SSR</strong></p><p><em>Server-Side Rendering</em></p><p>python中 render template(‘index.html’)</p><p><strong>服务端处理（PHP）:</strong></p><ul><li>通过 <code>include</code> 引入外部 HTML 模板文件（<code>index_template.php</code>）。</li><li>执行任何 PHP 逻辑或动态内容生成。</li><li>生成最终的 HTML 内容。</li></ul><p> console.<strong>log</strong>(xhr.responseText);</p><p>难怪浏览器输出的是一大页html代码</p><p><strong>客户端渲染CSR</strong></p><p><em>Customer-Side Rendering</em></p><ul><li>使用 AJAX 或其他前端技术从服务端获取数据，通常以 JSON 格式返回。</li><li>在客户端使用 JavaScript 处理这些数据，动态地更新页面内容。这样的方式被称为单页应用（SPA）模型。</li><li>由于客户端渲染，页面的初始加载可能较快，但搜索引擎对于初始页面内容的索引可能会受到一些影响。</li></ul><p>浏览器判断后端相应数据类型</p><p><strong>HTML 页面的响应头</strong></p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: text/html; charset=utf-<span class="number">8</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>JSON 数据的响应头</strong></p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: application/json; charset=utf-<span class="number">8</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>动态模板引擎是一种后端渲染模式吗？</p><p><strong>DOM</strong></p><p>文档对象模型</p><p>document object model</p><p><strong>无刷新分页</strong></p><p><strong>分页逻辑</strong></p><p>使用的是<strong>后端分页</strong>，每次更新页面都向后端发起一次请求，一次获取十条数据。</p><p>如果使用<strong>前端分页</strong>，则一次向后端请求所有数据，每次更新页面不用向后端重新请求，更新速度快。</p><ol><li><p><strong>减轻后端压力：</strong> 后端只需一次性提供全部数据，而不需要为每个页面的请求生成数据。</p></li><li><p><strong>快速切换：</strong> 用户在不同页面之间切换更加迅速，因为不需要等待后端响应。</p><p>如果数据量非常庞大，一次性传输可能会导致较大的网络开销。</p></li></ol><p>search页面</p><p>使用DOM元素</p><p>id&#x3D;x</p><p>x可以作为一个dom元素，在html页面中被选中动态更改。</p><p><strong>网页安全</strong></p><p><strong>版权</strong></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;copy;</span> <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> today = <span class="keyword">new</span> <span class="title class_">Date</span>();</span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> year = today.<span class="title function_">getFullYear</span>();</span></span><br><span class="line"><span class="language-javascript">                <span class="variable language_">document</span>.<span class="title function_">write</span>(year)</span></span><br><span class="line"><span class="language-javascript">            </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span> 新闻网 | Author: klull</span><br></pre></td></tr></table></figure><p>点赞 收藏 功能</p><p>首页想弄个时钟，太麻烦了</p><p>首页和搜索页没分离开，算了时钟功能先舍弃，一般搜索引擎也没放时钟嘛，放其他不用动态更新的也挺美观</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">resultContainer.innerHTML = `</span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;text-align: center; padding: 20px; border: 1px solid #ccc; border-radius: 8px; max-width: 400px; background-color: #f8f8f8; margin: 0 auto;&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">strong</span> <span class="attr">style</span>=<span class="string">&quot;color: #333; display: block; margin-bottom: 10px;&quot;</span>&gt;</span>Welcome to the Search Engine<span class="tag">&lt;/<span class="name">strong</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;color: #666; display: block; margin-bottom: 10px;&quot;</span>&gt;</span>Please enter keywords to start your search.<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;color: #666; display: block;&quot;</span>&gt;</span>Current time: $&#123;timeString&#125;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    `;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">resultContainer.innerHTML = `</span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;display: flex; align-items: center; justify-content: center; height: 100vh;&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;text-align: center; padding: 20px; border: 1px solid #ccc; border-radius: 8px; max-width: 400px; background-color: #f8f8f8;&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">strong</span> <span class="attr">style</span>=<span class="string">&quot;color: #333; display: block; margin-bottom: 10px;&quot;</span>&gt;</span>Welcome to the Search Engine<span class="tag">&lt;/<span class="name">strong</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;color: #666; display: block; margin-bottom: 10px;&quot;</span>&gt;</span>Please enter keywords to start your search.<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;color: #666; display: block;&quot;</span>&gt;</span>Current time: $&#123;timeString&#125;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    `;</span><br></pre></td></tr></table></figure><p>用户登录信息的保存</p><p>user 表</p><p>user_id user_name user_password</p><p>user_profile表</p><p>user_id user_pic user_收藏 </p><p>text表</p><p>text_id text_点赞</p>]]></content>
    
    
    
    <tags>
      
      <tag>web开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>前端向后端提交数据</title>
    <link href="/2023/12/15/%E5%89%8D%E7%AB%AF%E5%90%91%E5%90%8E%E7%AB%AF%E6%8F%90%E4%BA%A4%E6%95%B0%E6%8D%AE/"/>
    <url>/2023/12/15/%E5%89%8D%E7%AB%AF%E5%90%91%E5%90%8E%E7%AB%AF%E6%8F%90%E4%BA%A4%E6%95%B0%E6%8D%AE/</url>
    
    <content type="html"><![CDATA[<p>前端向后端</p><p>两种按钮</p><p>button按钮 提交方式</p><div class="form-group">     <button type="button" onclick="submitForm()">Login</button></div><p>是不包含任何默认js的，需要自己编写Js代码，使点击按钮时触发对应的js代码行为。</p><p>默认按钮对应的js需要指出提交的数据去往的地址路径，如果没有默认为当前网页的路径</p><p>submit按钮 提交方式</p><form name="search" action="search.php" method="post">                <p>                    <input type="text" id="searchBox" placeholder="Enter keywords...">                    <input type="submit" value="Search" >                </p>            </form><p>submit按钮包含了默认的js，只要点击按钮就会触发提交数据行为。</p><p>可以直接在html里面指出提交的路径，如果没有就默认为当前网页的路径。</p><form>                <p>                    <input type="text" id="searchBox" placeholder="Enter keywords...">                    <input type="button" value="Search" >                </p>            </form> <form>                <p>                    <input type="text" id="searchBox" placeholder="Enter keywords...">                    <button type="button" onclick="submitForm()">Search</button>                </p>            </form>]]></content>
    
    
    
    <tags>
      
      <tag>bugs web开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra模型训练</title>
    <link href="/2023/12/14/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/"/>
    <url>/2023/12/14/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[<p>为什么irra把mlm从损失函数中去掉后速度慢了三倍，怎么会差这么多</p><p>irra代码里面几种损失函数的定义</p><p><strong>sdm_loss</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">compute_sdm(i_feats, t_feats, batch[<span class="string">&#x27;pids&#x27;</span>], logit_scale)</span><br></pre></td></tr></table></figure><p><strong>id_loss</strong></p><p><em>1</em></p><p>去掉 图片编码器||使用sdm+id+mlm 使用图像编码器提取特征</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214171105614.png" alt="image-20231214171105614"></p><p>运行情况：</p><p><em>2</em></p><p>去掉 图片编码器+文本编码器+mlm损失函数||使用图像编码器提取特征</p><p>训练到一轮的时候报错，没有文本编码器</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214171317133.png" alt="image-20231214171317133"></p><ol start="3"><li></li></ol><p>好好好，都没训练成功，注释掉了没法用啊</p><p>坏了，掉底子了</p><p>替换错了</p><p>往batch里面加特征键不够用啊</p><p>还得替换特征提取函数</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214172850730.png" alt="image-20231214172850730"></p><p>图片编码器的代码不可以注释掉</p><p>得重新定义encode_image()函数</p><p>开始改，害怕啊</p><p>1、给imagedataset加上图片路径的返回</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214175307936.png" alt="image-20231214175307936"></p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214175326081.png" alt="image-20231214175326081"></p><ol start="2"><li></li></ol><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214175932164.png" alt="image-20231214175932164"></p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214175955257.png" alt="image-20231214175955257"></p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214195107618.png" alt="image-20231214195107618"></p><p>这个bug把上面改的代码都包括到了</p><p>为什么会慢了这么多</p><p>20s变成了1min30s</p><p>离谱</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214202535199.png" alt="image-20231214202535199"></p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214202546890.png" alt="image-20231214202546890"></p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214204622225.png" alt="image-20231214204622225"></p><p>好好好，看半天，不能改是吧，原来这个一趟的训练次数是由数据集大小决定的，数据集有那么大，就是要做那么多趟，我佛了</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214205245002.png" alt="image-20231214205245002"></p><p>开始训练后，可得在这挺很大一会，初始化更新这么慢是吧</p><p>找半天temperature的定义</p><p>原来是超参数</p><p><strong>置信度</strong></p><p><strong>temperature</strong>超参数</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214210906507.png" alt="image-20231214210906507"></p><p>偶真的服了，这bug是一个接一个啊</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214211559399.png" alt="image-20231214211559399"></p><p>再改，img_feat.to(device)</p><p>这是要让我把所有bug都感受一遍啊</p><p>返回列表</p><p>改成返回张量</p><p>变成stack张量时发现处理的np</p><p>改成张量</p><p>张量没有放在gpu上</p><p>啊啊啊啊</p><p>这改个bug重新运行就又要十几分钟，真的是伤不起啊</p><p>求求了，不要在报错了</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214213451952.png" alt="image-20231214213451952"></p><p>还搁这改，感觉改不完的错了</p><p>完了，逆天，跑出来啥也不是，寄</p><p>不对，还有希望，mlm好像都被我删掉了</p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214220848012.png" alt="image-20231214220848012"></p><p><img src="/irra%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/image-20231214220909876.png" alt="image-20231214220909876"></p><p>逆天，这真是绝了，搁这完了，啊啊啊，我这要怎么接着排查bug啊，我真的</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>日记</title>
    <link href="/2023/12/14/%E6%97%A5%E8%AE%B0/"/>
    <url>/2023/12/14/%E6%97%A5%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>闲谈</p><p>感觉自己好容易就想多了嗨嗨</p><p>妄自菲薄的感觉</p><p>要么就容易觉得自己不简单（当然现在基本不会有这样的感觉了，只觉得自己废物</p><p>就遇到难一点要坚持的事</p><p>就开始担心</p><p>更明显的是在团体中</p><p>担心自己很差劲</p><p>不符合别人期望</p><p>显得和一个废物一样</p><p>王成济老师真的很好</p><p>但我还是总是担心</p><p>会不会觉得我很差劲，会很失望</p><p>我到底何时能改变这些坏心理啊</p><p>哼，感觉都是小时候环境影响的</p>]]></content>
    
    
    
    <tags>
      
      <tag>日记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计学习方法</title>
    <link href="/2023/12/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    <url>/2023/12/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>php学习</title>
    <link href="/2023/12/13/php%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/12/13/php%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>后端脚本语言php</p><p>对比python 开发，路由定义都是放在后端代码里面，网页的跳转思路主要是看后端</p><p>而使用php开发，网页跳转是前端指定调用哪个后端php文件，网页的开发思路感觉更放在前端，毕竟php代码都是可以直接放在前端的</p><p>php引入文件，类似python import </p><p>require(“..&#x2F;t&#x2F;db.php”);</p>]]></content>
    
    
    
    <tags>
      
      <tag>web开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>phpstudy中php代码连接数据库</title>
    <link href="/2023/12/13/phpstudy%E4%B8%ADphp%E4%BB%A3%E7%A0%81%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <url>/2023/12/13/phpstudy%E4%B8%ADphp%E4%BB%A3%E7%A0%81%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<p>我真的服了！！！！！！！！</p><p>我都要以为自己是傻逼了</p><p>弄一下午人要崩了</p><p>网页如果只有前端，没有内容显示出来，首先怀疑就是和数据库的连接</p><p>这个破php</p><p>我一直怀疑是我环境没配好，才连不上数据库</p><p>结果真的是</p><p>连数据库的代码<strong>没有指出端口号</strong>啊啊啊啊啊啊</p><p>一般端口就是3306</p><p>但是之前数据库课我安装过mysql了</p><p>已经把3306口给占了</p><p>为了用这个phpstudy,我又装了个mysql，用的3305端口</p><p>没想到啊 没想到</p><p>一下午</p><p>结果就是个端口号没配好</p><p>绝了，emo一分钟</p><p>yeah!!!!!!!!!!!!!</p><p>win</p><p>前后端连好啦，可以往数据库写数据啦</p><p>哈哈哈哈哈加油</p><p>还挺神奇的</p><p>思路没转换过来</p><p>不过是用python还是java写web，都是在后端来定义路由，返回网页渲染</p><p>使用Php</p><p>居然是在前端里面来制定调用后端的Php文件，网页的关系在前端定义了</p><p>我nie马真服了</p><p>就说那个项目怎么一直显示不出来内容，源码里面也没看到php连接数据库，原来是把数据库的文件改路径了</p><p>吐了了了了</p><p>运行别人代码配环境永远最累</p><p>还是自己的代码好</p><p>还有readme文件一定要写好</p><p>涨涨涨记性</p><p>路径路径路径</p><p>很坑很坑很坑</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解决vscode因空格等代码风格报错</title>
    <link href="/2023/12/12/%E8%A7%A3%E5%86%B3vscode%E5%9B%A0%E7%A9%BA%E6%A0%BC%E7%AD%89%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC%E6%8A%A5%E9%94%99/"/>
    <url>/2023/12/12/%E8%A7%A3%E5%86%B3vscode%E5%9B%A0%E7%A9%BA%E6%A0%BC%E7%AD%89%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<p>禁用flake插件就可以了</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>环境配置容易出现的问题</title>
    <link href="/2023/12/12/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%AE%B9%E6%98%93%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2023/12/12/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%AE%B9%E6%98%93%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>一个项目下载好后使用vscode打开，运行项目夹里面的文件，当前的工作路径默认的是打开的文件的路径，因此代码里面的一些使用相对路径的地方会出现错误。</p><p>import os</p><p>获取当前脚本的目录</p><p>current_dir &#x3D; os.path.dirname(os.path.realpath(<strong>file</strong>))</p><p>切换当前工作目录到脚本所在目录</p><p>os.chdir(current_dir)</p><p>加上这两行代码就好了</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python+selenium爬虫报错</title>
    <link href="/2023/12/11/python-selenium%E7%88%AC%E8%99%AB%E6%8A%A5%E9%94%99/"/>
    <url>/2023/12/11/python-selenium%E7%88%AC%E8%99%AB%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>selenium包使用教程</title>
    <link href="/2023/12/11/selenium%E5%8C%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <url>/2023/12/11/selenium%E5%8C%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<p><strong>示例代码</strong></p><p>打开edge浏览器对应网址并关闭</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Edge WebDriver 实例</span></span><br><span class="line">driver = webdriver.Edge()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开网页</span></span><br><span class="line">driver.get(<span class="string">&#x27;https://www.bilibili.com&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">driver.quit()</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) E:\专业课作业\信息检索\scrapy\linyiSearcher-master&gt;D:/Software/Anaconda3_2023_3/python.exe e:/专业课作业/信息检索/scrapy/linyiSearcher-master/1_spider.py</span><br><span class="line">[<span class="number">4572</span>:<span class="number">19380</span>:<span class="number">1211</span>/<span class="number">180136.219</span>:ERROR:policy_logger.cc(<span class="number">156</span>)] :components\enterprise\browser\controller\chrome_browser_cloud_management_controller.cc(<span class="number">161</span>) Cloud management controller initialization aborted <span class="keyword">as</span> CBCM <span class="keyword">is</span> <span class="keyword">not</span> enabled. Please use the `--enable-chrome-browser-cloud-management` command line flag to enable it <span class="keyword">if</span> you are <span class="keyword">not</span> using the official Google Chrome build.</span><br><span class="line"></span><br><span class="line">DevTools listening on ws://<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">1691</span>/devtools/browser/2aac968c-2a13-4fe2-a681-5b8d93faf8cd</span><br></pre></td></tr></table></figure><p>我懂了，原来这不是在报错打开的是Chrome</p><p>果然配环境最烦</p><p>这个错误与 Chrome 浏览器的云端管理相关，不直接影响你的 Edge WebDriver。</p><p>Chrome涉及什么云端，链接github,网不好烦死了，还是用edge吧</p>]]></content>
    
    
    
    <tags>
      
      <tag>python包 爬虫 web自动化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vscode无法正确解析包补全代码</title>
    <link href="/2023/12/11/vscode%E6%97%A0%E6%B3%95%E6%AD%A3%E7%A1%AE%E8%A7%A3%E6%9E%90%E5%8C%85%E8%A1%A5%E5%85%A8%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/12/11/vscode%E6%97%A0%E6%B3%95%E6%AD%A3%E7%A1%AE%E8%A7%A3%E6%9E%90%E5%8C%85%E8%A1%A5%E5%85%A8%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<p>之前是一直显示import 导入包有问题</p><p>没有正确配置python解释器，打开控制面板ctrl +shift+p ,python interpreter 选择正确解释器就可以了</p><p>导入包成功后</p><p>但是还是不能查看包的源码，不能够跳转，并且也不能自动补全，缺少了Python包的解析插件， <strong>Python Extension Pack</strong>，安装这个插件就可以了。</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>总线的仲裁方式</title>
    <link href="/2023/12/11/%E6%80%BB%E7%BA%BF%E7%9A%84%E6%80%BB%E8%A3%81%E6%96%B9%E5%BC%8F/"/>
    <url>/2023/12/11/%E6%80%BB%E7%BA%BF%E7%9A%84%E6%80%BB%E8%A3%81%E6%96%B9%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<p><strong>总线仲裁Bus Arbiter</strong></p><p>多个设备同时竞争<em>总线控制权</em>，怎么决定哪个设备获得总线的控制权，就叫做总线仲裁。</p><p><strong>仲裁器Arbiter</strong></p><p>仲裁器来决定设备谁能获得<em>共享资源</em></p><p><strong>总线Bus</strong></p><p>计算机系统是由多个具有独立功能的模块<em>互相连接</em>而成。开发商还提供扩展模块的接口。模块之间需要互相<em>通信</em>，就产生了总线的概念。</p><p>总线是一种在多个模块间（模块之间是可以存在<em>优先级</em>的）传送信息的公共通路。</p><p>总线由传输信息的物理介质（电平信号）以及一套管理信息传输的通用规则（协议）所构成。</p><p><strong>总线标准</strong></p><p>符合相关的电气规范，机械结构规范等等。</p><p><strong>总线分类</strong></p><ul><li><p>片总线</p><p>片总线又成<strong>芯片总线</strong>，是处理器引出的信号线。<em>元件级总线</em>【不懂】</p><p><strong>地址总线</strong></p><p><strong>数据总线</strong></p><p><strong>控制总线</strong></p></li><li><p>内总线</p></li><li><p>外总线</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>接口技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>学习效率</title>
    <link href="/2023/12/11/%E5%AD%A6%E4%B9%A0%E6%95%88%E7%8E%87/"/>
    <url>/2023/12/11/%E5%AD%A6%E4%B9%A0%E6%95%88%E7%8E%87/</url>
    
    <content type="html"><![CDATA[<p><img src="/%E5%AD%A6%E4%B9%A0%E6%95%88%E7%8E%87/image-20231211093947464.png" alt="image-20231211093947464"></p><p>确实，环境稍微吵一点有助于避免走神，灯光不用太亮，会发困。</p>]]></content>
    
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra文件路径追踪</title>
    <link href="/2023/12/10/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/"/>
    <url>/2023/12/10/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/</url>
    
    <content type="html"><![CDATA[<p>method </p><p>vscode右键选择find in folder,直接搜索path</p><p>bases文件里面的dataset:</p><p><strong>BaseDataset</strong>(<strong>object</strong>)</p><p><strong>ImageTextDataset</strong>(<strong>Dataset</strong>)</p><p><strong>ImageDataset</strong></p><p><strong>TextDataset</strong></p><p><strong>ImageTextMLMDataset</strong></p><p>MLM使用的应该是<strong>ImageTextMLMDataset</strong>这个数据集</p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210143711133.png" alt="image-20231210143711133"></p><p>断点打在<strong>ImageTextMLMDataset</strong>数据集这里，运行train</p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210143842325.png" alt="image-20231210143842325"></p><p>停在这里进去</p><p>debug怎么传入命令行参数</p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210211159439.png" alt="image-20231210211159439"></p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210211311878.png" alt="image-20231210211311878"></p><p>换是换好了，但是特征的维度不匹配</p><p>原先图片编码器提取的特征</p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212036145.png" alt="image-20231210212036145"></p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212025474.png" alt="image-20231210212025474"></p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212348777.png" alt="image-20231210212348777"></p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212403907.png" alt="image-20231210212403907"></p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212725263.png" alt="image-20231210212725263"></p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212747727.png" alt="image-20231210212747727"></p><p> image_feats &#x3D; self.base_model.encode_image(images)        # print(image_feats.shape)        # i_feats &#x3D; image_feats[:, 0, :].float()        # print(i_feats.shape)   image_feats是[64,193,512]，i_feats是[64,512]，这是为什么呢，具体是怎么变化的</p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212856740.png" alt="image-20231210212856740"></p><p><img src="/irra%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%BF%BD%E8%B8%AA/image-20231210212940825.png" alt="image-20231210212940825"></p><p>问题来了</p><p>原模型的特征向量与现模型的长得不一样啊，老师救救我</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>clip论文阅读</title>
    <link href="/2023/12/07/clip%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2023/12/07/clip%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p>第一页  标题</p><p>大家好，今天我讲的论文是OpenAI在2021年发表在NeurIPS会议上的论文，在这个论文里提出了影响很大的模型CLIP。</p><p>这篇论文的作者团队全部来自OpenAI，然后OpenAI也将代码和预训练模型开源在了github上面。</p><p>首先我们来看看这篇文章的标题，利用自然语言监督学习可迁移的视觉模型。</p><p>标题中有两个关键词，利用自然语言监督以及可迁移。</p><p>怎么利用自然语言监督，就是这篇文章的关键。</p><p>然后他想达到的目的，就是这个迁移性transferable。</p><p>然后什么是迁移性呢，可迁移就是学习一个泛化很好的特征，能够在各种数据集上，不需要预训练就可以取得不错的效果。</p><p>英文表示就是zero-shot</p><p>第二页  </p><p>首先我们来直接看看clip模型是什么</p><p>这个图就是clip模型的结构</p><p>模型的输入</p><p>图片和文字的配对 pair</p><p>图片编码器既可以是个resnet,也可以是个vision transformer</p><p>文本编码器 文本特征</p><p>得到n个图片特征和n个文本特征</p><p>clip就对这n对特征进行对比学习</p><p>对比学习需要正样本和负样本</p><p>配对的就是正样本，沿着对角线的都是正样本</p><p>n*n-n都是负样本</p><p>通过正负样本对比学习，减少手工标注</p><p>openai收集了4亿个图片文本配对</p><p>clip如何做zero-shot推理</p><p>当然是不是zero-shot还存在疑问，因为openai收集的四亿对数据可能就包括了测试中图片文字对</p><p>prompt template</p><p>因为在预训练里面给的都是句子，所以在进行分类任务时把单词不全为句子</p><p>怎么变成句子，也有讲究</p><p>clip论文后面还提出了prompt engineering和prompt ensemble</p><p>计算cosine similarity，计算相似性</p><p>第三页 目录</p><p>clip这篇论文正文有三十多页，大部分都是实验和分析</p><p>第一页讲的摘要，然后一页讲的是引言，接下来几页讲的是方法，主要讲的是预训练，再后面的主要就是讲实验</p><p>第四页 摘要</p><p>目前的视觉系统训练，先有一个固定的，已经提前定义好的物体类别的集合</p><p>模型通过预测这些提前定义好的类别，从而完成模型的训练</p><p>固定的，提前定义好的标签类别</p><p>imagenet固定的1000个类别</p><p>cifar10 10个类</p><p>cifar100 100个类</p><p>提前定义好标签集合</p><p>采用了有限制性的监督信号，限制了模型的泛化性</p><p>不能识别新的物体类别</p><p>每次要预测新的类别，就要重新训练，就不好scale，不好做大做强了</p><p>第五页</p><p>不需要有提前定好的标签类</p><p>因为和自然语言处理的结合，clip学习到的视觉特征，和我们用语言描述出来的某个物体，已经产生了强烈的联系</p><p>比如香蕉，无论是在自然图像里的香蕉，或者素描的香蕉，或者动漫里的香蕉</p><p>clip训练出来的模型都知道是香蕉</p><p>第六页 引言</p><p>summary </p><p>概述</p><p>来自openai 的clip模型</p><p>思路简单</p><p>效果很好</p><p>zero shot</p><p>Learning transferable visual models from natural language supervision</p><p>从自然语言监督学习可迁移视觉模型</p><p>多模态</p><p>对比学习需要正样本和负样本</p><p>配对的就是正样本，沿着对角线的都是正样本</p><p>n*n-n都是负样本</p><p>通过正负样本对比学习，减少手工标注</p><p>openai收集了4亿个图片文本配对</p><p>clip如何做zero-shot推理</p><p>当然是不是zero-shot还存在疑问，因为openai收集的四亿对数据可能就包括了测试中图片文字对</p><p>prompt template</p><p>因为在预训练里面给的都是句子，所以在进行分类任务时把单词不全为句子</p><p>怎么变成句子，也有讲究</p><p>clip论文后面还提出了prompt engineering和prompt ensemble</p><p>计算cosine similarity，计算相似性</p><p>不需要有提前定好的标签类</p><p>因为和自然语言处理的结合，clip学习到的视觉特征，和我们用语言描述出来的某个物体，已经产生了强烈的联系</p><p>比如香蕉，无论是在自然图像里的香蕉，或者素描的香蕉，或者动漫里的香蕉</p><p>clip训练出来的模型都知道是香蕉</p><p>因为网络上的语言和图片有联系，不需要手工去打标签，所以迁移性非常强</p><p>与其说是做到了zero-shot,不如说是利用网络上文本图片省去了手工打标签</p><p>怎么利用自然语言</p><p>做到迁移性好</p><p>摘要</p><p>目前的视觉系统训练，先有一个固定的，已经提前定义好的物体类别的集合</p><p>模型通过预测这些提前定义好的类别，从而完成模型的训练</p><p>固定的，提前定义好的标签类别</p><p>imagenet固定的1000个类别</p><p>cifar10 10个类</p><p>cifar100 100个类</p><p>提前定义好标签集合</p><p>采用了有限制性的监督信号，限制了模型的泛化性</p><p>不能识别新的物体类别</p><p>每次要预测新的类别，就要重新训练，就不好scale，不好做大做强了</p><p>直接从自然语言文本里去的到监督信号</p><p>训练样本 图片文字的配对</p><p>爬了四个亿的图片对</p><p>有了这么大的数据集，就可以对模型进行自监督训练了。</p><p>多模态的对比学习完成模型训练</p><p>在预训练完成后，自然语言就被用来引导模型做物体分类</p><p>也就是之前说过的prompt</p><p>分类也不光局限于已经学到的视觉概念，还能扩展到新的类别，学习到的模型能直接在下游任务去做zero-shot推理</p><p>ground truth标注答案</p><p>参数调整</p><p>temperature参数设为可学习参数</p><p>视觉模型</p><p>resnet或者 vision transformer</p><p>文本使用的transformer</p><p>实验部分</p><p>什么是zero-shot transfer</p><p>clip的核心和精华所在</p><p>zero-shot 迁移的动机</p><p>之前自监督或者无监督的方法</p><p>主要研究的是特征学习的能力，目标是学一种泛化性比较好的特征，但是即使学到了泛化性很好的特征，想要应用到下游任务时，还是需要有标签的数据进行模型微调</p><p>如何训练一个模型，接下来不用再训练，微调了呢</p><p>所以这就是作者研究zero shot 迁移的动机，借助文本训练好了又大又好的模型</p><p>用文本做引导，很灵活的做zero-shot的迁移学习</p><p>prompt engineer and ensembling</p><p>提示 文本的引导作用</p><p>polysemy</p><p>多义性</p><p>constrcutive crane 起重机</p><p>crane 鹤</p><p>remote 远的</p><p>遥控器</p><p>a photo of ‘ ‘</p><p>指出来是个名词，解决一些歧义性问题</p><p>distribution gap</p><p>进行zero shot 迁移时，指出应用场景，都非常有用</p><p>limitation</p><p>数据集重叠</p><p>包括了下游数据集</p><p>不足和局限</p><p>扩大clip规模弥补十几个点的差距，不现实 sota state of art 特定任务中目前表现最好的模型</p><p>总结</p><p>43分钟代码讲解</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解空间树</title>
    <link href="/2023/12/07/%E8%A7%A3%E7%A9%BA%E9%97%B4%E6%A0%91/"/>
    <url>/2023/12/07/%E8%A7%A3%E7%A9%BA%E9%97%B4%E6%A0%91/</url>
    
    <content type="html"><![CDATA[<p>解空间树</p><p>表示问题解空间的结构</p><p>结点node 表示问题的<strong>状态</strong></p><p>边edge表示问题的<strong>转移</strong></p><p>子集树（组合树）每个节点的子节点代表添加或不添加</p><p>排列树 每个节点的子节点代表添加或交换</p>]]></content>
    
    
    
    <tags>
      
      <tag>算法设计与分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>out_of_memory</title>
    <link href="/2023/12/06/out-of-memory/"/>
    <url>/2023/12/06/out-of-memory/</url>
    
    <content type="html"><![CDATA[<p>模型训练时超出cuda内存</p><p>目前解决方法</p><p>把控制台关掉</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>r</title>
    <link href="/2023/12/06/r/"/>
    <url>/2023/12/06/r/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>模型替换bugs</title>
    <link href="/2023/12/06/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/"/>
    <url>/2023/12/06/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/</url>
    
    <content type="html"><![CDATA[<p>运行代码使用sh run_irra.sh</p><p>那么debug运行呢，怎么把参数传进去呢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#图片编码器</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode_image</span>(<span class="params">self, image</span>):</span><br><span class="line">        x = self.base_model.encode_image(image)</span><br><span class="line">        <span class="keyword">return</span> x[:, <span class="number">0</span>, :].<span class="built_in">float</span>()</span><br><span class="line">        <span class="comment"># return x.float() # for CLIP ResNet visual model</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode_text</span>(<span class="params">self, text</span>):</span><br><span class="line">        x = self.base_model.encode_text(text)</span><br><span class="line">        <span class="keyword">return</span> x[torch.arange(x.shape[<span class="number">0</span>]), text.argmax(dim=-<span class="number">1</span>)].<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure><p>注释掉这段代码并没有影响</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231206202415641.png" alt="image-20231206202415641"></p><p>具体怎么看大小啊</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231206202845996.png" alt="image-20231206202845996"></p><p>好了，使用.shape或者.size()</p><p>数据大小</p><p>batch[‘caption_ids’].shape</p><p>[128,77]</p><p>二维，一个批次128个个描述，每个</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231206203349401.png" alt="image-20231206203349401"></p><p>好好好，实际内容果然看不懂一点</p><p>在预处理里面被处理了的，那我怎么对应到原数据集里面实际图片呢</p><p>好好好</p><p>batch里面有一个image_ids,128张图片，然后对应的值就是图片的id,具体是怎么从图片名里面薅出来的，在还原回去吧，肯定要通过dataset文件看看了</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231206204020041.png" alt="image-20231206204020041"></p><p>&#x2F;mnt&#x2F;disk1&#x2F;yyh&#x2F;IRRA-main&#x2F;datasets&#x2F;cuhkpedes.py</p><p>去这个代码里面找数据集是怎么被预处理的</p><p>然后batch[image_ids]是怎么获取的，然后还原回去</p><p>找不到image_ids的来源啊</p><p>打开json文件</p><p>ctrl+shif+p</p><p>输入json</p><p>或者</p><p>ctrl+alt+m</p><p>一个batch有pids,caption_ids,image_ids,images</p><p>pids 大小128</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231206232337258.png" alt="image-20231206232337258"></p><p>都是行人的id</p><p>caption_ids</p><p>[128,77]</p><p>image_ids</p><p>[128]</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231206232649532.png" alt="image-20231206232649532"></p><p>image_ids都是图片的什么，序号？唯一的，怎么对应到图片路径？</p><p>images</p><p>[128,3,384,128]</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231206232832528.png" alt="image-20231206232832528"></p><p>batch追踪</p><p>首先使用build_dataloader函数，数据集中取出train_loader</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231207130217076.png" alt="image-20231207130217076"></p><p>build_dataloader函数实现</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231207130913413.png" alt="image-20231207130913413"></p><p>然后do_train，传入train_loader</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231207130136167.png" alt="image-20231207130136167"></p><p>do_train函数中迭代train_loader获取batch</p><p><img src="/%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2bugs/image-20231207130357480.png" alt="image-20231207130357480"></p><p>batch就是这么来的，然后传到model里面进行训练</p>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra模型替换</title>
    <link href="/2023/12/06/irra%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2/"/>
    <url>/2023/12/06/irra%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<ol><li><p><strong>不调用 <code>self.base_model</code> 进行图像特征提取</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pythonCopy codeimages = batch[<span class="string">&#x27;images&#x27;</span>]</span><br><span class="line">caption_ids = batch[<span class="string">&#x27;caption_ids&#x27;</span>]</span><br><span class="line"><span class="comment"># image_feats, text_feats = self.base_model(images, caption_ids)</span></span><br><span class="line">image_feats = self.load_image_features(batch[<span class="string">&#x27;image_feature_path&#x27;</span>])</span><br><span class="line">text_feats = self.base_model.encode_text(caption_ids)</span><br></pre></td></tr></table></figure><p>在这里，我使用了一个假设的 <code>load_image_features</code> 函数，你需要替换它为实际用于加载图片特征的函数。<code>load_image_features</code> 函数的实现应该负责从文件中读取保存的图片特征，并将其作为 <code>image_feats</code> 返回。</p></li><li><p><strong>不更新图像特征的梯度</strong>： 在上述修改后，确保不对 <code>image_feats</code> 部分进行梯度更新，以防止它们参与训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonCopy code</span><br><span class="line">i_feats = image_feats[:, <span class="number">0</span>, :].<span class="built_in">float</span>().detach()  <span class="comment"># 使用detach()防止梯度更新</span></span><br></pre></td></tr></table></figure><p>在这里，我添加了 <code>.detach()</code> 方法，这会使得 <code>i_feats</code> 不再参与梯度计算，从而实现图像特征不更新的效果。</p></li><li><p><strong>修改训练数据</strong>： 确保在训练数据中传递正确的 <code>image_feature_path</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonCopy code</span><br><span class="line">batch = &#123;<span class="string">&#x27;caption_ids&#x27;</span>: ..., <span class="string">&#x27;mlm_ids&#x27;</span>: ..., <span class="string">&#x27;mlm_labels&#x27;</span>: ..., <span class="string">&#x27;image_feature_path&#x27;</span>: ...&#125;</span><br></pre></td></tr></table></figure></li></ol><p>请注意，为了成功运行，你需要根据你的实际情况修改 <code>load_image_features</code> 函数，确保它能够正确地从文件中加载图片特征。此外，为了确保 <code>image_feats</code> 不参与训练，确保在计算损失时使用 <code>.detach()</code> 或 <code>.clone().detach()</code>。</p><p>最终修改的 <code>forward</code> 方法可能如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">pythonCopy codedef forward(self, batch):</span><br><span class="line">    ret = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    caption_ids = batch[<span class="string">&#x27;caption_ids&#x27;</span>]</span><br><span class="line">    image_feats = self.load_image_features(batch[<span class="string">&#x27;image_feature_path&#x27;</span>])</span><br><span class="line">    text_feats = self.base_model.encode_text(caption_ids)</span><br><span class="line"></span><br><span class="line">    i_feats = image_feats[:, <span class="number">0</span>, :].<span class="built_in">float</span>().detach()  <span class="comment"># 使用detach()防止梯度更新</span></span><br><span class="line">    t_feats = text_feats[torch.arange(text_feats.shape[<span class="number">0</span>]), caption_ids.argmax(dim=-<span class="number">1</span>)].<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">    logit_scale = self.logit_scale</span><br><span class="line">    ret.update(&#123;<span class="string">&#x27;temperature&#x27;</span>: <span class="number">1</span> / logit_scale&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 其余的任务处理保持不变...</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>irra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>phpmyadmin登陆</title>
    <link href="/2023/12/05/phpmyadmin%E7%99%BB%E9%99%86/"/>
    <url>/2023/12/05/phpmyadmin%E7%99%BB%E9%99%86/</url>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_45743302/article/details/117153490">记录phpstudy集成环境中phpmyadmin的相关配置以及遇到的一些问题_白沙染赤的博客-CSDN博客</a></p><p>配置文件</p><p>config.default.php</p>]]></content>
    
    
    
    <tags>
      
      <tag>bugs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>循环神经网络RNN</title>
    <link href="/2023/12/02/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN/"/>
    <url>/2023/12/02/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>encoder-decoder和Seq2Seq</title>
    <link href="/2023/12/02/Encoder-Decoder%E5%92%8CSeq2Seq/"/>
    <url>/2023/12/02/Encoder-Decoder%E5%92%8CSeq2Seq/</url>
    
    <content type="html"><![CDATA[<p>Encoder-Decoder</p><p>Encoder-Decoder 这个框架很好的诠释了机器学习的核心思路：</p><blockquote><p>将现实问题转化为数学问题，通过求解数学问题，从而解决现实问题。</p></blockquote><p>Encoder 又称作编码器。它的作用就是「将现实问题转化为数学问题」</p><p>将输入转换为向量</p><p><img src="/Encoder-Decoder%E5%92%8CSeq2Seq/image-20231202160757974.png" alt="image-20231202160757974"></p><p>Decoder 又称作解码器，他的作用是「求解数学问题，并转化为现实世界的解决方案」</p><p>将向量转换为输出</p><p><img src="/Encoder-Decoder%E5%92%8CSeq2Seq/image-20231202160833282.png" alt="image-20231202160833282"></p><p><img src="/Encoder-Decoder%E5%92%8CSeq2Seq/image-20231202185634257.png" alt="image-20231202185634257"></p><p>attention机制</p><p>将输入转换为向量序列</p><p>attention机制解决信息过长，信息丢失的问题</p><p>seq2seq框架</p><p>一种特殊的Encoder-Decoder框架</p><p>机器学习四大部分</p><p>算法 决策 参数 模型</p>]]></content>
    
    
    
    <tags>
      
      <tag>自然语言处理 NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>clip</title>
    <link href="/2023/12/02/clip/"/>
    <url>/2023/12/02/clip/</url>
    
    <content type="html"><![CDATA[<h1 id="Learning-Transferable-Visual-Models-From-Natural-Language-Supervision"><a href="#Learning-Transferable-Visual-Models-From-Natural-Language-Supervision" class="headerlink" title="Learning Transferable Visual Models From Natural Language Supervision"></a>Learning Transferable Visual Models From Natural Language Supervision</h1><ul><li><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2></li><li><h2 id="Clip"><a href="#Clip" class="headerlink" title="Clip"></a>Clip</h2></li><li><h2 id="IRRA"><a href="#IRRA" class="headerlink" title="IRRA"></a>IRRA</h2></li></ul><p>从自然语言natural language supervision监督学习可转移视觉模型</p><p>what is transferable models？</p><p>可转移视觉模型  可转移是什么意思</p><p>comparison</p><p>zero-short learning</p><p>利用可转移模型来解决零训练的情况</p><p>CLIP（Contrastive Language-Image Pre-training）</p><p>contrastive 对比</p><p>what is contrastive model </p><p><strong>contrastive language-Image Pre-training</strong></p><p>Bert</p><p>Bidirectional Encoder Representation from Transformers</p><p>双向 </p><p>transformer</p><p>transformer模型的提出论文<a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a>。创新点：引入了注意力机制</p><p>[^编码器-解码器结构]: </p>]]></content>
    
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irra代码</title>
    <link href="/2023/11/30/irra%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/11/30/irra%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<p>batch 数据批次</p><p>collate 函数：处理数据批次的函数</p><p>数据加载器dataloader的每个迭代中都会返回一个批次的数据，而’collate’函数则用于处理这个批次的数据，以便适应模型的输入要求。</p><p>当数据集的样本具有不同的大小或结构，’collate’函数非常有用。</p><p>它接收一个包含样本的列表，然后整理成一个批次，以便能输入到模型中。</p><p>整理通常包括</p><p>将不同长度的序列填充到相同的长度</p><p>将图像和标签打包成一个字典</p><p>我服了</p><p>纠结了我三星期的调式bug</p><p>xxxxxxxxxx pythonCopy codedef forward(self, batch):    ret &#x3D; dict()​    caption_ids &#x3D; batch[‘caption_ids’]    image_feats &#x3D; self.load_image_features(batch[‘image_feature_path’])    text_feats &#x3D; self.base_model.encode_text(caption_ids)​    i_feats &#x3D; image_feats[:, 0, :].float().detach()  # 使用detach()防止梯度更新    t_feats &#x3D; text_feats[torch.arange(text_feats.shape[0]), caption_ids.argmax(dim&#x3D;-1)].float()​    logit_scale &#x3D; self.logit_scale    ret.update({‘temperature’: 1 &#x2F; logit_scale})​    # 其余的任务处理保持不变…​    return retpython</p><p><em>斜体</em></p><p>就可以更改到指定目录了</p><p>优化器和学习率调度器的区别</p><p>优化器optimizer，调整模型参数，最小化训练损失函数。通过梯度下降或其他优化算法来更新模型参数，使得模型在训练数据上能够逐渐收敛到最优值。</p><p>学习率调度器 lrscheduler,学习率调度器用来自动调整学习率的大小，改善模型的训练性能。适当的学习率可以加速模型的收敛、提高稳定性，并有助于克服训练过程中的困难。</p><p>常见的学习率调度器包括固定学习率、学习率衰减、余弦退火学习率、学习率梯度调度等。</p>]]></content>
    
    
    
    <tags>
      
      <tag>reid 代码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>web开发</title>
    <link href="/2023/11/29/web%E5%BC%80%E5%8F%91/"/>
    <url>/2023/11/29/web%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<p>java后端开发</p><p>后端服务器环境使用Apache tomcat,为什么需要web服务器呢？</p><p>php后端开发</p><p>Apache HTTP Server Nginx</p><p>python后端开发</p><p>Django内置</p><p>flask内置</p>]]></content>
    
    
    
    <tags>
      
      <tag>web开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>bugs</title>
    <link href="/2023/11/13/bugs/"/>
    <url>/2023/11/13/bugs/</url>
    
    <content type="html"><![CDATA[<p>dataloaders &#x3D; {x: <strong>torch</strong>.utils.data.DataLoader(image_datasets[x], batch_size&#x3D;opt.batchsize,</p><p>​                       shuffle&#x3D;True, num_workers&#x3D;2, pin_memory&#x3D;False,</p><p>​                       prefetch_factor&#x3D;2, persistent_workers&#x3D;True) <em># 8 workers may work faster</em></p><p>​       for x in [‘train’, ‘val’]}</p><p>  File “train.py”, line 597, in <module><br>    model &#x3D; train_model(model, criterion, optimizer_ft, exp_lr_scheduler,<br>  File “train.py”, line 255, in train_model<br>    for iter, data in enumerate(dataloaders[phase]):<br>  File “&#x2F;home&#x2F;stu&#x2F;anaconda3&#x2F;envs&#x2F;yyh_env&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;torch&#x2F;utils&#x2F;data&#x2F;dataloader.py”, line 349, in <strong>iter</strong><br>    self._iterator._reset(self)<br>  File “&#x2F;home&#x2F;stu&#x2F;anaconda3&#x2F;envs&#x2F;yyh_env&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;torch&#x2F;utils&#x2F;data&#x2F;dataloader.py”, line 852, in _reset<br>    data &#x3D; self._get_data()<br>  File “&#x2F;home&#x2F;stu&#x2F;anaconda3&#x2F;envs&#x2F;yyh_env&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;torch&#x2F;utils&#x2F;data&#x2F;dataloader.py”, line 1029, in _get_data<br>    raise RuntimeError(‘Pin memory thread exited unexpectedly’)<br>RuntimeError: Pin memory thread exited unexpectedly</p><p>pin memory设置为false就可以了</p><p><img src="/image-20231115152128314.png" alt="image-20231115152128314"></p><p>服了，这又是什么bug</p><p><img src="/image-20231115202527552.png" alt="image-20231115202527552"></p><p><img src="/image-20231115205908431.png" alt="image-20231115205908431"></p><p><img src="/image-20231115230924667.png" alt="image-20231115230924667"></p>]]></content>
    
    
    
    <tags>
      
      <tag>reid代码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征提取</title>
    <link href="/2023/11/07/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    <url>/2023/11/07/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>特征提取保存</title>
    <link href="/2023/11/02/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%BF%9D%E5%AD%98/"/>
    <url>/2023/11/02/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%BF%9D%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<p>使用pickle进行特征保存</p><p>[Swin (all tricks+Circle 224x224)]模型</p><p>python train.py –use_swin –name swin_p0.5_circle_w5  –erasing_p 0.5 –circle –warm_epoch 5;  python test.py –name swin_p0.5_circle_w5 命令行参数</p>]]></content>
    
    
    
    <tags>
      
      <tag>reid 特征提取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>reid代码实战</title>
    <link href="/2023/11/01/reid%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/"/>
    <url>/2023/11/01/reid%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ Quick Question. How to recognize the images of the same ID?</span><br></pre></td></tr></table></figure><p>特征提取</p><p>特征匹配</p><p>不对啊，market 1051的图片命名是使用标签的，还是人为准备好的数据集，是由label的，有监督学习</p><p>那么自行进行的弱监督学习</p><p>网络自己进行的特征提取是怎么做到的呢</p><p>主干网络</p><p>backbone network</p><p>预训练模型</p><p>pretrained model</p><p>学习一下numpy</p><p>学习一下几种主干网络  backbone network</p><p>跑一下代码</p><p>读一下论文</p><p>了解怎么替换骨干网络</p><p>colab运行reid步骤</p><p>配置环境</p><p>1.使用requirements.txt</p><p>packagename&#x3D;&#x3D;version</p><p>cd 到包含requirements.txt的文件夹中</p><p>pip install -r requirements.txt</p><p>-r 中的r 表示依赖项选项，即requirement的缩写</p><p>每次更改环境只需要在requirements.txt文件中更改，重新运行即可</p><p>注意，在goole colab中使用命令行执行cmd时要加上!，切换路径要加上%</p><p>本地配置环境实现环境隔离使用虚拟环境就好了，google colab中好像每次重新打开就是新环境了，都得重新配置</p><p><code>AlexNet</code>, <code>VGG16</code>,</p><p>test</p><p><img src="/reid%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/image-20231101100848392.png" alt="image-20231101100848392"></p><p>linux终端命令格式</p><p>numpy</p><p>感知机 perceptonper</p><p>感知机就是</p><p>多层感知机</p><p>resnet模型</p>]]></content>
    
    
    
    <tags>
      
      <tag>reid 行人重识别 深度学习与神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>小土堆视频学习</title>
    <link href="/2023/10/20/%E5%B0%8F%E5%9C%9F%E5%A0%86%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/10/20/%E5%B0%8F%E5%9C%9F%E5%A0%86%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>踩坑点</p><p>不要把文件名命名为常见的包的名，会报错,import error </p><p>transforms使用，transforms就是一个工具包，使用里面的类要先初始化类称为一个对象，然后在调用对象解决问题</p><p>实用技巧</p><p>ctrl+p查看函数所需参数</p><p>长按ctrl去查看源代码中给出的函数用法</p><p>使用alt+enter显示错误自动补充导入包</p><p><img src="/%E5%B0%8F%E5%9C%9F%E5%A0%86%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0/image-20231025191318691.png" alt="image-20231025191318691"></p><p><img src="/%E5%B0%8F%E5%9C%9F%E5%A0%86%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0/image-20231025191352216.png" alt="image-20231025191352216"></p><p>不使用module，直接使用一层网络，输出的结果也是一样的？？？</p><p>所以构建module的作用是保存了神经网络的训练参数，便于后面的训练吗？</p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络与数据学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据操作</title>
    <link href="/2023/10/19/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"/>
    <url>/2023/10/19/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>环境配置</title>
    <link href="/2023/10/19/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <url>/2023/10/19/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p>day1李沐《动手学深度学习》</p><p>电脑</p><p>anaconda scikit-learn环境</p><p>JupterNotebook运行</p><p>存疑</p><p>有必要换成电脑的ubuntu运行吗</p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络与深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>导航栏复用</title>
    <link href="/2023/10/19/%E5%AF%BC%E8%88%AA%E6%A0%8F%E5%A4%8D%E7%94%A8/"/>
    <url>/2023/10/19/%E5%AF%BC%E8%88%AA%E6%A0%8F%E5%A4%8D%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>网页前端开发使用bootstrap框架</p><p>html学习各种标签</p><p>css学习各种选择器 id选择器# 属性选择器. 类选择器 selector</p><p>js</p><p>写导航栏时希望每个网页共用一个导航栏</p><p>解决方案（仅限于学习了前端知识）：</p><p>每个网页都粘贴一遍代码，缺点：一改全改</p><p>使用iframe 缺点：属于网页嵌入显示在另一个网页中，不好排版，使用下拉菜单栏时距离不好控制，尽量不要使用iframe,否则只会给自己找麻烦</p><p>。。。</p>]]></content>
    
    
    
    <tags>
      
      <tag>web开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo推送到gitee网页无法更新</title>
    <link href="/2023/09/23/hexo%E6%8E%A8%E9%80%81%E5%88%B0gitee%E7%BD%91%E9%A1%B5%E6%97%A0%E6%B3%95%E6%9B%B4%E6%96%B0/"/>
    <url>/2023/09/23/hexo%E6%8E%A8%E9%80%81%E5%88%B0gitee%E7%BD%91%E9%A1%B5%E6%97%A0%E6%B3%95%E6%9B%B4%E6%96%B0/</url>
    
    <content type="html"><![CDATA[<p>使用hexo往gitee更新博客，网页无显示</p><p>首先hexo clean hexo generate hexo deploy</p><p>本地可以显示新更新网页</p><p>但是通过gitee访问未更新</p><p>解决方法</p><p><img src="/2023/09/23/hexo%E6%8E%A8%E9%80%81%E5%88%B0gitee%E7%BD%91%E9%A1%B5%E6%97%A0%E6%B3%95%E6%9B%B4%E6%96%B0/1.png" alt="1"></p><p>在gitee pages服务中重新更新</p>]]></content>
    
    
    
    <tags>
      
      <tag>bug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性回归模型</title>
    <link href="/2023/09/23/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    <url>/2023/09/23/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>辗转相除法</title>
    <link href="/2023/09/05/%E8%BE%97%E8%BD%AC%E7%9B%B8%E9%99%A4%E6%B3%95/"/>
    <url>/2023/09/05/%E8%BE%97%E8%BD%AC%E7%9B%B8%E9%99%A4%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>复习一下一个简单但很有用的算法</p><p>辗转相除求最大公因数</p><p>算法的核心就是数学知识，这个算法也就是发现了一个数学规律并且应用</p><p>当求a和b两个数的最大公因（约）数时，用a-b（假设a大于b)求出来的这个值一定是最大公因数的倍数（可以用公式推出来的</p><p>在设计算法时，忽视这个规律，直接去枚举所有的数来判断是否能整除显然复杂了，用这个减出来的数就可以排除掉很多</p><p>取余也能体现出减法，而且省略掉许多不必要的减法</p><p>%在算法里面非常常见</p><p>void </p>]]></content>
    
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>差分与前缀和</title>
    <link href="/2023/09/04/%E5%B7%AE%E5%88%86%E4%B8%8E%E5%89%8D%E7%BC%80%E5%92%8C/"/>
    <url>/2023/09/04/%E5%B7%AE%E5%88%86%E4%B8%8E%E5%89%8D%E7%BC%80%E5%92%8C/</url>
    
    <content type="html"><![CDATA[<p>每日算法打卡</p><p>差分数组 b[] 1 2 3 4 5</p><p>前缀和数组 a[] 1 3 6 10 15</p><p>insert函数，改变差分数组的两个值来改变前缀和数组的一段范围内的所有值</p><p>void insert(int l, int r, int c)</p><p>{</p><p>​b[l]+&#x3D;c;</p><p>​b[r+1]-&#x3D;c;</p><p>}</p><p>关键点：想要改变一个数组内连续范围增加或减少同一个值，可以构造差分数组来帮助降低时间复杂度</p><p>已知a 构造b  原理b[i]&#x3D;a[i]-a[i-1]</p><p>简化</p><p>for(int i&#x3D;1;i&lt;&#x3D;n;i++)insert(i,i,a[i]);通过insert函数构造出差分数组，当然也可以直接用公式（使用这个函数不需要初始化b数组为0？）</p><p>由差分数组还原出前缀和数组</p><p>a[i]&#x3D;a[i-1]+b[i];</p><p>或者直接再把b当做前缀和数组b[i]+&#x3D;b[i-1];</p>]]></content>
    
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ad学习</title>
    <link href="/2023/08/03/ad%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/08/03/ad%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>altuim designer pcb设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>词根词缀学习</title>
    <link href="/2023/07/25/%E8%AF%8D%E6%A0%B9%E8%AF%8D%E7%BC%80%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/07/25/%E8%AF%8D%E6%A0%B9%E8%AF%8D%E7%BC%80%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>1</title>
    <link href="/2023/07/24/1/"/>
    <url>/2023/07/24/1/</url>
    
    <content type="html"><![CDATA[<p>快递电话号码写错了，真倒霉，等了这么久的holocubic的外壳，还以为今天可以拿到，结果电话没打到我手机，明天补送，惨兮兮</p><p>上午科四考了，这么久终于把驾照拿了，今天也算有收获，回来时一路红灯都没熄火，真顺，有驾照嘿嘿就是不一样</p><p>晚上把typora和hexo网页插入图片的博客写了</p><p>我的holocubic，急急急急急，迫不及待要拿到我的外壳啊啊啊啊啊啊啊</p><p>可以开新坑了，下一个复刻太极创客的太乐小车</p><p>下下一个，立创开源广场雪花灯</p><p>还有Holocubic板子发热有点严重，后面把屏幕板改成给主板供电，以及自己试试写固件，烧一下自己的程序，专门复刻别人的有什么意思是吧</p><p>还有，做一个单词本的软件，电脑上面背的，holocubic上面显示</p>]]></content>
    
    
    
    <tags>
      
      <tag>日常</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo+typora博客中添加图片</title>
    <link href="/2023/07/21/hexo-typora%E5%8D%9A%E5%AE%A2%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%9B%BE%E7%89%87/"/>
    <url>/2023/07/21/hexo-typora%E5%8D%9A%E5%AE%A2%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%9B%BE%E7%89%87/</url>
    
    <content type="html"><![CDATA[<p>在typora中图片格式!加上[]加上() 中括号里面是图片信息描述，圆括号里面是图片路径</p><p>图片路径可以分为三种  <strong>绝对路径 相对路径 网络路径</strong></p><p><em>网络路径</em>可以不用将图片插在博客文件夹里面，直接到网站去复制一下别人的图片链接。</p><p>优点，不占内存</p><p>缺点，链接可能会失效，打开网页时加载图片相对较慢，其它网站可能不给引用，加载不显示，总之就不是自己的哈哈</p><p><img src="https://img2.baidu.com/it/u=4268481969,128088531&fm=253&fmt=auto&app=138&f=JPEG?w=1000&h=500" alt=" 网络路径"></p><p><em>绝对路径</em>，文件夹在自己电脑的位置写死了，不好移动，也不好部署到gitee或github上，否决</p><p><img src="E:\Pictures\1.jpeg" alt="直接在typora中插入图片，默认是绝对路径"></p><p><em>相对路径</em>，设置图片相对当前博客文件夹source的位置</p><p>在source里面放blog和pic文件夹，然后路径使用\pic\文件名</p><p>虽然typora里面没有显示出来图片，但在网页中显示出来了</p><p><img src="/%5Cpic%5C1.jpeg" alt="相对路径"></p><p>但是这就挺麻烦的呢，所有日志的图片都放在一个文件夹里面，按照一般习惯都是相应图片和相应博客有对应关系的，这种方法都没有对应关系，修改都不好弄。</p><p>但是开发者都考虑到了，于是可以去全局配置文件里面设置一下</p><p>post_asset_folder: true</p><p>这样使用hexo new 的时候在生成md文件时也会生成同名文件夹，里面用来存放图片</p><p>怎么显示图片呢</p><p>再写相对路径又多一级，好麻烦好像</p><p><img src="/1.jpg"></p><p>但是不用，直接写相应文件夹里面的文件名就行，这就很方便了</p><p>只能说typore和hexo真的是挺兼容的，真的是天生一对嘿嘿</p><p>网上有使用插件的，但我觉得已经很方便了直接引用文件名</p><p>剩下还有点不方便的就是每次往相应文件夹插入图片，如果我复制图片typora能自动帮我复制到对应图片文件夹就好了，这就可以使用typora的偏好设置了</p><p><img src="/u=1185492631,1304693633&fm=253&fmt=auto&app=138&f=JPEG.jpeg" alt="直接复制网络图片"></p><p>相应同名图片文件夹就有了这张图片呢，这真的是太方便了哈哈哈</p><p><img src="/u=2616026941,1797983244&fm=253&fmt=auto&app=138&f=JPEG.jpeg" alt="img"></p><p>不过还是有个小bug，typora的相对路径是以source 为根目录，而hexo的根目录是用的图片文件夹，这就导致插入图片的相对路径每次都要删一下前面，有点小麻烦，而且typora看不到图片</p><p>哦补充一下，这个自动生成相应同名图片文件夹需要下载插件</p>]]></content>
    
    
    
    <tags>
      
      <tag>技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>holocubic复刻</title>
    <link href="/2023/07/21/holocubic/"/>
    <url>/2023/07/21/holocubic/</url>
    
    <content type="html"><![CDATA[<p>记录第一次复刻项目</p><p>稚晖君的holocubic</p><p>购买材料</p><p>工具：电烙铁 焊锡丝 热风枪 加热台 焊锡膏 助焊剂 洗板水 </p><p>热风枪买的是华谊的代工产品，100块，挺好用的</p><p>加热台随便买的400w的，9元</p><p>焊锡膏：10元</p><p>助焊剂：8元</p><p>洗板水：10元</p><p>元器件：第一次用bom表配元器件，零散的元件淘宝下单30元，同样的元器件如果单价比较贵直接购买不要放在bom表单里面更便宜，比较贵的mpu8050陀螺仪，cp2012, esp32 15元</p><p>外壳：稚晖君原版naive版本要打印两个外壳，使用群文件里面的Metal版本只用打印一个外壳，在立创的三维猴下单的，新用户可以有15元的快递免费劵，外壳3d打印可以有透明，半透明，白色等选择，透明半透明比较贵，而且我也比较喜欢白色款式，还有一个盲盒随机材料，所以一共打印了两份Metal外壳，耗费6元</p><p>踩坑：</p><p>一开始是在立创开源广场搜索的holocubic项目，直接找了一个高访问量的就打印板子和bom表下单了，资料匮乏，项目也有部分问题，对于新手复刻实在不友好，复刻到了cp2012可以被电脑识别后死活esp32不能和电脑通信，而且后面就算接着做下去缺少相应固件资料以及排错指导，只好中途放弃。后面加群发现Holocubic的项目被各位大佬们完善的真的很好，教程也真的是非常照顾小白了。所以以后如果复刻而自己又没有相应基础的项目还是要找资料完善的以及加qq群及时交流。</p>]]></content>
    
    
    
    <tags>
      
      <tag>holocubic复刻</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>太乐小车</title>
    <link href="/2023/07/21/%E5%A4%AA%E4%B9%90%E5%B0%8F%E8%BD%A6/"/>
    <url>/2023/07/21/%E5%A4%AA%E4%B9%90%E5%B0%8F%E8%BD%A6/</url>
    
    <content type="html"><![CDATA[<p>学习太极创客的太乐小车项目</p><p>arduino uno主板+L293D电机驱动扩展板</p>]]></content>
    
    
    
    <tags>
      
      <tag>arduino uno</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的第一篇博客</title>
    <link href="/2023/07/20/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <url>/2023/07/20/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<p>之前一直想搭建一个服务器，但是租服务器好像挺贵的，也不是很用得着，只是觉得在浏览器输入网址的感觉很酷，现在用hexo和gitee pages很方便。</p><p>写些什么呢，要不要能被其他人看到呢，想技术相关的分享来反推自己学习，可是又不想自己日常被看到，毕竟日记都是写给自己看的，就像小学写日记，如果要给老师看的，总会有些写的不太自在。</p><p>博客，接触到这个词真的挺晚的，反正是在大学我才有电脑的，大学之前我可能连电脑开关机都不太会。</p><p>记录些什么呢，技术肯定是要的，电子相关可能算是我难得的和学习有关的爱好了，运动可以记录一下乒乓球，乒乓球也是一个顶顶重要的爱好，或许还可以记录一下听的广播剧，这也算是我的一个打法时间的小兴趣。哦对了，做饭日常记录一波，炸厨房的日常也很有意思的。</p><p>大学专业课也可以记录一下。</p><p>果然是日常，写得没有什么逻辑，想到什么就些什么，这种自在的感觉真好。</p><p>大二暑假</p><p>目标：搭建一个网页，和风灵玉秀相关的</p><p>做出来holocubic</p><p>做出来智能小车，最好能加上机械臂</p><p>多打球，多去游泳<img src="E:\Pictures\1632553134965.jpg" alt="1632553134965"></p><p>多做些种类的美食</p><p><img src="E:\Pictures\1.jpeg"></p>]]></content>
    
    
    
    <tags>
      
      <tag>日常</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
